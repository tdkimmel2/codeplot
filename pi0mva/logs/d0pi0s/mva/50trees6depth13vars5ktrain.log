DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : Booking method: [1mBDT[0m
                         : 
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 5000
                         : Signal     -- testing events             : 5000
                         : Signal     -- training and testing events: 10000
                         : Background -- training events            : 5000
                         : Background -- testing events             : 5000
                         : Background -- training and testing events: 10000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.974  +0.955  +0.751  -0.185  -0.185  +0.724    +0.755    +0.642   +0.937   +0.754     -0.687  -0.213
                         :   pi0p3cms:  +0.974   +1.000  +0.931  +0.734  -0.170  -0.170  +0.704    +0.759    +0.647   +0.960   +0.777     -0.672  -0.190
                         :       gm1e:  +0.955   +0.931  +1.000  +0.524  -0.128  -0.128  +0.895    +0.820    +0.448   +0.976   +0.538     -0.619  -0.192
                         :       gm2e:  +0.751   +0.734  +0.524  +1.000  -0.253  -0.253  +0.089    +0.355    +0.862   +0.526   +0.978     -0.563  -0.199
                         :    gm1e925:  -0.185   -0.170  -0.128  -0.253  +1.000  +1.000  -0.017    -0.079    -0.248   -0.118   -0.234     +0.081  -0.031
                         :    gm2e925:  -0.185   -0.170  -0.128  -0.253  +1.000  +1.000  -0.017    -0.079    -0.248   -0.118   -0.234     +0.081  -0.031
                         :      ediff:  +0.724   +0.704  +0.895  +0.089  -0.017  -0.017  +1.000    +0.773    +0.071   +0.866   +0.116     -0.428  -0.120
                         :  gm1eerror:  +0.755   +0.759  +0.820  +0.355  -0.079  -0.079  +0.773    +1.000    +0.339   +0.823   +0.380     -0.370  -0.111
                         :  gm2eerror:  +0.642   +0.647  +0.448  +0.862  -0.248  -0.248  +0.071    +0.339    +1.000   +0.463   +0.868     -0.377  -0.137
                         :   gm1p3cms:  +0.937   +0.960  +0.976  +0.526  -0.118  -0.118  +0.866    +0.823    +0.463   +1.000   +0.571     -0.614  -0.172
                         :   gm2p3cms:  +0.754   +0.777  +0.538  +0.978  -0.234  -0.234  +0.116    +0.380    +0.868   +0.571   +1.000     -0.565  -0.182
                         : gmthetacms:  -0.687   -0.672  -0.619  -0.563  +0.081  +0.081  -0.428    -0.370    -0.377   -0.614   -0.565     +1.000  +0.226
                         :     mfchi2:  -0.213   -0.190  -0.192  -0.199  -0.031  -0.031  -0.120    -0.111    -0.137   -0.172   -0.182     +0.226  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.975  +0.967  +0.635  -0.072  -0.072  +0.850    +0.786    +0.504   +0.949   +0.633     -0.716  -0.140
                         :   pi0p3cms:  +0.975   +1.000  +0.942  +0.627  -0.068  -0.068  +0.825    +0.779    +0.513   +0.969   +0.667     -0.727  -0.130
                         :       gm1e:  +0.967   +0.942  +1.000  +0.432  -0.063  -0.063  +0.954    +0.843    +0.342   +0.978   +0.441     -0.620  -0.137
                         :       gm2e:  +0.635   +0.627  +0.432  +1.000  -0.069  -0.069  +0.141    +0.301    +0.829   +0.437   +0.963     -0.547  -0.122
                         :    gm1e925:  -0.072   -0.068  -0.063  -0.069  +1.000  +1.000  -0.047    -0.034    -0.056   -0.062   -0.064     +0.047  -0.001
                         :    gm2e925:  -0.072   -0.068  -0.063  -0.069  +1.000  +1.000  -0.047    -0.034    -0.056   -0.062   -0.064     +0.047  -0.001
                         :      ediff:  +0.850   +0.825  +0.954  +0.141  -0.047  -0.047  +1.000    +0.825    +0.100   +0.928   +0.164     -0.498  -0.109
                         :  gm1eerror:  +0.786   +0.779  +0.843  +0.301  -0.034  -0.034  +0.825    +1.000    +0.253   +0.833   +0.319     -0.384  -0.120
                         :  gm2eerror:  +0.504   +0.513  +0.342  +0.829  -0.056  -0.056  +0.100    +0.253    +1.000   +0.355   +0.821     -0.347  -0.105
                         :   gm1p3cms:  +0.949   +0.969  +0.978  +0.437  -0.062  -0.062  +0.928    +0.833    +0.355   +1.000   +0.473     -0.637  -0.127
                         :   gm2p3cms:  +0.633   +0.667  +0.441  +0.963  -0.064  -0.064  +0.164    +0.319    +0.821   +0.473   +1.000     -0.586  -0.113
                         : gmthetacms:  -0.716   -0.727  -0.620  -0.547  +0.047  +0.047  -0.498    -0.384    -0.347   -0.637   -0.586     +1.000  +0.081
                         :     mfchi2:  -0.140   -0.130  -0.137  -0.122  -0.001  -0.001  -0.109    -0.120    -0.105   -0.127   -0.113     +0.081  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [1mTrain all methods[0m
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0060582     0.99822   [     -3.1814      5.7307 ]
                         :   pi0p3cms:   0.0060451     0.99834   [     -3.1823      5.7307 ]
                         :       gm1e:   0.0072977      1.0039   [     -3.1781      5.7307 ]
                         :       gm2e:   0.0057390     0.99688   [     -3.0048      5.7307 ]
                         :    gm1e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :    gm2e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :      ediff:   0.0071855      1.0039   [     -3.0813      5.7307 ]
                         :  gm1eerror:   0.0087212     0.98917   [     -2.9440      5.7307 ]
                         :  gm2eerror:   0.0072976     0.99978   [     -2.8631      5.7307 ]
                         :   gm1p3cms:   0.0064692      1.0006   [     -3.1755      5.7307 ]
                         :   gm2p3cms:   0.0056364     0.99686   [     -3.1597      5.7307 ]
                         : gmthetacms:   0.0059472     0.99744   [     -3.1827      5.7307 ]
                         :     mfchi2:    0.010585     0.99134   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 2.907e-01
                         :    2 : gmthetacms : 2.573e-01
                         :    3 : gm1e       : 2.565e-01
                         :    4 : pi0p3cms   : 2.465e-01
                         :    5 : gm1eerror  : 2.402e-01
                         :    6 : mfchi2     : 2.393e-01
                         :    7 : gm2e       : 2.383e-01
                         :    8 : gm1p3cms   : 2.217e-01
                         :    9 : gm2eerror  : 2.201e-01
                         :   10 : gm2p3cms   : 2.024e-01
                         :   11 : ediff      : 1.325e-01
                         :   12 : gm1e925    : 7.736e-02
                         :   13 : gm2e925    : 7.736e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0060582     0.99822   [     -3.1814      5.7307 ]
                         :   pi0p3cms:   0.0060451     0.99834   [     -3.1823      5.7307 ]
                         :       gm1e:   0.0072977      1.0039   [     -3.1781      5.7307 ]
                         :       gm2e:   0.0057390     0.99688   [     -3.0048      5.7307 ]
                         :    gm1e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :    gm2e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :      ediff:   0.0071855      1.0039   [     -3.0813      5.7307 ]
                         :  gm1eerror:   0.0087212     0.98917   [     -2.9440      5.7307 ]
                         :  gm2eerror:   0.0072976     0.99978   [     -2.8631      5.7307 ]
                         :   gm1p3cms:   0.0064692      1.0006   [     -3.1755      5.7307 ]
                         :   gm2p3cms:   0.0056364     0.99686   [     -3.1597      5.7307 ]
                         : gmthetacms:   0.0059472     0.99744   [     -3.1827      5.7307 ]
                         :     mfchi2:    0.010585     0.99134   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 10000 samples, validate on 10000 samples
Epoch 1/50

   32/10000 [..............................] - ETA: 49s - loss: 0.8025 - categorical_accuracy: 0.4688
 1632/10000 [===>..........................] - ETA: 1s - loss: 0.7168 - categorical_accuracy: 0.5919 
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.6540 - categorical_accuracy: 0.6432
 4960/10000 [=============>................] - ETA: 0s - loss: 0.6298 - categorical_accuracy: 0.6649
 6592/10000 [==================>...........] - ETA: 0s - loss: 0.6062 - categorical_accuracy: 0.6834
 8224/10000 [=======================>......] - ETA: 0s - loss: 0.5963 - categorical_accuracy: 0.6948
 9920/10000 [============================>.] - ETA: 0s - loss: 0.5897 - categorical_accuracy: 0.7002
10000/10000 [==============================] - 1s 69us/step - loss: 0.5892 - categorical_accuracy: 0.7003 - val_loss: 0.4894 - val_categorical_accuracy: 0.7774

Epoch 00001: val_loss improved from inf to 0.48936, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4446 - categorical_accuracy: 0.8438
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.5331 - categorical_accuracy: 0.7500
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.5337 - categorical_accuracy: 0.7476
 4864/10000 [=============>................] - ETA: 0s - loss: 0.5221 - categorical_accuracy: 0.7547
 6528/10000 [==================>...........] - ETA: 0s - loss: 0.5226 - categorical_accuracy: 0.7574
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.5258 - categorical_accuracy: 0.7569
 9824/10000 [============================>.] - ETA: 0s - loss: 0.5236 - categorical_accuracy: 0.7578
10000/10000 [==============================] - 0s 50us/step - loss: 0.5233 - categorical_accuracy: 0.7575 - val_loss: 0.4753 - val_categorical_accuracy: 0.7830

Epoch 00002: val_loss improved from 0.48936 to 0.47528, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3736 - categorical_accuracy: 0.8750
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.5136 - categorical_accuracy: 0.7574
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.5060 - categorical_accuracy: 0.7686
 4832/10000 [=============>................] - ETA: 0s - loss: 0.5051 - categorical_accuracy: 0.7686
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.5066 - categorical_accuracy: 0.7676
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.5108 - categorical_accuracy: 0.7670
 9696/10000 [============================>.] - ETA: 0s - loss: 0.5074 - categorical_accuracy: 0.7697
10000/10000 [==============================] - 1s 51us/step - loss: 0.5073 - categorical_accuracy: 0.7699 - val_loss: 0.4729 - val_categorical_accuracy: 0.7873

Epoch 00003: val_loss improved from 0.47528 to 0.47291, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3962 - categorical_accuracy: 0.8750
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.5176 - categorical_accuracy: 0.7650
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.5180 - categorical_accuracy: 0.7623
 4928/10000 [=============>................] - ETA: 0s - loss: 0.5132 - categorical_accuracy: 0.7648
 6528/10000 [==================>...........] - ETA: 0s - loss: 0.5038 - categorical_accuracy: 0.7705
 8192/10000 [=======================>......] - ETA: 0s - loss: 0.5048 - categorical_accuracy: 0.7706
 9728/10000 [============================>.] - ETA: 0s - loss: 0.5026 - categorical_accuracy: 0.7725
10000/10000 [==============================] - 1s 57us/step - loss: 0.5027 - categorical_accuracy: 0.7722 - val_loss: 0.4709 - val_categorical_accuracy: 0.7871

Epoch 00004: val_loss improved from 0.47291 to 0.47092, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4107 - categorical_accuracy: 0.7812
 1536/10000 [===>..........................] - ETA: 0s - loss: 0.4896 - categorical_accuracy: 0.7728
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.5000 - categorical_accuracy: 0.7706
 4640/10000 [============>.................] - ETA: 0s - loss: 0.4962 - categorical_accuracy: 0.7716
 6272/10000 [=================>............] - ETA: 0s - loss: 0.4984 - categorical_accuracy: 0.7714
 7840/10000 [======================>.......] - ETA: 0s - loss: 0.4999 - categorical_accuracy: 0.7727
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.4981 - categorical_accuracy: 0.7749
10000/10000 [==============================] - 1s 56us/step - loss: 0.4972 - categorical_accuracy: 0.7753 - val_loss: 0.4674 - val_categorical_accuracy: 0.7871

Epoch 00005: val_loss improved from 0.47092 to 0.46738, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4388 - categorical_accuracy: 0.8438
 1184/10000 [==>...........................] - ETA: 0s - loss: 0.4933 - categorical_accuracy: 0.7796
 2784/10000 [=======>......................] - ETA: 0s - loss: 0.4970 - categorical_accuracy: 0.7816
 4160/10000 [===========>..................] - ETA: 0s - loss: 0.4945 - categorical_accuracy: 0.7803
 5760/10000 [================>.............] - ETA: 0s - loss: 0.4924 - categorical_accuracy: 0.7832
 7392/10000 [=====================>........] - ETA: 0s - loss: 0.4912 - categorical_accuracy: 0.7829
 9024/10000 [==========================>...] - ETA: 0s - loss: 0.4917 - categorical_accuracy: 0.7836
10000/10000 [==============================] - 1s 52us/step - loss: 0.4952 - categorical_accuracy: 0.7809 - val_loss: 0.4743 - val_categorical_accuracy: 0.7867

Epoch 00006: val_loss did not improve from 0.46738
Epoch 7/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6315 - categorical_accuracy: 0.7188
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4925 - categorical_accuracy: 0.7935
 3008/10000 [========>.....................] - ETA: 0s - loss: 0.4930 - categorical_accuracy: 0.7819
 4160/10000 [===========>..................] - ETA: 0s - loss: 0.4980 - categorical_accuracy: 0.7793
 5344/10000 [===============>..............] - ETA: 0s - loss: 0.4910 - categorical_accuracy: 0.7809
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4935 - categorical_accuracy: 0.7808
 7712/10000 [======================>.......] - ETA: 0s - loss: 0.4921 - categorical_accuracy: 0.7812
 8928/10000 [=========================>....] - ETA: 0s - loss: 0.4918 - categorical_accuracy: 0.7817
10000/10000 [==============================] - 1s 65us/step - loss: 0.4924 - categorical_accuracy: 0.7834 - val_loss: 0.4637 - val_categorical_accuracy: 0.7898

Epoch 00007: val_loss improved from 0.46738 to 0.46365, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4619 - categorical_accuracy: 0.7812
 1248/10000 [==>...........................] - ETA: 0s - loss: 0.4898 - categorical_accuracy: 0.7901
 2560/10000 [======>.......................] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.7992
 3712/10000 [==========>...................] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.7966
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4861 - categorical_accuracy: 0.7882
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4894 - categorical_accuracy: 0.7876
 8064/10000 [=======================>......] - ETA: 0s - loss: 0.4872 - categorical_accuracy: 0.7875
 9632/10000 [===========================>..] - ETA: 0s - loss: 0.4884 - categorical_accuracy: 0.7858
10000/10000 [==============================] - 1s 57us/step - loss: 0.4887 - categorical_accuracy: 0.7854 - val_loss: 0.4640 - val_categorical_accuracy: 0.7901

Epoch 00008: val_loss did not improve from 0.46365
Epoch 9/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4294 - categorical_accuracy: 0.8125
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7782
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7837
 4928/10000 [=============>................] - ETA: 0s - loss: 0.4763 - categorical_accuracy: 0.7873
 6592/10000 [==================>...........] - ETA: 0s - loss: 0.4786 - categorical_accuracy: 0.7858
 8192/10000 [=======================>......] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7822
 9856/10000 [============================>.] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7820
10000/10000 [==============================] - 1s 50us/step - loss: 0.4821 - categorical_accuracy: 0.7821 - val_loss: 0.4636 - val_categorical_accuracy: 0.7890

Epoch 00009: val_loss improved from 0.46365 to 0.46360, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 10/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3640 - categorical_accuracy: 0.8750
 1536/10000 [===>..........................] - ETA: 0s - loss: 0.5004 - categorical_accuracy: 0.7650
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4903 - categorical_accuracy: 0.7777
 4800/10000 [=============>................] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7860
 6304/10000 [=================>............] - ETA: 0s - loss: 0.4774 - categorical_accuracy: 0.7881
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4818 - categorical_accuracy: 0.7834
 9344/10000 [===========================>..] - ETA: 0s - loss: 0.4815 - categorical_accuracy: 0.7847
10000/10000 [==============================] - 1s 52us/step - loss: 0.4814 - categorical_accuracy: 0.7844 - val_loss: 0.4589 - val_categorical_accuracy: 0.7891

Epoch 00010: val_loss improved from 0.46360 to 0.45886, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 11/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5776 - categorical_accuracy: 0.7188
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4876 - categorical_accuracy: 0.7722
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4858 - categorical_accuracy: 0.7797
 4928/10000 [=============>................] - ETA: 0s - loss: 0.4837 - categorical_accuracy: 0.7788
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7833
 8192/10000 [=======================>......] - ETA: 0s - loss: 0.4794 - categorical_accuracy: 0.7832
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7836
10000/10000 [==============================] - 0s 50us/step - loss: 0.4806 - categorical_accuracy: 0.7833 - val_loss: 0.4612 - val_categorical_accuracy: 0.7916

Epoch 00011: val_loss did not improve from 0.45886
Epoch 12/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3401 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4808 - categorical_accuracy: 0.7775
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4854 - categorical_accuracy: 0.7812
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4841 - categorical_accuracy: 0.7827
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4833 - categorical_accuracy: 0.7826
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4828 - categorical_accuracy: 0.7836
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7855
10000/10000 [==============================] - 1s 56us/step - loss: 0.4803 - categorical_accuracy: 0.7852 - val_loss: 0.4569 - val_categorical_accuracy: 0.7912

Epoch 00012: val_loss improved from 0.45886 to 0.45686, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 13/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3963 - categorical_accuracy: 0.8125
 1696/10000 [====>.........................] - ETA: 0s - loss: 0.4835 - categorical_accuracy: 0.7789
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4843 - categorical_accuracy: 0.7822
 4992/10000 [=============>................] - ETA: 0s - loss: 0.4890 - categorical_accuracy: 0.7790
 6592/10000 [==================>...........] - ETA: 0s - loss: 0.4887 - categorical_accuracy: 0.7785
 8288/10000 [=======================>......] - ETA: 0s - loss: 0.4856 - categorical_accuracy: 0.7838
 9856/10000 [============================>.] - ETA: 0s - loss: 0.4842 - categorical_accuracy: 0.7841
10000/10000 [==============================] - 0s 50us/step - loss: 0.4836 - categorical_accuracy: 0.7842 - val_loss: 0.4567 - val_categorical_accuracy: 0.7914

Epoch 00013: val_loss improved from 0.45686 to 0.45666, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 14/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3977 - categorical_accuracy: 0.8438
 1472/10000 [===>..........................] - ETA: 0s - loss: 0.5001 - categorical_accuracy: 0.7745
 3072/10000 [========>.....................] - ETA: 0s - loss: 0.4797 - categorical_accuracy: 0.7858
 4704/10000 [=============>................] - ETA: 0s - loss: 0.4762 - categorical_accuracy: 0.7849
 6272/10000 [=================>............] - ETA: 0s - loss: 0.4818 - categorical_accuracy: 0.7835
 7808/10000 [======================>.......] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.7850
 9472/10000 [===========================>..] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7884
10000/10000 [==============================] - 1s 51us/step - loss: 0.4759 - categorical_accuracy: 0.7878 - val_loss: 0.4551 - val_categorical_accuracy: 0.7936

Epoch 00014: val_loss improved from 0.45666 to 0.45507, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 15/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6233 - categorical_accuracy: 0.6875
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4581 - categorical_accuracy: 0.7959
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7919
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4766 - categorical_accuracy: 0.7844
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4730 - categorical_accuracy: 0.7856
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.7850
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4754 - categorical_accuracy: 0.7857
10000/10000 [==============================] - 0s 50us/step - loss: 0.4769 - categorical_accuracy: 0.7853 - val_loss: 0.4571 - val_categorical_accuracy: 0.7933

Epoch 00015: val_loss did not improve from 0.45507
Epoch 16/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4900 - categorical_accuracy: 0.8125
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4755 - categorical_accuracy: 0.7874
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4708 - categorical_accuracy: 0.7909
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4760 - categorical_accuracy: 0.7866
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4759 - categorical_accuracy: 0.7884
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4753 - categorical_accuracy: 0.7898
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7893
10000/10000 [==============================] - 1s 50us/step - loss: 0.4762 - categorical_accuracy: 0.7889 - val_loss: 0.4571 - val_categorical_accuracy: 0.7912

Epoch 00016: val_loss did not improve from 0.45507
Epoch 17/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4337 - categorical_accuracy: 0.8438
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4770 - categorical_accuracy: 0.7915
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4767 - categorical_accuracy: 0.7904
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7912
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.7925
 8064/10000 [=======================>......] - ETA: 0s - loss: 0.4721 - categorical_accuracy: 0.7877
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4746 - categorical_accuracy: 0.7868
10000/10000 [==============================] - 0s 50us/step - loss: 0.4751 - categorical_accuracy: 0.7864 - val_loss: 0.4589 - val_categorical_accuracy: 0.7916

Epoch 00017: val_loss did not improve from 0.45507
Epoch 18/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4036 - categorical_accuracy: 0.8438
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4745 - categorical_accuracy: 0.7868
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4767 - categorical_accuracy: 0.7927
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7947
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.7936
 7904/10000 [======================>.......] - ETA: 0s - loss: 0.4698 - categorical_accuracy: 0.7940
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7928
10000/10000 [==============================] - 1s 50us/step - loss: 0.4733 - categorical_accuracy: 0.7906 - val_loss: 0.4560 - val_categorical_accuracy: 0.7921

Epoch 00018: val_loss did not improve from 0.45507
Epoch 19/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4596 - categorical_accuracy: 0.8125
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.7927
 3360/10000 [=========>....................] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.7920
 4960/10000 [=============>................] - ETA: 0s - loss: 0.4760 - categorical_accuracy: 0.7869
 6592/10000 [==================>...........] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.7870
 8192/10000 [=======================>......] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7843
 9856/10000 [============================>.] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7843
10000/10000 [==============================] - 0s 49us/step - loss: 0.4746 - categorical_accuracy: 0.7849 - val_loss: 0.4546 - val_categorical_accuracy: 0.7934

Epoch 00019: val_loss improved from 0.45507 to 0.45462, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 20/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5095 - categorical_accuracy: 0.7812
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4753 - categorical_accuracy: 0.7768
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4771 - categorical_accuracy: 0.7822
 4704/10000 [=============>................] - ETA: 0s - loss: 0.4726 - categorical_accuracy: 0.7859
 6208/10000 [=================>............] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7850
 7808/10000 [======================>.......] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.7883
 9376/10000 [===========================>..] - ETA: 0s - loss: 0.4700 - categorical_accuracy: 0.7891
10000/10000 [==============================] - 1s 51us/step - loss: 0.4714 - categorical_accuracy: 0.7884 - val_loss: 0.4572 - val_categorical_accuracy: 0.7936

Epoch 00020: val_loss did not improve from 0.45462
Epoch 21/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4860 - categorical_accuracy: 0.6875
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4654 - categorical_accuracy: 0.7794
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4757 - categorical_accuracy: 0.7782
 4928/10000 [=============>................] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7867
 6624/10000 [==================>...........] - ETA: 0s - loss: 0.4708 - categorical_accuracy: 0.7867
 8224/10000 [=======================>......] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.7872
 9888/10000 [============================>.] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7888
10000/10000 [==============================] - 0s 50us/step - loss: 0.4712 - categorical_accuracy: 0.7887 - val_loss: 0.4540 - val_categorical_accuracy: 0.7941

Epoch 00021: val_loss improved from 0.45462 to 0.45398, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 22/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5446 - categorical_accuracy: 0.7812
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4874 - categorical_accuracy: 0.7856
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4881 - categorical_accuracy: 0.7857
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4845 - categorical_accuracy: 0.7884
 6240/10000 [=================>............] - ETA: 0s - loss: 0.4798 - categorical_accuracy: 0.7894
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4795 - categorical_accuracy: 0.7887
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.7888
10000/10000 [==============================] - 1s 50us/step - loss: 0.4776 - categorical_accuracy: 0.7889 - val_loss: 0.4533 - val_categorical_accuracy: 0.7928

Epoch 00022: val_loss improved from 0.45398 to 0.45332, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 23/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6638 - categorical_accuracy: 0.7500
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4796 - categorical_accuracy: 0.7832
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4809 - categorical_accuracy: 0.7794
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4838 - categorical_accuracy: 0.7798
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.7814
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.4770 - categorical_accuracy: 0.7859
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7880
10000/10000 [==============================] - 1s 50us/step - loss: 0.4732 - categorical_accuracy: 0.7879 - val_loss: 0.4496 - val_categorical_accuracy: 0.7930

Epoch 00023: val_loss improved from 0.45332 to 0.44958, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 24/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3569 - categorical_accuracy: 0.8750
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7950
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4627 - categorical_accuracy: 0.7942
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.7929
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7944
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4699 - categorical_accuracy: 0.7917
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.4724 - categorical_accuracy: 0.7884
10000/10000 [==============================] - 1s 51us/step - loss: 0.4729 - categorical_accuracy: 0.7892 - val_loss: 0.4551 - val_categorical_accuracy: 0.7939

Epoch 00024: val_loss did not improve from 0.44958
Epoch 25/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6873 - categorical_accuracy: 0.6875
 1536/10000 [===>..........................] - ETA: 0s - loss: 0.4644 - categorical_accuracy: 0.7949
 2816/10000 [=======>......................] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7908
 4032/10000 [===========>..................] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.7934
 5216/10000 [==============>...............] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.7947
 6784/10000 [===================>..........] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7941
 8352/10000 [========================>.....] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.7912
 9952/10000 [============================>.] - ETA: 0s - loss: 0.4736 - categorical_accuracy: 0.7887
10000/10000 [==============================] - 1s 55us/step - loss: 0.4735 - categorical_accuracy: 0.7890 - val_loss: 0.4507 - val_categorical_accuracy: 0.7938

Epoch 00025: val_loss did not improve from 0.44958
Epoch 26/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5591 - categorical_accuracy: 0.7500
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7843
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7803
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4768 - categorical_accuracy: 0.7819
 6528/10000 [==================>...........] - ETA: 0s - loss: 0.4745 - categorical_accuracy: 0.7852
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7844
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4721 - categorical_accuracy: 0.7860
10000/10000 [==============================] - 1s 50us/step - loss: 0.4721 - categorical_accuracy: 0.7866 - val_loss: 0.4500 - val_categorical_accuracy: 0.7928

Epoch 00026: val_loss did not improve from 0.44958
Epoch 27/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4452 - categorical_accuracy: 0.8125
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7843
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4768 - categorical_accuracy: 0.7812
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7891
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.7893
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7893
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.7897
10000/10000 [==============================] - 1s 50us/step - loss: 0.4694 - categorical_accuracy: 0.7903 - val_loss: 0.4483 - val_categorical_accuracy: 0.7941

Epoch 00027: val_loss improved from 0.44958 to 0.44835, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 28/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3879 - categorical_accuracy: 0.8438
 1408/10000 [===>..........................] - ETA: 0s - loss: 0.4901 - categorical_accuracy: 0.7720
 3040/10000 [========>.....................] - ETA: 0s - loss: 0.4822 - categorical_accuracy: 0.7872
 4672/10000 [=============>................] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.7905
 6272/10000 [=================>............] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.7889
 7904/10000 [======================>.......] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7877
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.4724 - categorical_accuracy: 0.7923
10000/10000 [==============================] - 1s 51us/step - loss: 0.4730 - categorical_accuracy: 0.7905 - val_loss: 0.4496 - val_categorical_accuracy: 0.7953

Epoch 00028: val_loss did not improve from 0.44835
Epoch 29/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4375 - categorical_accuracy: 0.8125
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4853 - categorical_accuracy: 0.7891
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.4673 - categorical_accuracy: 0.7988
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7989
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.7926
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.7936
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7933
10000/10000 [==============================] - 1s 51us/step - loss: 0.4719 - categorical_accuracy: 0.7931 - val_loss: 0.4512 - val_categorical_accuracy: 0.7954

Epoch 00029: val_loss did not improve from 0.44835
Epoch 30/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4505 - categorical_accuracy: 0.8125
 1504/10000 [===>..........................] - ETA: 0s - loss: 0.4660 - categorical_accuracy: 0.7839
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.7906
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.7891
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4668 - categorical_accuracy: 0.7897
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.7888
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.7908
10000/10000 [==============================] - 1s 50us/step - loss: 0.4691 - categorical_accuracy: 0.7901 - val_loss: 0.4500 - val_categorical_accuracy: 0.7941

Epoch 00030: val_loss did not improve from 0.44835
Epoch 31/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3384 - categorical_accuracy: 0.8438
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4457 - categorical_accuracy: 0.7975
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4593 - categorical_accuracy: 0.8005
 4992/10000 [=============>................] - ETA: 0s - loss: 0.4588 - categorical_accuracy: 0.7993
 6624/10000 [==================>...........] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.7973
 8288/10000 [=======================>......] - ETA: 0s - loss: 0.4608 - categorical_accuracy: 0.7956
 9888/10000 [============================>.] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7928
10000/10000 [==============================] - 0s 50us/step - loss: 0.4661 - categorical_accuracy: 0.7928 - val_loss: 0.4522 - val_categorical_accuracy: 0.7947

Epoch 00031: val_loss did not improve from 0.44835
Epoch 32/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4649 - categorical_accuracy: 0.8438
 1504/10000 [===>..........................] - ETA: 0s - loss: 0.4843 - categorical_accuracy: 0.7899
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7921
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7873
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7881
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4716 - categorical_accuracy: 0.7884
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7915
10000/10000 [==============================] - 1s 51us/step - loss: 0.4674 - categorical_accuracy: 0.7923 - val_loss: 0.4527 - val_categorical_accuracy: 0.7943

Epoch 00032: val_loss did not improve from 0.44835
Epoch 33/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4086 - categorical_accuracy: 0.8125
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.8036
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4659 - categorical_accuracy: 0.7967
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4613 - categorical_accuracy: 0.7949
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4597 - categorical_accuracy: 0.7976
 8064/10000 [=======================>......] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.7935
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7917
10000/10000 [==============================] - 1s 50us/step - loss: 0.4676 - categorical_accuracy: 0.7907 - val_loss: 0.4514 - val_categorical_accuracy: 0.7952

Epoch 00033: val_loss did not improve from 0.44835
Epoch 34/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.8125
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7915
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7837
 4992/10000 [=============>................] - ETA: 0s - loss: 0.4702 - categorical_accuracy: 0.7901
 6624/10000 [==================>...........] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7923
 8256/10000 [=======================>......] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7936
 9920/10000 [============================>.] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.7914
10000/10000 [==============================] - 1s 50us/step - loss: 0.4695 - categorical_accuracy: 0.7914 - val_loss: 0.4501 - val_categorical_accuracy: 0.7953

Epoch 00034: val_loss did not improve from 0.44835
Epoch 35/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3848 - categorical_accuracy: 0.8438
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4540 - categorical_accuracy: 0.7909
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4582 - categorical_accuracy: 0.7948
 4928/10000 [=============>................] - ETA: 0s - loss: 0.4565 - categorical_accuracy: 0.7985
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4631 - categorical_accuracy: 0.7945
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.4660 - categorical_accuracy: 0.7922
 9824/10000 [============================>.] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.7917
10000/10000 [==============================] - 0s 50us/step - loss: 0.4671 - categorical_accuracy: 0.7918 - val_loss: 0.4490 - val_categorical_accuracy: 0.7947

Epoch 00035: val_loss did not improve from 0.44835
Epoch 36/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4834 - categorical_accuracy: 0.7812
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.7887
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7960
 4928/10000 [=============>................] - ETA: 0s - loss: 0.4651 - categorical_accuracy: 0.7955
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4635 - categorical_accuracy: 0.7930
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.7916
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7915
10000/10000 [==============================] - 1s 50us/step - loss: 0.4672 - categorical_accuracy: 0.7912 - val_loss: 0.4493 - val_categorical_accuracy: 0.7934

Epoch 00036: val_loss did not improve from 0.44835
Epoch 37/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4098 - categorical_accuracy: 0.7812
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4566 - categorical_accuracy: 0.7937
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4583 - categorical_accuracy: 0.7912
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4616 - categorical_accuracy: 0.7919
 6336/10000 [==================>...........] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7885
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7893
 9536/10000 [===========================>..] - ETA: 0s - loss: 0.4643 - categorical_accuracy: 0.7922
10000/10000 [==============================] - 1s 51us/step - loss: 0.4623 - categorical_accuracy: 0.7931 - val_loss: 0.4508 - val_categorical_accuracy: 0.7949

Epoch 00037: val_loss did not improve from 0.44835
Epoch 38/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6477 - categorical_accuracy: 0.6562
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4688 - categorical_accuracy: 0.7812
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7803
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4698 - categorical_accuracy: 0.7848
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.7866
 7904/10000 [======================>.......] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7893
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7898
10000/10000 [==============================] - 1s 51us/step - loss: 0.4683 - categorical_accuracy: 0.7892 - val_loss: 0.4484 - val_categorical_accuracy: 0.7956

Epoch 00038: val_loss did not improve from 0.44835
Epoch 39/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6308 - categorical_accuracy: 0.6875
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4804 - categorical_accuracy: 0.7921
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4771 - categorical_accuracy: 0.7939
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4669 - categorical_accuracy: 0.7992
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7911
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.7897
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.7897
10000/10000 [==============================] - 1s 51us/step - loss: 0.4700 - categorical_accuracy: 0.7898 - val_loss: 0.4484 - val_categorical_accuracy: 0.7961

Epoch 00039: val_loss did not improve from 0.44835
Epoch 40/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4193 - categorical_accuracy: 0.8438
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4676 - categorical_accuracy: 0.7975
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4688 - categorical_accuracy: 0.7944
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7899
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.7917
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4679 - categorical_accuracy: 0.7899
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4717 - categorical_accuracy: 0.7875
10000/10000 [==============================] - 1s 50us/step - loss: 0.4693 - categorical_accuracy: 0.7894 - val_loss: 0.4494 - val_categorical_accuracy: 0.7953

Epoch 00040: val_loss did not improve from 0.44835
Epoch 41/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4596 - categorical_accuracy: 0.7812
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.7917
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.4688 - categorical_accuracy: 0.7925
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4685 - categorical_accuracy: 0.7921
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7911
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7897
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7917
10000/10000 [==============================] - 1s 51us/step - loss: 0.4694 - categorical_accuracy: 0.7909 - val_loss: 0.4505 - val_categorical_accuracy: 0.7949

Epoch 00041: val_loss did not improve from 0.44835
Epoch 42/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.8125
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4568 - categorical_accuracy: 0.7966
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4639 - categorical_accuracy: 0.7929
 4800/10000 [=============>................] - ETA: 0s - loss: 0.4628 - categorical_accuracy: 0.7971
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4681 - categorical_accuracy: 0.7930
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7913
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7894
10000/10000 [==============================] - 1s 51us/step - loss: 0.4721 - categorical_accuracy: 0.7892 - val_loss: 0.4503 - val_categorical_accuracy: 0.7950

Epoch 00042: val_loss did not improve from 0.44835
Epoch 43/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4356 - categorical_accuracy: 0.9062
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.7800
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4747 - categorical_accuracy: 0.7844
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.7869
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4672 - categorical_accuracy: 0.7910
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7910
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.7907
10000/10000 [==============================] - 1s 50us/step - loss: 0.4685 - categorical_accuracy: 0.7920 - val_loss: 0.4488 - val_categorical_accuracy: 0.7972

Epoch 00043: val_loss did not improve from 0.44835
Epoch 44/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4974 - categorical_accuracy: 0.8438
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4708 - categorical_accuracy: 0.7903
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4589 - categorical_accuracy: 0.7936
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4540 - categorical_accuracy: 0.7986
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4608 - categorical_accuracy: 0.7933
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4591 - categorical_accuracy: 0.7967
 9536/10000 [===========================>..] - ETA: 0s - loss: 0.4626 - categorical_accuracy: 0.7951
10000/10000 [==============================] - 1s 50us/step - loss: 0.4642 - categorical_accuracy: 0.7940 - val_loss: 0.4502 - val_categorical_accuracy: 0.7953

Epoch 00044: val_loss did not improve from 0.44835
Epoch 45/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5929 - categorical_accuracy: 0.7500
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4515 - categorical_accuracy: 0.7987
 3328/10000 [========>.....................] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7918
 4960/10000 [=============>................] - ETA: 0s - loss: 0.4631 - categorical_accuracy: 0.7937
 6624/10000 [==================>...........] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7930
 8288/10000 [=======================>......] - ETA: 0s - loss: 0.4685 - categorical_accuracy: 0.7907
 9952/10000 [============================>.] - ETA: 0s - loss: 0.4676 - categorical_accuracy: 0.7895
10000/10000 [==============================] - 1s 53us/step - loss: 0.4680 - categorical_accuracy: 0.7893 - val_loss: 0.4483 - val_categorical_accuracy: 0.7947

Epoch 00045: val_loss improved from 0.44835 to 0.44832, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 46/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5496 - categorical_accuracy: 0.8125
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4716 - categorical_accuracy: 0.7990
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.7949
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7948
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.7936
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.7924
 9760/10000 [============================>.] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7922
10000/10000 [==============================] - 0s 50us/step - loss: 0.4693 - categorical_accuracy: 0.7915 - val_loss: 0.4517 - val_categorical_accuracy: 0.7952

Epoch 00046: val_loss did not improve from 0.44832
Epoch 47/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4834 - categorical_accuracy: 0.8125
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4443 - categorical_accuracy: 0.8019
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4422 - categorical_accuracy: 0.8039
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4460 - categorical_accuracy: 0.8037
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4504 - categorical_accuracy: 0.7976
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4595 - categorical_accuracy: 0.7947
 9792/10000 [============================>.] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7925
10000/10000 [==============================] - 1s 50us/step - loss: 0.4640 - categorical_accuracy: 0.7920 - val_loss: 0.4528 - val_categorical_accuracy: 0.7955

Epoch 00047: val_loss did not improve from 0.44832
Epoch 48/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5733 - categorical_accuracy: 0.6562
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4708 - categorical_accuracy: 0.7861
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7873
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.7866
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7846
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.7908
 9824/10000 [============================>.] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7923
10000/10000 [==============================] - 1s 50us/step - loss: 0.4687 - categorical_accuracy: 0.7915 - val_loss: 0.4511 - val_categorical_accuracy: 0.7951

Epoch 00048: val_loss did not improve from 0.44832
Epoch 49/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5376 - categorical_accuracy: 0.8125
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7909
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.7941
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4692 - categorical_accuracy: 0.7905
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4699 - categorical_accuracy: 0.7902
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.4694 - categorical_accuracy: 0.7903
 9792/10000 [============================>.] - ETA: 0s - loss: 0.4693 - categorical_accuracy: 0.7897
10000/10000 [==============================] - 1s 51us/step - loss: 0.4685 - categorical_accuracy: 0.7901 - val_loss: 0.4503 - val_categorical_accuracy: 0.7972

Epoch 00049: val_loss did not improve from 0.44832
Epoch 50/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4548 - categorical_accuracy: 0.8438
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7975
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4647 - categorical_accuracy: 0.7909
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4637 - categorical_accuracy: 0.7906
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4672 - categorical_accuracy: 0.7894
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4666 - categorical_accuracy: 0.7885
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7906
10000/10000 [==============================] - 1s 50us/step - loss: 0.4655 - categorical_accuracy: 0.7908 - val_loss: 0.4476 - val_categorical_accuracy: 0.7956

Epoch 00050: val_loss improved from 0.44832 to 0.44756, saving model to dataset/weights/TrainedModel_PyKeras.h5
                         : Elapsed time for training with 10000 events: [1;31m26.9 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 10000 events: [1;31m2.82 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 5000 bkg: 5000
                         : #events: (unweighted) sig: 5000 bkg: 5000
                         : Training 50 Decision Trees ... patience please
                         : Elapsed time for training with 10000 events: [1;31m0.659 sec[0m         
BDT                      : [dataset] : Evaluation of BDT on training sample (10000 events)
                         : Elapsed time for evaluation of 10000 events: [1;31m0.045 sec[0m       
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_BDT.class.C[0m
                         : MVAOutput.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 4.487e-01
                         :    2 : mfchi2     : 2.459e-01
                         :    3 : gm2e       : 5.966e-02
                         :    4 : gm2p3cms   : 3.810e-02
                         :    5 : gmthetacms : 3.194e-02
                         :    6 : gm1p3cms   : 3.047e-02
                         :    7 : gm2e925    : 2.725e-02
                         :    8 : pi0p3cms   : 2.631e-02
                         :    9 : gm1e925    : 2.304e-02
                         :   10 : gm1eerror  : 2.079e-02
                         :   11 : gm1e       : 2.018e-02
                         :   12 : ediff      : 1.405e-02
                         :   13 : gm2eerror  : 1.361e-02
                         : --------------------------------------------
BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 2.028e-01
                         :    2 : gm2e       : 1.456e-01
                         :    3 : mfchi2     : 1.258e-01
                         :    4 : gm1e       : 7.344e-02
                         :    5 : gmthetacms : 6.874e-02
                         :    6 : ediff      : 6.830e-02
                         :    7 : gm1p3cms   : 6.331e-02
                         :    8 : gm2p3cms   : 5.981e-02
                         :    9 : gm1eerror  : 5.596e-02
                         :   10 : gm1e925    : 5.204e-02
                         :   11 : pi0p3cms   : 4.440e-02
                         :   12 : gm2eerror  : 3.970e-02
                         :   13 : gm2e925    : 0.000e+00
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (10000 events)
                         : Elapsed time for evaluation of 10000 events: [1;31m0.0412 sec[0m       
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.032698     0.98528   [     -3.3185      5.7307 ]
                         :   pi0p3cms:    0.031525     0.98939   [     -3.1739      5.7307 ]
                         :       gm1e:    0.037156     0.99648   [     -3.1688      5.7307 ]
                         :       gm2e:    0.019090     0.98641   [     -3.0473      5.7307 ]
                         :    gm1e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :    gm2e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :      ediff:    0.037446      1.0010   [     -3.2146      5.7307 ]
                         :  gm1eerror:    0.037890     0.97969   [     -2.9310      5.7307 ]
                         :  gm2eerror:    0.016566     0.98404   [     -2.8571      5.7307 ]
                         :   gm1p3cms:    0.035527     0.99481   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.017945     0.99035   [     -3.0355      5.7307 ]
                         : gmthetacms:   -0.015994     0.98551   [     -2.9852      5.7307 ]
                         :     mfchi2:  -0.0031458     0.98859   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.032698     0.98528   [     -3.3185      5.7307 ]
                         :   pi0p3cms:    0.031525     0.98939   [     -3.1739      5.7307 ]
                         :       gm1e:    0.037156     0.99648   [     -3.1688      5.7307 ]
                         :       gm2e:    0.019090     0.98641   [     -3.0473      5.7307 ]
                         :    gm1e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :    gm2e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :      ediff:    0.037446      1.0010   [     -3.2146      5.7307 ]
                         :  gm1eerror:    0.037890     0.97969   [     -2.9310      5.7307 ]
                         :  gm2eerror:    0.016566     0.98404   [     -2.8571      5.7307 ]
                         :   gm1p3cms:    0.035527     0.99481   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.017945     0.99035   [     -3.0355      5.7307 ]
                         : gmthetacms:   -0.015994     0.98551   [     -2.9852      5.7307 ]
                         :     mfchi2:  -0.0031458     0.98859   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59786     0.55669   [   0.0049119      4.9404 ]
                         :   pi0p3cms:     0.75579     0.74589   [    0.011479      6.9727 ]
                         :       gm1e:     0.44434     0.42427   [    0.063063      4.8358 ]
                         :       gm2e:     0.18021     0.17182   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95208    0.062272   [     0.22900      1.0000 ]
                         :    gm2e925:     0.95208    0.062272   [     0.22900      1.0000 ]
                         :      ediff:     0.26413     0.35410   [  1.2249e-05      4.7205 ]
                         :  gm1eerror:  0.00013800  0.00032775   [  2.1524e-06   0.0088087 ]
                         :  gm2eerror:  2.5697e-05  6.6469e-05   [  1.7209e-06   0.0013470 ]
                         :   gm1p3cms:     0.55537     0.57310   [    0.048464      6.8307 ]
                         :   gm2p3cms:     0.22241     0.22897   [    0.043817      2.6974 ]
                         : gmthetacms:     0.72740     0.52235   [    0.044029      3.0902 ]
                         :     mfchi2:      8.7758      11.427   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59786     0.55669   [   0.0049119      4.9404 ]
                         :   pi0p3cms:     0.75579     0.74589   [    0.011479      6.9727 ]
                         :       gm1e:     0.44434     0.42427   [    0.063063      4.8358 ]
                         :       gm2e:     0.18021     0.17182   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95208    0.062272   [     0.22900      1.0000 ]
                         :    gm2e925:     0.95208    0.062272   [     0.22900      1.0000 ]
                         :      ediff:     0.26413     0.35410   [  1.2249e-05      4.7205 ]
                         :  gm1eerror:  0.00013800  0.00032775   [  2.1524e-06   0.0088087 ]
                         :  gm2eerror:  2.5697e-05  6.6469e-05   [  1.7209e-06   0.0013470 ]
                         :   gm1p3cms:     0.55537     0.57310   [    0.048464      6.8307 ]
                         :   gm2p3cms:     0.22241     0.22897   [    0.043817      2.6974 ]
                         : gmthetacms:     0.72740     0.52235   [    0.044029      3.0902 ]
                         :     mfchi2:      8.7758      11.427   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       PyKeras        : 0.874
                         : dataset       BDT            : 0.867
                         : dataset       GTB            : 0.867
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              PyKeras        : 0.235 (0.285)       0.662 (0.676)      0.863 (0.869)
                         : dataset              BDT            : 0.245 (0.315)       0.645 (0.679)      0.850 (0.859)
                         : dataset              GTB            : 0.220 (0.511)       0.642 (0.768)      0.854 (0.899)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 10000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 10000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
