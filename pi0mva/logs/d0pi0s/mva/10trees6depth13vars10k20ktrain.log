DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : Booking method: [1mBDT[0m
                         : 
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 10000
                         : Signal     -- testing events             : 10000
                         : Signal     -- training and testing events: 20000
                         : Background -- training events            : 20000
                         : Background -- testing events             : 20000
                         : Background -- training and testing events: 40000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.976  +0.956  +0.757  -0.198  -0.198  +0.725    +0.768    +0.631   +0.938   +0.758     -0.684  -0.209
                         :   pi0p3cms:  +0.976   +1.000  +0.933  +0.740  -0.184  -0.184  +0.706    +0.773    +0.640   +0.961   +0.780     -0.669  -0.186
                         :       gm1e:  +0.956   +0.933  +1.000  +0.533  -0.135  -0.135  +0.895    +0.828    +0.441   +0.977   +0.545     -0.619  -0.189
                         :       gm2e:  +0.757   +0.740  +0.533  +1.000  -0.273  -0.273  +0.100    +0.379    +0.850   +0.534   +0.979     -0.561  -0.194
                         :    gm1e925:  -0.198   -0.184  -0.135  -0.273  +1.000  +1.000  -0.015    -0.092    -0.269   -0.128   -0.258     +0.084  -0.032
                         :    gm2e925:  -0.198   -0.184  -0.135  -0.273  +1.000  +1.000  -0.015    -0.092    -0.269   -0.128   -0.258     +0.084  -0.032
                         :      ediff:  +0.725   +0.706  +0.895  +0.100  -0.015  -0.015  +1.000    +0.774    +0.070   +0.867   +0.125     -0.432  -0.120
                         :  gm1eerror:  +0.768   +0.773  +0.828  +0.379  -0.092  -0.092  +0.774    +1.000    +0.356   +0.833   +0.403     -0.375  -0.116
                         :  gm2eerror:  +0.631   +0.640  +0.441  +0.850  -0.269  -0.269  +0.070    +0.356    +1.000   +0.457   +0.860     -0.360  -0.130
                         :   gm1p3cms:  +0.938   +0.961  +0.977  +0.534  -0.128  -0.128  +0.867    +0.833    +0.457   +1.000   +0.577     -0.613  -0.170
                         :   gm2p3cms:  +0.758   +0.780  +0.545  +0.979  -0.258  -0.258  +0.125    +0.403    +0.860   +0.577   +1.000     -0.562  -0.178
                         : gmthetacms:  -0.684   -0.669  -0.619  -0.561  +0.084  +0.084  -0.432    -0.375    -0.360   -0.613   -0.562     +1.000  +0.209
                         :     mfchi2:  -0.209   -0.186  -0.189  -0.194  -0.032  -0.032  -0.120    -0.116    -0.130   -0.170   -0.178     +0.209  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.977  +0.967  +0.647  -0.083  -0.083  +0.848    +0.805    +0.517   +0.950   +0.647     -0.700  -0.145
                         :   pi0p3cms:  +0.977   +1.000  +0.946  +0.634  -0.078  -0.078  +0.830    +0.806    +0.521   +0.969   +0.674     -0.709  -0.131
                         :       gm1e:  +0.967   +0.946  +1.000  +0.447  -0.082  -0.082  +0.952    +0.860    +0.357   +0.980   +0.458     -0.610  -0.140
                         :       gm2e:  +0.647   +0.634  +0.447  +1.000  -0.053  -0.053  +0.154    +0.331    +0.832   +0.446   +0.965     -0.526  -0.124
                         :    gm1e925:  -0.083   -0.078  -0.082  -0.053  +1.000  +1.000  -0.072    -0.059    -0.047   -0.077   -0.052     +0.056  +0.015
                         :    gm2e925:  -0.083   -0.078  -0.082  -0.053  +1.000  +1.000  -0.072    -0.059    -0.047   -0.077   -0.052     +0.056  +0.015
                         :      ediff:  +0.848   +0.830  +0.952  +0.154  -0.072  -0.072  +1.000    +0.837    +0.111   +0.931   +0.178     -0.494  -0.112
                         :  gm1eerror:  +0.805   +0.806  +0.860  +0.331  -0.059  -0.059  +0.837    +1.000    +0.287   +0.858   +0.347     -0.377  -0.113
                         :  gm2eerror:  +0.517   +0.521  +0.357  +0.832  -0.047  -0.047  +0.111    +0.287    +1.000   +0.365   +0.822     -0.322  -0.102
                         :   gm1p3cms:  +0.950   +0.969  +0.980  +0.446  -0.077  -0.077  +0.931    +0.858    +0.365   +1.000   +0.483     -0.622  -0.128
                         :   gm2p3cms:  +0.647   +0.674  +0.458  +0.965  -0.052  -0.052  +0.178    +0.347    +0.822   +0.483   +1.000     -0.571  -0.111
                         : gmthetacms:  -0.700   -0.709  -0.610  -0.526  +0.056  +0.056  -0.494    -0.377    -0.322   -0.622   -0.571     +1.000  +0.089
                         :     mfchi2:  -0.145   -0.131  -0.140  -0.124  +0.015  +0.015  -0.112    -0.113    -0.102   -0.128   -0.111     +0.089  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [1mTrain all methods[0m
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0032177     0.99829   [     -3.3422      5.7307 ]
                         :   pi0p3cms:   0.0032209     0.99822   [     -3.3444      5.7307 ]
                         :       gm1e:   0.0030945     0.99767   [     -3.3372      5.7307 ]
                         :       gm2e:   0.0034680     0.99944   [     -3.2052      5.7307 ]
                         :    gm1e925:     0.83314      2.2166   [     -3.3034      5.7307 ]
                         :    gm2e925:     0.83314      2.2166   [     -3.3034      5.7307 ]
                         :      ediff:   0.0031275     0.99764   [     -3.1653      5.7307 ]
                         :  gm1eerror:   0.0058158     0.99161   [     -3.1304      5.7307 ]
                         :  gm2eerror:   0.0047118     0.99602   [     -3.1299      5.7307 ]
                         :   gm1p3cms:   0.0031199     0.99760   [     -3.3408      5.7307 ]
                         :   gm2p3cms:   0.0034652     0.99923   [     -3.3146      5.7307 ]
                         : gmthetacms:   0.0034996     0.99917   [     -3.3450      5.7307 ]
                         :     mfchi2:   0.0068681     0.99262   [     -2.3072      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 2.877e-01
                         :    2 : gm1e       : 2.571e-01
                         :    3 : gmthetacms : 2.533e-01
                         :    4 : pi0p3cms   : 2.445e-01
                         :    5 : gm1eerror  : 2.413e-01
                         :    6 : gm2e       : 2.371e-01
                         :    7 : mfchi2     : 2.319e-01
                         :    8 : gm1p3cms   : 2.193e-01
                         :    9 : gm2eerror  : 2.177e-01
                         :   10 : gm2p3cms   : 1.974e-01
                         :   11 : ediff      : 1.343e-01
                         :   12 : gm1e925    : 7.483e-02
                         :   13 : gm2e925    : 7.483e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0032177     0.99829   [     -3.3422      5.7307 ]
                         :   pi0p3cms:   0.0032209     0.99822   [     -3.3444      5.7307 ]
                         :       gm1e:   0.0030945     0.99767   [     -3.3372      5.7307 ]
                         :       gm2e:   0.0034680     0.99944   [     -3.2052      5.7307 ]
                         :    gm1e925:     0.83314      2.2166   [     -3.3034      5.7307 ]
                         :    gm2e925:     0.83314      2.2166   [     -3.3034      5.7307 ]
                         :      ediff:   0.0031275     0.99764   [     -3.1653      5.7307 ]
                         :  gm1eerror:   0.0058158     0.99161   [     -3.1304      5.7307 ]
                         :  gm2eerror:   0.0047118     0.99602   [     -3.1299      5.7307 ]
                         :   gm1p3cms:   0.0031199     0.99760   [     -3.3408      5.7307 ]
                         :   gm2p3cms:   0.0034652     0.99923   [     -3.3146      5.7307 ]
                         : gmthetacms:   0.0034996     0.99917   [     -3.3450      5.7307 ]
                         :     mfchi2:   0.0068681     0.99262   [     -2.3072      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 30000 samples, validate on 30000 samples
Epoch 1/10

   32/30000 [..............................] - ETA: 2:38 - loss: 1.3898 - categorical_accuracy: 0.3438
 1632/30000 [>.............................] - ETA: 3s - loss: 0.8970 - categorical_accuracy: 0.5551  
 3200/30000 [==>...........................] - ETA: 2s - loss: 0.7792 - categorical_accuracy: 0.6212
 4800/30000 [===>..........................] - ETA: 1s - loss: 0.7300 - categorical_accuracy: 0.6550
 6368/30000 [=====>........................] - ETA: 1s - loss: 0.6763 - categorical_accuracy: 0.6812
 8032/30000 [=======>......................] - ETA: 1s - loss: 0.6523 - categorical_accuracy: 0.6956
 9696/30000 [========>.....................] - ETA: 0s - loss: 0.6277 - categorical_accuracy: 0.7087
11200/30000 [==========>...................] - ETA: 0s - loss: 0.6110 - categorical_accuracy: 0.7175
12864/30000 [===========>..................] - ETA: 0s - loss: 0.5972 - categorical_accuracy: 0.7252
14496/30000 [=============>................] - ETA: 0s - loss: 0.5868 - categorical_accuracy: 0.7305
16160/30000 [===============>..............] - ETA: 0s - loss: 0.5795 - categorical_accuracy: 0.7345
17888/30000 [================>.............] - ETA: 0s - loss: 0.5711 - categorical_accuracy: 0.7372
19520/30000 [==================>...........] - ETA: 0s - loss: 0.5618 - categorical_accuracy: 0.7425
21120/30000 [====================>.........] - ETA: 0s - loss: 0.5559 - categorical_accuracy: 0.7461
22720/30000 [=====================>........] - ETA: 0s - loss: 0.5505 - categorical_accuracy: 0.7487
24384/30000 [=======================>......] - ETA: 0s - loss: 0.5478 - categorical_accuracy: 0.7498
26048/30000 [=========================>....] - ETA: 0s - loss: 0.5424 - categorical_accuracy: 0.7532
27712/30000 [==========================>...] - ETA: 0s - loss: 0.5394 - categorical_accuracy: 0.7549
29376/30000 [============================>.] - ETA: 0s - loss: 0.5361 - categorical_accuracy: 0.7564
30000/30000 [==============================] - 2s 56us/step - loss: 0.5345 - categorical_accuracy: 0.7574 - val_loss: 0.4343 - val_categorical_accuracy: 0.8128

Epoch 00001: val_loss improved from inf to 0.43427, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/10

   32/30000 [..............................] - ETA: 1s - loss: 0.5442 - categorical_accuracy: 0.6875
 1568/30000 [>.............................] - ETA: 0s - loss: 0.4637 - categorical_accuracy: 0.7934
 3136/30000 [==>...........................] - ETA: 0s - loss: 0.4657 - categorical_accuracy: 0.7892
 4832/30000 [===>..........................] - ETA: 0s - loss: 0.4667 - categorical_accuracy: 0.7877
 6432/30000 [=====>........................] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7914
 8064/30000 [=======>......................] - ETA: 0s - loss: 0.4639 - categorical_accuracy: 0.7910
 9696/30000 [========>.....................] - ETA: 0s - loss: 0.4646 - categorical_accuracy: 0.7914
11360/30000 [==========>...................] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7924
12960/30000 [===========>..................] - ETA: 0s - loss: 0.4613 - categorical_accuracy: 0.7940
14656/30000 [=============>................] - ETA: 0s - loss: 0.4590 - categorical_accuracy: 0.7937
16128/30000 [===============>..............] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.7925
17760/30000 [================>.............] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.7926
19296/30000 [==================>...........] - ETA: 0s - loss: 0.4617 - categorical_accuracy: 0.7926
20992/30000 [===================>..........] - ETA: 0s - loss: 0.4616 - categorical_accuracy: 0.7934
22560/30000 [=====================>........] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.7939
24256/30000 [=======================>......] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.7941
25856/30000 [========================>.....] - ETA: 0s - loss: 0.4608 - categorical_accuracy: 0.7939
27488/30000 [==========================>...] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.7942
29088/30000 [============================>.] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.7936
30000/30000 [==============================] - 1s 50us/step - loss: 0.4611 - categorical_accuracy: 0.7935 - val_loss: 0.4340 - val_categorical_accuracy: 0.8151

Epoch 00002: val_loss improved from 0.43427 to 0.43401, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/10

   32/30000 [..............................] - ETA: 2s - loss: 0.5576 - categorical_accuracy: 0.8438
 1664/30000 [>.............................] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.7981
 3296/30000 [==>...........................] - ETA: 0s - loss: 0.4564 - categorical_accuracy: 0.8025
 4992/30000 [===>..........................] - ETA: 0s - loss: 0.4589 - categorical_accuracy: 0.8001
 6560/30000 [=====>........................] - ETA: 0s - loss: 0.4553 - categorical_accuracy: 0.8026
 8224/30000 [=======>......................] - ETA: 0s - loss: 0.4593 - categorical_accuracy: 0.7982
 9792/30000 [========>.....................] - ETA: 0s - loss: 0.4607 - categorical_accuracy: 0.7967
11488/30000 [==========>...................] - ETA: 0s - loss: 0.4603 - categorical_accuracy: 0.7969
13024/30000 [============>.................] - ETA: 0s - loss: 0.4579 - categorical_accuracy: 0.7970
14656/30000 [=============>................] - ETA: 0s - loss: 0.4600 - categorical_accuracy: 0.7969
16192/30000 [===============>..............] - ETA: 0s - loss: 0.4602 - categorical_accuracy: 0.7967
17760/30000 [================>.............] - ETA: 0s - loss: 0.4593 - categorical_accuracy: 0.7976
19296/30000 [==================>...........] - ETA: 0s - loss: 0.4594 - categorical_accuracy: 0.7966
20928/30000 [===================>..........] - ETA: 0s - loss: 0.4590 - categorical_accuracy: 0.7964
22528/30000 [=====================>........] - ETA: 0s - loss: 0.4570 - categorical_accuracy: 0.7977
24224/30000 [=======================>......] - ETA: 0s - loss: 0.4560 - categorical_accuracy: 0.7981
25856/30000 [========================>.....] - ETA: 0s - loss: 0.4549 - categorical_accuracy: 0.7983
27552/30000 [==========================>...] - ETA: 0s - loss: 0.4537 - categorical_accuracy: 0.7988
29088/30000 [============================>.] - ETA: 0s - loss: 0.4548 - categorical_accuracy: 0.7987
30000/30000 [==============================] - 1s 50us/step - loss: 0.4543 - categorical_accuracy: 0.7991 - val_loss: 0.4234 - val_categorical_accuracy: 0.8164

Epoch 00003: val_loss improved from 0.43401 to 0.42342, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/10

   32/30000 [..............................] - ETA: 2s - loss: 0.5027 - categorical_accuracy: 0.8125
 1536/30000 [>.............................] - ETA: 0s - loss: 0.4601 - categorical_accuracy: 0.7949
 3104/30000 [==>...........................] - ETA: 0s - loss: 0.4423 - categorical_accuracy: 0.8093
 4480/30000 [===>..........................] - ETA: 0s - loss: 0.4439 - categorical_accuracy: 0.8076
 5632/30000 [====>.........................] - ETA: 0s - loss: 0.4477 - categorical_accuracy: 0.8082
 7168/30000 [======>.......................] - ETA: 0s - loss: 0.4490 - categorical_accuracy: 0.8048
 8768/30000 [=======>......................] - ETA: 0s - loss: 0.4495 - categorical_accuracy: 0.8050
10432/30000 [=========>....................] - ETA: 0s - loss: 0.4520 - categorical_accuracy: 0.8041
12000/30000 [===========>..................] - ETA: 0s - loss: 0.4522 - categorical_accuracy: 0.8043
13632/30000 [============>.................] - ETA: 0s - loss: 0.4512 - categorical_accuracy: 0.8039
15168/30000 [==============>...............] - ETA: 0s - loss: 0.4528 - categorical_accuracy: 0.8023
16832/30000 [===============>..............] - ETA: 0s - loss: 0.4505 - categorical_accuracy: 0.8028
18464/30000 [=================>............] - ETA: 0s - loss: 0.4522 - categorical_accuracy: 0.8020
20160/30000 [===================>..........] - ETA: 0s - loss: 0.4520 - categorical_accuracy: 0.8013
21728/30000 [====================>.........] - ETA: 0s - loss: 0.4531 - categorical_accuracy: 0.8007
23424/30000 [======================>.......] - ETA: 0s - loss: 0.4514 - categorical_accuracy: 0.8020
24992/30000 [=======================>......] - ETA: 0s - loss: 0.4500 - categorical_accuracy: 0.8028
26656/30000 [=========================>....] - ETA: 0s - loss: 0.4508 - categorical_accuracy: 0.8025
28160/30000 [===========================>..] - ETA: 0s - loss: 0.4507 - categorical_accuracy: 0.8031
29824/30000 [============================>.] - ETA: 0s - loss: 0.4504 - categorical_accuracy: 0.8031
30000/30000 [==============================] - 2s 51us/step - loss: 0.4504 - categorical_accuracy: 0.8029 - val_loss: 0.4212 - val_categorical_accuracy: 0.8178

Epoch 00004: val_loss improved from 0.42342 to 0.42118, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/10

   32/30000 [..............................] - ETA: 1s - loss: 0.4063 - categorical_accuracy: 0.7500
 1504/30000 [>.............................] - ETA: 0s - loss: 0.4412 - categorical_accuracy: 0.7952
 3136/30000 [==>...........................] - ETA: 0s - loss: 0.4476 - categorical_accuracy: 0.7988
 4768/30000 [===>..........................] - ETA: 0s - loss: 0.4388 - categorical_accuracy: 0.8060
 6400/30000 [=====>........................] - ETA: 0s - loss: 0.4411 - categorical_accuracy: 0.8041
 8000/30000 [=======>......................] - ETA: 0s - loss: 0.4423 - categorical_accuracy: 0.8059
 9664/30000 [========>.....................] - ETA: 0s - loss: 0.4436 - categorical_accuracy: 0.8050
11264/30000 [==========>...................] - ETA: 0s - loss: 0.4434 - categorical_accuracy: 0.8046
12928/30000 [===========>..................] - ETA: 0s - loss: 0.4421 - categorical_accuracy: 0.8056
14496/30000 [=============>................] - ETA: 0s - loss: 0.4448 - categorical_accuracy: 0.8049
16064/30000 [===============>..............] - ETA: 0s - loss: 0.4468 - categorical_accuracy: 0.8044
17664/30000 [================>.............] - ETA: 0s - loss: 0.4452 - categorical_accuracy: 0.8047
19328/30000 [==================>...........] - ETA: 0s - loss: 0.4460 - categorical_accuracy: 0.8035
20928/30000 [===================>..........] - ETA: 0s - loss: 0.4461 - categorical_accuracy: 0.8040
22560/30000 [=====================>........] - ETA: 0s - loss: 0.4464 - categorical_accuracy: 0.8039
24160/30000 [=======================>......] - ETA: 0s - loss: 0.4458 - categorical_accuracy: 0.8042
25824/30000 [========================>.....] - ETA: 0s - loss: 0.4434 - categorical_accuracy: 0.8056
27424/30000 [==========================>...] - ETA: 0s - loss: 0.4441 - categorical_accuracy: 0.8048
29056/30000 [============================>.] - ETA: 0s - loss: 0.4455 - categorical_accuracy: 0.8041
30000/30000 [==============================] - 1s 50us/step - loss: 0.4450 - categorical_accuracy: 0.8046 - val_loss: 0.4184 - val_categorical_accuracy: 0.8190

Epoch 00005: val_loss improved from 0.42118 to 0.41841, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/10

   32/30000 [..............................] - ETA: 1s - loss: 0.4512 - categorical_accuracy: 0.7500
 1568/30000 [>.............................] - ETA: 0s - loss: 0.4726 - categorical_accuracy: 0.7978
 3136/30000 [==>...........................] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.8010
 4800/30000 [===>..........................] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.8027
 6400/30000 [=====>........................] - ETA: 0s - loss: 0.4580 - categorical_accuracy: 0.8014
 8064/30000 [=======>......................] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.8000
 9696/30000 [========>.....................] - ETA: 0s - loss: 0.4541 - categorical_accuracy: 0.8016
11392/30000 [==========>...................] - ETA: 0s - loss: 0.4527 - categorical_accuracy: 0.8027
12992/30000 [===========>..................] - ETA: 0s - loss: 0.4514 - categorical_accuracy: 0.8033
14656/30000 [=============>................] - ETA: 0s - loss: 0.4458 - categorical_accuracy: 0.8051
16224/30000 [===============>..............] - ETA: 0s - loss: 0.4433 - categorical_accuracy: 0.8064
17888/30000 [================>.............] - ETA: 0s - loss: 0.4429 - categorical_accuracy: 0.8065
19488/30000 [==================>...........] - ETA: 0s - loss: 0.4447 - categorical_accuracy: 0.8051
21120/30000 [====================>.........] - ETA: 0s - loss: 0.4436 - categorical_accuracy: 0.8055
22720/30000 [=====================>........] - ETA: 0s - loss: 0.4423 - categorical_accuracy: 0.8064
24416/30000 [=======================>......] - ETA: 0s - loss: 0.4417 - categorical_accuracy: 0.8074
25984/30000 [========================>.....] - ETA: 0s - loss: 0.4408 - categorical_accuracy: 0.8083
27648/30000 [==========================>...] - ETA: 0s - loss: 0.4420 - categorical_accuracy: 0.8074
29056/30000 [============================>.] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8082
30000/30000 [==============================] - 2s 51us/step - loss: 0.4416 - categorical_accuracy: 0.8078 - val_loss: 0.4166 - val_categorical_accuracy: 0.8200

Epoch 00006: val_loss improved from 0.41841 to 0.41655, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/10

   32/30000 [..............................] - ETA: 2s - loss: 0.4880 - categorical_accuracy: 0.8125
 1600/30000 [>.............................] - ETA: 0s - loss: 0.4087 - categorical_accuracy: 0.8256
 3200/30000 [==>...........................] - ETA: 0s - loss: 0.4349 - categorical_accuracy: 0.8109
 4800/30000 [===>..........................] - ETA: 0s - loss: 0.4323 - categorical_accuracy: 0.8127
 6400/30000 [=====>........................] - ETA: 0s - loss: 0.4348 - categorical_accuracy: 0.8108
 8064/30000 [=======>......................] - ETA: 0s - loss: 0.4374 - categorical_accuracy: 0.8083
 9728/30000 [========>.....................] - ETA: 0s - loss: 0.4368 - categorical_accuracy: 0.8079
11392/30000 [==========>...................] - ETA: 0s - loss: 0.4412 - categorical_accuracy: 0.8052
13024/30000 [============>.................] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8061
14624/30000 [=============>................] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8068
16256/30000 [===============>..............] - ETA: 0s - loss: 0.4402 - categorical_accuracy: 0.8079
17856/30000 [================>.............] - ETA: 0s - loss: 0.4395 - categorical_accuracy: 0.8082
19456/30000 [==================>...........] - ETA: 0s - loss: 0.4396 - categorical_accuracy: 0.8084
21024/30000 [====================>.........] - ETA: 0s - loss: 0.4393 - categorical_accuracy: 0.8090
22624/30000 [=====================>........] - ETA: 0s - loss: 0.4388 - categorical_accuracy: 0.8087
24256/30000 [=======================>......] - ETA: 0s - loss: 0.4398 - categorical_accuracy: 0.8082
25888/30000 [========================>.....] - ETA: 0s - loss: 0.4405 - categorical_accuracy: 0.8076
27520/30000 [==========================>...] - ETA: 0s - loss: 0.4399 - categorical_accuracy: 0.8078
29120/30000 [============================>.] - ETA: 0s - loss: 0.4395 - categorical_accuracy: 0.8083
30000/30000 [==============================] - 1s 50us/step - loss: 0.4397 - categorical_accuracy: 0.8083 - val_loss: 0.4207 - val_categorical_accuracy: 0.8179

Epoch 00007: val_loss did not improve from 0.41655
Epoch 8/10

   32/30000 [..............................] - ETA: 1s - loss: 0.4227 - categorical_accuracy: 0.8125
 1600/30000 [>.............................] - ETA: 0s - loss: 0.4466 - categorical_accuracy: 0.8075
 3264/30000 [==>...........................] - ETA: 0s - loss: 0.4442 - categorical_accuracy: 0.8076
 4896/30000 [===>..........................] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8096
 6528/30000 [=====>........................] - ETA: 0s - loss: 0.4404 - categorical_accuracy: 0.8100
 8128/30000 [=======>......................] - ETA: 0s - loss: 0.4397 - categorical_accuracy: 0.8089
 9760/30000 [========>.....................] - ETA: 0s - loss: 0.4419 - categorical_accuracy: 0.8081
11328/30000 [==========>...................] - ETA: 0s - loss: 0.4409 - categorical_accuracy: 0.8072
12992/30000 [===========>..................] - ETA: 0s - loss: 0.4402 - categorical_accuracy: 0.8087
14560/30000 [=============>................] - ETA: 0s - loss: 0.4388 - categorical_accuracy: 0.8089
16224/30000 [===============>..............] - ETA: 0s - loss: 0.4407 - categorical_accuracy: 0.8086
17824/30000 [================>.............] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8077
19456/30000 [==================>...........] - ETA: 0s - loss: 0.4419 - categorical_accuracy: 0.8076
21120/30000 [====================>.........] - ETA: 0s - loss: 0.4402 - categorical_accuracy: 0.8080
22784/30000 [=====================>........] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8069
24352/30000 [=======================>......] - ETA: 0s - loss: 0.4414 - categorical_accuracy: 0.8072
26016/30000 [=========================>....] - ETA: 0s - loss: 0.4409 - categorical_accuracy: 0.8072
27584/30000 [==========================>...] - ETA: 0s - loss: 0.4406 - categorical_accuracy: 0.8074
29280/30000 [============================>.] - ETA: 0s - loss: 0.4393 - categorical_accuracy: 0.8082
30000/30000 [==============================] - 1s 50us/step - loss: 0.4398 - categorical_accuracy: 0.8083 - val_loss: 0.4135 - val_categorical_accuracy: 0.8207

Epoch 00008: val_loss improved from 0.41655 to 0.41352, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 9/10

   32/30000 [..............................] - ETA: 2s - loss: 0.7892 - categorical_accuracy: 0.5625
 1536/30000 [>.............................] - ETA: 0s - loss: 0.4667 - categorical_accuracy: 0.7923
 3136/30000 [==>...........................] - ETA: 0s - loss: 0.4496 - categorical_accuracy: 0.8023
 4704/30000 [===>..........................] - ETA: 0s - loss: 0.4462 - categorical_accuracy: 0.8053
 6336/30000 [=====>........................] - ETA: 0s - loss: 0.4446 - categorical_accuracy: 0.8041
 7936/30000 [======>.......................] - ETA: 0s - loss: 0.4411 - categorical_accuracy: 0.8054
 9568/30000 [========>.....................] - ETA: 0s - loss: 0.4434 - categorical_accuracy: 0.8051
11200/30000 [==========>...................] - ETA: 0s - loss: 0.4471 - categorical_accuracy: 0.8042
12736/30000 [===========>..................] - ETA: 0s - loss: 0.4443 - categorical_accuracy: 0.8059
14208/30000 [=============>................] - ETA: 0s - loss: 0.4420 - categorical_accuracy: 0.8071
15872/30000 [==============>...............] - ETA: 0s - loss: 0.4415 - categorical_accuracy: 0.8075
17536/30000 [================>.............] - ETA: 0s - loss: 0.4419 - categorical_accuracy: 0.8075
19168/30000 [==================>...........] - ETA: 0s - loss: 0.4414 - categorical_accuracy: 0.8072
20800/30000 [===================>..........] - ETA: 0s - loss: 0.4407 - categorical_accuracy: 0.8074
22432/30000 [=====================>........] - ETA: 0s - loss: 0.4395 - categorical_accuracy: 0.8076
24064/30000 [=======================>......] - ETA: 0s - loss: 0.4388 - categorical_accuracy: 0.8078
25664/30000 [========================>.....] - ETA: 0s - loss: 0.4392 - categorical_accuracy: 0.8081
27296/30000 [==========================>...] - ETA: 0s - loss: 0.4385 - categorical_accuracy: 0.8084
28928/30000 [===========================>..] - ETA: 0s - loss: 0.4384 - categorical_accuracy: 0.8082
30000/30000 [==============================] - 2s 50us/step - loss: 0.4377 - categorical_accuracy: 0.8081 - val_loss: 0.4133 - val_categorical_accuracy: 0.8210

Epoch 00009: val_loss improved from 0.41352 to 0.41328, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 10/10

   32/30000 [..............................] - ETA: 2s - loss: 0.4101 - categorical_accuracy: 0.8125
 1536/30000 [>.............................] - ETA: 0s - loss: 0.4577 - categorical_accuracy: 0.8021
 3200/30000 [==>...........................] - ETA: 0s - loss: 0.4385 - categorical_accuracy: 0.8097
 4800/30000 [===>..........................] - ETA: 0s - loss: 0.4409 - categorical_accuracy: 0.8060
 6432/30000 [=====>........................] - ETA: 0s - loss: 0.4447 - categorical_accuracy: 0.8016
 8064/30000 [=======>......................] - ETA: 0s - loss: 0.4459 - categorical_accuracy: 0.7996
 9728/30000 [========>.....................] - ETA: 0s - loss: 0.4468 - categorical_accuracy: 0.8007
11328/30000 [==========>...................] - ETA: 0s - loss: 0.4445 - categorical_accuracy: 0.8022
12992/30000 [===========>..................] - ETA: 0s - loss: 0.4411 - categorical_accuracy: 0.8060
14528/30000 [=============>................] - ETA: 0s - loss: 0.4401 - categorical_accuracy: 0.8065
16192/30000 [===============>..............] - ETA: 0s - loss: 0.4387 - categorical_accuracy: 0.8072
17824/30000 [================>.............] - ETA: 0s - loss: 0.4381 - categorical_accuracy: 0.8086
19456/30000 [==================>...........] - ETA: 0s - loss: 0.4391 - categorical_accuracy: 0.8086
21088/30000 [====================>.........] - ETA: 0s - loss: 0.4387 - categorical_accuracy: 0.8091
22656/30000 [=====================>........] - ETA: 0s - loss: 0.4377 - categorical_accuracy: 0.8098
24320/30000 [=======================>......] - ETA: 0s - loss: 0.4379 - categorical_accuracy: 0.8097
25888/30000 [========================>.....] - ETA: 0s - loss: 0.4374 - categorical_accuracy: 0.8100
27456/30000 [==========================>...] - ETA: 0s - loss: 0.4371 - categorical_accuracy: 0.8102
28960/30000 [===========================>..] - ETA: 0s - loss: 0.4371 - categorical_accuracy: 0.8108
30000/30000 [==============================] - 1s 50us/step - loss: 0.4368 - categorical_accuracy: 0.8111 - val_loss: 0.4111 - val_categorical_accuracy: 0.8215

Epoch 00010: val_loss improved from 0.41328 to 0.41110, saving model to dataset/weights/TrainedModel_PyKeras.h5
                         : Elapsed time for training with 30000 events: [1;31m16.2 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 30000 events: [1;31m9.92 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 15000 bkg: 15000
                         : #events: (unweighted) sig: 10000 bkg: 20000
                         : Training 10 Decision Trees ... patience please
                         : Elapsed time for training with 30000 events: [1;31m0.824 sec[0m         
BDT                      : [dataset] : Evaluation of BDT on training sample (30000 events)
                         : Elapsed time for evaluation of 30000 events: [1;31m0.0224 sec[0m       
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_BDT.class.C[0m
                         : MVAOutput.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.087e-01
                         :    2 : mfchi2     : 2.572e-01
                         :    3 : gm2e       : 5.872e-02
                         :    4 : gm1e925    : 2.444e-02
                         :    5 : gm2p3cms   : 2.424e-02
                         :    6 : gm1p3cms   : 2.356e-02
                         :    7 : pi0p3cms   : 2.210e-02
                         :    8 : gmthetacms : 2.164e-02
                         :    9 : gm2e925    : 2.086e-02
                         :   10 : gm1e       : 1.080e-02
                         :   11 : gm1eerror  : 9.694e-03
                         :   12 : ediff      : 9.478e-03
                         :   13 : gm2eerror  : 8.621e-03
                         : --------------------------------------------
BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 3.528e-01
                         :    2 : gm2e       : 2.501e-01
                         :    3 : mfchi2     : 2.375e-01
                         :    4 : gm1e925    : 6.706e-02
                         :    5 : gm2p3cms   : 2.770e-02
                         :    6 : pi0p3cms   : 2.581e-02
                         :    7 : gm1e       : 1.480e-02
                         :    8 : gm1p3cms   : 1.227e-02
                         :    9 : gmthetacms : 1.194e-02
                         :   10 : gm2e925    : 0.000e+00
                         :   11 : ediff      : 0.000e+00
                         :   12 : gm1eerror  : 0.000e+00
                         :   13 : gm2eerror  : 0.000e+00
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (30000 events)
                         : Elapsed time for evaluation of 30000 events: [1;31m0.02 sec[0m       
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.017349     0.99433   [     -3.7731      5.7307 ]
                         :   pi0p3cms:    0.016401     0.99502   [     -3.3733      5.7307 ]
                         :       gm1e:    0.016638     0.99449   [     -3.2397      5.7307 ]
                         :       gm2e:    0.016359     0.99670   [     -3.2155      5.7307 ]
                         :    gm1e925:     0.81258      2.1988   [     -3.8549      5.7307 ]
                         :    gm2e925:     0.81258      2.1988   [     -3.8549      5.7307 ]
                         :      ediff:    0.015698     0.99208   [     -3.1665      5.7307 ]
                         :  gm1eerror:    0.019081     0.98569   [     -3.1305      5.7307 ]
                         :  gm2eerror:    0.019114     0.99104   [     -3.0225      5.7307 ]
                         :   gm1p3cms:    0.015875     0.99356   [     -3.2709      5.7307 ]
                         :   gm2p3cms:    0.016432     0.99685   [     -3.2558      5.7307 ]
                         : gmthetacms:   -0.010199     0.99455   [     -3.1398      5.7307 ]
                         :     mfchi2:  -0.0028632     0.99130   [     -2.3072      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.017349     0.99433   [     -3.7731      5.7307 ]
                         :   pi0p3cms:    0.016401     0.99502   [     -3.3733      5.7307 ]
                         :       gm1e:    0.016638     0.99449   [     -3.2397      5.7307 ]
                         :       gm2e:    0.016359     0.99670   [     -3.2155      5.7307 ]
                         :    gm1e925:     0.81258      2.1988   [     -3.8549      5.7307 ]
                         :    gm2e925:     0.81258      2.1988   [     -3.8549      5.7307 ]
                         :      ediff:    0.015698     0.99208   [     -3.1665      5.7307 ]
                         :  gm1eerror:    0.019081     0.98569   [     -3.1305      5.7307 ]
                         :  gm2eerror:    0.019114     0.99104   [     -3.0225      5.7307 ]
                         :   gm1p3cms:    0.015875     0.99356   [     -3.2709      5.7307 ]
                         :   gm2p3cms:    0.016432     0.99685   [     -3.2558      5.7307 ]
                         : gmthetacms:   -0.010199     0.99455   [     -3.1398      5.7307 ]
                         :     mfchi2:  -0.0028632     0.99130   [     -2.3072      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.51036     0.49773   [   0.0024752      4.9404 ]
                         :   pi0p3cms:     0.64889     0.66437   [   0.0073237      7.1892 ]
                         :       gm1e:     0.38273     0.37615   [    0.062132      4.8358 ]
                         :       gm2e:     0.15843     0.15133   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95107    0.062328   [     0.19151      1.0000 ]
                         :    gm2e925:     0.95107    0.062328   [     0.19151      1.0000 ]
                         :      ediff:     0.22430     0.31066   [  2.2352e-07      4.7205 ]
                         :  gm1eerror:  0.00010748  0.00028235   [  1.8278e-06    0.011124 ]
                         :  gm2eerror:  2.0396e-05  5.6785e-05   [  1.7062e-06   0.0015329 ]
                         :   gm1p3cms:     0.47863     0.50646   [    0.047244      6.9342 ]
                         :   gm2p3cms:     0.19574     0.20292   [    0.043337      2.6974 ]
                         : gmthetacms:     0.81359     0.54802   [    0.044029      3.0902 ]
                         :     mfchi2:      10.419      12.179   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.51036     0.49773   [   0.0024752      4.9404 ]
                         :   pi0p3cms:     0.64889     0.66437   [   0.0073237      7.1892 ]
                         :       gm1e:     0.38273     0.37615   [    0.062132      4.8358 ]
                         :       gm2e:     0.15843     0.15133   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95107    0.062328   [     0.19151      1.0000 ]
                         :    gm2e925:     0.95107    0.062328   [     0.19151      1.0000 ]
                         :      ediff:     0.22430     0.31066   [  2.2352e-07      4.7205 ]
                         :  gm1eerror:  0.00010748  0.00028235   [  1.8278e-06    0.011124 ]
                         :  gm2eerror:  2.0396e-05  5.6785e-05   [  1.7062e-06   0.0015329 ]
                         :   gm1p3cms:     0.47863     0.50646   [    0.047244      6.9342 ]
                         :   gm2p3cms:     0.19574     0.20292   [    0.043337      2.6974 ]
                         : gmthetacms:     0.81359     0.54802   [    0.044029      3.0902 ]
                         :     mfchi2:      10.419      12.179   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       GTB            : 0.872
                         : dataset       PyKeras        : 0.872
                         : dataset       BDT            : 0.865
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              GTB            : 0.265 (0.394)       0.658 (0.703)      0.858 (0.874)
                         : dataset              PyKeras        : 0.263 (0.266)       0.664 (0.662)      0.855 (0.858)
                         : dataset              BDT            : 0.000 (0.000)       0.644 (0.646)      0.848 (0.851)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 30000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 30000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
