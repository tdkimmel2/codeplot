DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : Booking method: [1mBDT[0m
                         : 
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 20000
                         : Signal     -- testing events             : 20000
                         : Signal     -- training and testing events: 40000
                         : Background -- training events            : 20000
                         : Background -- testing events             : 20000
                         : Background -- training and testing events: 40000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.976  +0.957  +0.757  -0.194  -0.194  +0.731    +0.775    +0.648   +0.939   +0.759     -0.684  -0.209
                         :   pi0p3cms:  +0.976   +1.000  +0.934  +0.740  -0.179  -0.179  +0.712    +0.780    +0.655   +0.962   +0.780     -0.669  -0.187
                         :       gm1e:  +0.957   +0.934  +1.000  +0.536  -0.137  -0.137  +0.897    +0.836    +0.457   +0.977   +0.548     -0.618  -0.190
                         :       gm2e:  +0.757   +0.740  +0.536  +1.000  -0.261  -0.261  +0.108    +0.383    +0.865   +0.537   +0.978     -0.564  -0.195
                         :    gm1e925:  -0.194   -0.179  -0.137  -0.261  +1.000  +1.000  -0.024    -0.102    -0.262   -0.128   -0.243     +0.082  -0.032
                         :    gm2e925:  -0.194   -0.179  -0.137  -0.261  +1.000  +1.000  -0.024    -0.102    -0.262   -0.128   -0.243     +0.082  -0.032
                         :      ediff:  +0.731   +0.712  +0.897  +0.108  -0.024  -0.024  +1.000    +0.784    +0.085   +0.870   +0.134     -0.433  -0.122
                         :  gm1eerror:  +0.775   +0.780  +0.836  +0.383  -0.102  -0.102  +0.784    +1.000    +0.368   +0.840   +0.408     -0.380  -0.117
                         :  gm2eerror:  +0.648   +0.655  +0.457  +0.865  -0.262  -0.262  +0.085    +0.368    +1.000   +0.473   +0.873     -0.375  -0.131
                         :   gm1p3cms:  +0.939   +0.962  +0.977  +0.537  -0.128  -0.128  +0.870    +0.840    +0.473   +1.000   +0.580     -0.612  -0.172
                         :   gm2p3cms:  +0.759   +0.780  +0.548  +0.978  -0.243  -0.243  +0.134    +0.408    +0.873   +0.580   +1.000     -0.565  -0.179
                         : gmthetacms:  -0.684   -0.669  -0.618  -0.564  +0.082  +0.082  -0.433    -0.380    -0.375   -0.612   -0.565     +1.000  +0.209
                         :     mfchi2:  -0.209   -0.187  -0.190  -0.195  -0.032  -0.032  -0.122    -0.117    -0.131   -0.172   -0.179     +0.209  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.977  +0.967  +0.647  -0.083  -0.083  +0.848    +0.805    +0.517   +0.950   +0.647     -0.700  -0.145
                         :   pi0p3cms:  +0.977   +1.000  +0.946  +0.634  -0.078  -0.078  +0.830    +0.806    +0.521   +0.969   +0.674     -0.709  -0.131
                         :       gm1e:  +0.967   +0.946  +1.000  +0.447  -0.082  -0.082  +0.952    +0.860    +0.357   +0.980   +0.458     -0.610  -0.140
                         :       gm2e:  +0.647   +0.634  +0.447  +1.000  -0.053  -0.053  +0.154    +0.331    +0.832   +0.446   +0.965     -0.526  -0.124
                         :    gm1e925:  -0.083   -0.078  -0.082  -0.053  +1.000  +1.000  -0.072    -0.059    -0.047   -0.077   -0.052     +0.056  +0.015
                         :    gm2e925:  -0.083   -0.078  -0.082  -0.053  +1.000  +1.000  -0.072    -0.059    -0.047   -0.077   -0.052     +0.056  +0.015
                         :      ediff:  +0.848   +0.830  +0.952  +0.154  -0.072  -0.072  +1.000    +0.837    +0.111   +0.931   +0.178     -0.494  -0.112
                         :  gm1eerror:  +0.805   +0.806  +0.860  +0.331  -0.059  -0.059  +0.837    +1.000    +0.287   +0.858   +0.347     -0.377  -0.113
                         :  gm2eerror:  +0.517   +0.521  +0.357  +0.832  -0.047  -0.047  +0.111    +0.287    +1.000   +0.365   +0.822     -0.322  -0.102
                         :   gm1p3cms:  +0.950   +0.969  +0.980  +0.446  -0.077  -0.077  +0.931    +0.858    +0.365   +1.000   +0.483     -0.622  -0.128
                         :   gm2p3cms:  +0.647   +0.674  +0.458  +0.965  -0.052  -0.052  +0.178    +0.347    +0.822   +0.483   +1.000     -0.571  -0.111
                         : gmthetacms:  -0.700   -0.709  -0.610  -0.526  +0.056  +0.056  -0.494    -0.377    -0.322   -0.622   -0.571     +1.000  +0.089
                         :     mfchi2:  -0.145   -0.131  -0.140  -0.124  +0.015  +0.015  -0.112    -0.113    -0.102   -0.128   -0.111     +0.089  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [1mTrain all methods[0m
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0033258     0.99814   [     -3.3275      5.7307 ]
                         :   pi0p3cms:   0.0033076     0.99805   [     -3.3296      5.7307 ]
                         :       gm1e:   0.0031683     0.99745   [     -3.3229      5.7307 ]
                         :       gm2e:   0.0035142     0.99903   [     -3.1871      5.7307 ]
                         :    gm1e925:     0.72790      2.1194   [     -3.2941      5.7307 ]
                         :    gm2e925:     0.72790      2.1194   [     -3.2941      5.7307 ]
                         :      ediff:   0.0031712     0.99739   [     -3.1700      5.7307 ]
                         :  gm1eerror:   0.0053248     0.99302   [     -3.1202      5.7307 ]
                         :  gm2eerror:   0.0046378     0.99612   [     -3.1196      5.7307 ]
                         :   gm1p3cms:   0.0032027     0.99745   [     -3.3266      5.7307 ]
                         :   gm2p3cms:   0.0036406     0.99949   [     -3.3022      5.7307 ]
                         : gmthetacms:   0.0036587     0.99955   [     -3.3294      5.7307 ]
                         :     mfchi2:   0.0076186     0.99084   [     -2.2435      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 2.862e-01
                         :    2 : gm1e       : 2.546e-01
                         :    3 : gmthetacms : 2.516e-01
                         :    4 : pi0p3cms   : 2.421e-01
                         :    5 : gm1eerror  : 2.395e-01
                         :    6 : gm2e       : 2.376e-01
                         :    7 : mfchi2     : 2.310e-01
                         :    8 : gm2eerror  : 2.189e-01
                         :    9 : gm1p3cms   : 2.168e-01
                         :   10 : gm2p3cms   : 1.980e-01
                         :   11 : ediff      : 1.327e-01
                         :   12 : gm1e925    : 7.559e-02
                         :   13 : gm2e925    : 7.559e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0033258     0.99814   [     -3.3275      5.7307 ]
                         :   pi0p3cms:   0.0033076     0.99805   [     -3.3296      5.7307 ]
                         :       gm1e:   0.0031683     0.99745   [     -3.3229      5.7307 ]
                         :       gm2e:   0.0035142     0.99903   [     -3.1871      5.7307 ]
                         :    gm1e925:     0.72790      2.1194   [     -3.2941      5.7307 ]
                         :    gm2e925:     0.72790      2.1194   [     -3.2941      5.7307 ]
                         :      ediff:   0.0031712     0.99739   [     -3.1700      5.7307 ]
                         :  gm1eerror:   0.0053248     0.99302   [     -3.1202      5.7307 ]
                         :  gm2eerror:   0.0046378     0.99612   [     -3.1196      5.7307 ]
                         :   gm1p3cms:   0.0032027     0.99745   [     -3.3266      5.7307 ]
                         :   gm2p3cms:   0.0036406     0.99949   [     -3.3022      5.7307 ]
                         : gmthetacms:   0.0036587     0.99955   [     -3.3294      5.7307 ]
                         :     mfchi2:   0.0076186     0.99084   [     -2.2435      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 40000 samples, validate on 40000 samples
Epoch 1/10

   32/40000 [..............................] - ETA: 3:45 - loss: 1.3404 - categorical_accuracy: 0.3750
 1600/40000 [>.............................] - ETA: 5s - loss: 0.8037 - categorical_accuracy: 0.5544  
 3136/40000 [=>............................] - ETA: 3s - loss: 0.7249 - categorical_accuracy: 0.6027
 4544/40000 [==>...........................] - ETA: 2s - loss: 0.6806 - categorical_accuracy: 0.6318
 6080/40000 [===>..........................] - ETA: 2s - loss: 0.6536 - categorical_accuracy: 0.6538
 7680/40000 [====>.........................] - ETA: 1s - loss: 0.6341 - categorical_accuracy: 0.6682
 9248/40000 [=====>........................] - ETA: 1s - loss: 0.6227 - categorical_accuracy: 0.6805
10848/40000 [=======>......................] - ETA: 1s - loss: 0.6115 - categorical_accuracy: 0.6899
12032/40000 [========>.....................] - ETA: 1s - loss: 0.6031 - categorical_accuracy: 0.6964
13600/40000 [=========>....................] - ETA: 1s - loss: 0.5942 - categorical_accuracy: 0.7044
15200/40000 [==========>...................] - ETA: 1s - loss: 0.5861 - categorical_accuracy: 0.7093
16832/40000 [===========>..................] - ETA: 1s - loss: 0.5771 - categorical_accuracy: 0.7152
18304/40000 [============>.................] - ETA: 0s - loss: 0.5727 - categorical_accuracy: 0.7188
19936/40000 [=============>................] - ETA: 0s - loss: 0.5671 - categorical_accuracy: 0.7230
21472/40000 [===============>..............] - ETA: 0s - loss: 0.5628 - categorical_accuracy: 0.7264
23072/40000 [================>.............] - ETA: 0s - loss: 0.5592 - categorical_accuracy: 0.7288
24672/40000 [=================>............] - ETA: 0s - loss: 0.5540 - categorical_accuracy: 0.7318
26272/40000 [==================>...........] - ETA: 0s - loss: 0.5514 - categorical_accuracy: 0.7335
27840/40000 [===================>..........] - ETA: 0s - loss: 0.5489 - categorical_accuracy: 0.7355
29440/40000 [=====================>........] - ETA: 0s - loss: 0.5463 - categorical_accuracy: 0.7377
31072/40000 [======================>.......] - ETA: 0s - loss: 0.5438 - categorical_accuracy: 0.7393
32576/40000 [=======================>......] - ETA: 0s - loss: 0.5417 - categorical_accuracy: 0.7408
34176/40000 [========================>.....] - ETA: 0s - loss: 0.5407 - categorical_accuracy: 0.7417
35744/40000 [=========================>....] - ETA: 0s - loss: 0.5387 - categorical_accuracy: 0.7434
37312/40000 [==========================>...] - ETA: 0s - loss: 0.5375 - categorical_accuracy: 0.7442
38944/40000 [============================>.] - ETA: 0s - loss: 0.5369 - categorical_accuracy: 0.7445
40000/40000 [==============================] - 2s 56us/step - loss: 0.5354 - categorical_accuracy: 0.7452 - val_loss: 0.4669 - val_categorical_accuracy: 0.7858

Epoch 00001: val_loss improved from inf to 0.46686, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/10

   32/40000 [..............................] - ETA: 2s - loss: 0.5850 - categorical_accuracy: 0.6875
 1600/40000 [>.............................] - ETA: 1s - loss: 0.4975 - categorical_accuracy: 0.7713
 3168/40000 [=>............................] - ETA: 1s - loss: 0.4995 - categorical_accuracy: 0.7759
 4736/40000 [==>...........................] - ETA: 1s - loss: 0.4901 - categorical_accuracy: 0.7823
 6272/40000 [===>..........................] - ETA: 1s - loss: 0.4901 - categorical_accuracy: 0.7825
 7808/40000 [====>.........................] - ETA: 1s - loss: 0.4933 - categorical_accuracy: 0.7780
 9408/40000 [======>.......................] - ETA: 0s - loss: 0.4936 - categorical_accuracy: 0.7794
10976/40000 [=======>......................] - ETA: 0s - loss: 0.4940 - categorical_accuracy: 0.7792
12512/40000 [========>.....................] - ETA: 0s - loss: 0.4944 - categorical_accuracy: 0.7781
14080/40000 [=========>....................] - ETA: 0s - loss: 0.4950 - categorical_accuracy: 0.7780
15680/40000 [==========>...................] - ETA: 0s - loss: 0.4946 - categorical_accuracy: 0.7781
17248/40000 [===========>..................] - ETA: 0s - loss: 0.4936 - categorical_accuracy: 0.7787
18816/40000 [=============>................] - ETA: 0s - loss: 0.4930 - categorical_accuracy: 0.7786
20448/40000 [==============>...............] - ETA: 0s - loss: 0.4916 - categorical_accuracy: 0.7791
21920/40000 [===============>..............] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.7794
23520/40000 [================>.............] - ETA: 0s - loss: 0.4913 - categorical_accuracy: 0.7795
25120/40000 [=================>............] - ETA: 0s - loss: 0.4928 - categorical_accuracy: 0.7785
26688/40000 [===================>..........] - ETA: 0s - loss: 0.4921 - categorical_accuracy: 0.7792
28320/40000 [====================>.........] - ETA: 0s - loss: 0.4914 - categorical_accuracy: 0.7796
29824/40000 [=====================>........] - ETA: 0s - loss: 0.4915 - categorical_accuracy: 0.7800
31456/40000 [======================>.......] - ETA: 0s - loss: 0.4917 - categorical_accuracy: 0.7797
33024/40000 [=======================>......] - ETA: 0s - loss: 0.4905 - categorical_accuracy: 0.7803
34624/40000 [========================>.....] - ETA: 0s - loss: 0.4916 - categorical_accuracy: 0.7795
36000/40000 [==========================>...] - ETA: 0s - loss: 0.4913 - categorical_accuracy: 0.7798
37536/40000 [===========================>..] - ETA: 0s - loss: 0.4913 - categorical_accuracy: 0.7800
39136/40000 [============================>.] - ETA: 0s - loss: 0.4916 - categorical_accuracy: 0.7795
40000/40000 [==============================] - 2s 51us/step - loss: 0.4917 - categorical_accuracy: 0.7792 - val_loss: 0.4642 - val_categorical_accuracy: 0.7877

Epoch 00002: val_loss improved from 0.46686 to 0.46419, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/10

   32/40000 [..............................] - ETA: 2s - loss: 0.3880 - categorical_accuracy: 0.8125
 1632/40000 [>.............................] - ETA: 1s - loss: 0.4958 - categorical_accuracy: 0.7763
 3136/40000 [=>............................] - ETA: 1s - loss: 0.4937 - categorical_accuracy: 0.7819
 4608/40000 [==>...........................] - ETA: 1s - loss: 0.4865 - categorical_accuracy: 0.7854
 6112/40000 [===>..........................] - ETA: 1s - loss: 0.4787 - categorical_accuracy: 0.7868
 7712/40000 [====>.........................] - ETA: 1s - loss: 0.4768 - categorical_accuracy: 0.7895
 9248/40000 [=====>........................] - ETA: 1s - loss: 0.4786 - categorical_accuracy: 0.7858
10880/40000 [=======>......................] - ETA: 0s - loss: 0.4801 - categorical_accuracy: 0.7849
12384/40000 [========>.....................] - ETA: 0s - loss: 0.4837 - categorical_accuracy: 0.7829
13952/40000 [=========>....................] - ETA: 0s - loss: 0.4863 - categorical_accuracy: 0.7805
15520/40000 [==========>...................] - ETA: 0s - loss: 0.4848 - categorical_accuracy: 0.7816
17088/40000 [===========>..................] - ETA: 0s - loss: 0.4834 - categorical_accuracy: 0.7826
18688/40000 [=============>................] - ETA: 0s - loss: 0.4829 - categorical_accuracy: 0.7836
20256/40000 [==============>...............] - ETA: 0s - loss: 0.4831 - categorical_accuracy: 0.7838
21856/40000 [===============>..............] - ETA: 0s - loss: 0.4839 - categorical_accuracy: 0.7834
23360/40000 [================>.............] - ETA: 0s - loss: 0.4842 - categorical_accuracy: 0.7829
24864/40000 [=================>............] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.7825
26464/40000 [==================>...........] - ETA: 0s - loss: 0.4860 - categorical_accuracy: 0.7816
28032/40000 [====================>.........] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.7802
29600/40000 [=====================>........] - ETA: 0s - loss: 0.4865 - categorical_accuracy: 0.7805
31168/40000 [======================>.......] - ETA: 0s - loss: 0.4871 - categorical_accuracy: 0.7803
32768/40000 [=======================>......] - ETA: 0s - loss: 0.4858 - categorical_accuracy: 0.7814
34368/40000 [========================>.....] - ETA: 0s - loss: 0.4855 - categorical_accuracy: 0.7816
35968/40000 [=========================>....] - ETA: 0s - loss: 0.4853 - categorical_accuracy: 0.7814
37472/40000 [===========================>..] - ETA: 0s - loss: 0.4852 - categorical_accuracy: 0.7815
39040/40000 [============================>.] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.7817
40000/40000 [==============================] - 2s 51us/step - loss: 0.4839 - categorical_accuracy: 0.7827 - val_loss: 0.4545 - val_categorical_accuracy: 0.7908

Epoch 00003: val_loss improved from 0.46419 to 0.45454, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/10

   32/40000 [..............................] - ETA: 2s - loss: 0.5307 - categorical_accuracy: 0.7500
 1632/40000 [>.............................] - ETA: 1s - loss: 0.4660 - categorical_accuracy: 0.7898
 3008/40000 [=>............................] - ETA: 1s - loss: 0.4699 - categorical_accuracy: 0.7926
 4608/40000 [==>...........................] - ETA: 1s - loss: 0.4763 - categorical_accuracy: 0.7865
 6176/40000 [===>..........................] - ETA: 1s - loss: 0.4831 - categorical_accuracy: 0.7837
 7744/40000 [====>.........................] - ETA: 1s - loss: 0.4809 - categorical_accuracy: 0.7858
 9376/40000 [======>.......................] - ETA: 0s - loss: 0.4810 - categorical_accuracy: 0.7844
10912/40000 [=======>......................] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7851
12544/40000 [========>.....................] - ETA: 0s - loss: 0.4806 - categorical_accuracy: 0.7839
14112/40000 [=========>....................] - ETA: 0s - loss: 0.4797 - categorical_accuracy: 0.7851
15712/40000 [==========>...................] - ETA: 0s - loss: 0.4800 - categorical_accuracy: 0.7846
17184/40000 [===========>..................] - ETA: 0s - loss: 0.4816 - categorical_accuracy: 0.7842
18784/40000 [=============>................] - ETA: 0s - loss: 0.4818 - categorical_accuracy: 0.7839
20352/40000 [==============>...............] - ETA: 0s - loss: 0.4820 - categorical_accuracy: 0.7846
21952/40000 [===============>..............] - ETA: 0s - loss: 0.4798 - categorical_accuracy: 0.7866
23488/40000 [================>.............] - ETA: 0s - loss: 0.4820 - categorical_accuracy: 0.7850
25088/40000 [=================>............] - ETA: 0s - loss: 0.4819 - categorical_accuracy: 0.7845
26624/40000 [==================>...........] - ETA: 0s - loss: 0.4823 - categorical_accuracy: 0.7838
28256/40000 [====================>.........] - ETA: 0s - loss: 0.4815 - categorical_accuracy: 0.7842
29824/40000 [=====================>........] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.7842
31456/40000 [======================>.......] - ETA: 0s - loss: 0.4804 - categorical_accuracy: 0.7849
32960/40000 [=======================>......] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.7850
34400/40000 [========================>.....] - ETA: 0s - loss: 0.4810 - categorical_accuracy: 0.7847
35968/40000 [=========================>....] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.7850
37536/40000 [===========================>..] - ETA: 0s - loss: 0.4808 - categorical_accuracy: 0.7853
39168/40000 [============================>.] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7855
40000/40000 [==============================] - 2s 51us/step - loss: 0.4806 - categorical_accuracy: 0.7851 - val_loss: 0.4545 - val_categorical_accuracy: 0.7921

Epoch 00004: val_loss improved from 0.45454 to 0.45445, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/10

   32/40000 [..............................] - ETA: 2s - loss: 0.6281 - categorical_accuracy: 0.6875
 1504/40000 [>.............................] - ETA: 1s - loss: 0.4868 - categorical_accuracy: 0.7779
 3040/40000 [=>............................] - ETA: 1s - loss: 0.4907 - categorical_accuracy: 0.7763
 4672/40000 [==>...........................] - ETA: 1s - loss: 0.4960 - categorical_accuracy: 0.7755
 5824/40000 [===>..........................] - ETA: 1s - loss: 0.4889 - categorical_accuracy: 0.7799
 7456/40000 [====>.........................] - ETA: 1s - loss: 0.4909 - categorical_accuracy: 0.7790
 9024/40000 [=====>........................] - ETA: 1s - loss: 0.4921 - categorical_accuracy: 0.7763
10656/40000 [======>.......................] - ETA: 0s - loss: 0.4878 - categorical_accuracy: 0.7787
12128/40000 [========>.....................] - ETA: 0s - loss: 0.4853 - categorical_accuracy: 0.7804
13760/40000 [=========>....................] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.7806
15328/40000 [==========>...................] - ETA: 0s - loss: 0.4834 - categorical_accuracy: 0.7818
16928/40000 [===========>..................] - ETA: 0s - loss: 0.4823 - categorical_accuracy: 0.7810
18464/40000 [============>.................] - ETA: 0s - loss: 0.4821 - categorical_accuracy: 0.7805
20096/40000 [==============>...............] - ETA: 0s - loss: 0.4818 - categorical_accuracy: 0.7808
21632/40000 [===============>..............] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7817
23232/40000 [================>.............] - ETA: 0s - loss: 0.4810 - categorical_accuracy: 0.7828
24768/40000 [=================>............] - ETA: 0s - loss: 0.4808 - categorical_accuracy: 0.7833
26304/40000 [==================>...........] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7836
27808/40000 [===================>..........] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.7836
29440/40000 [=====================>........] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7845
31008/40000 [======================>.......] - ETA: 0s - loss: 0.4797 - categorical_accuracy: 0.7846
32032/40000 [=======================>......] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.7850
33440/40000 [========================>.....] - ETA: 0s - loss: 0.4791 - categorical_accuracy: 0.7850
35040/40000 [=========================>....] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.7849
36544/40000 [==========================>...] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.7856
38144/40000 [===========================>..] - ETA: 0s - loss: 0.4784 - categorical_accuracy: 0.7851
39584/40000 [============================>.] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7854
40000/40000 [==============================] - 2s 52us/step - loss: 0.4776 - categorical_accuracy: 0.7857 - val_loss: 0.4511 - val_categorical_accuracy: 0.7936

Epoch 00005: val_loss improved from 0.45445 to 0.45112, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/10

   32/40000 [..............................] - ETA: 2s - loss: 0.4316 - categorical_accuracy: 0.8125
 1536/40000 [>.............................] - ETA: 1s - loss: 0.4714 - categorical_accuracy: 0.8047
 3136/40000 [=>............................] - ETA: 1s - loss: 0.4843 - categorical_accuracy: 0.7918
 4736/40000 [==>...........................] - ETA: 1s - loss: 0.4817 - categorical_accuracy: 0.7861
 6304/40000 [===>..........................] - ETA: 1s - loss: 0.4835 - categorical_accuracy: 0.7841
 7872/40000 [====>.........................] - ETA: 1s - loss: 0.4785 - categorical_accuracy: 0.7858
 9472/40000 [======>.......................] - ETA: 0s - loss: 0.4776 - categorical_accuracy: 0.7861
10976/40000 [=======>......................] - ETA: 0s - loss: 0.4785 - categorical_accuracy: 0.7848
12576/40000 [========>.....................] - ETA: 0s - loss: 0.4782 - categorical_accuracy: 0.7859
14144/40000 [=========>....................] - ETA: 0s - loss: 0.4790 - categorical_accuracy: 0.7849
15744/40000 [==========>...................] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.7844
17056/40000 [===========>..................] - ETA: 0s - loss: 0.4790 - categorical_accuracy: 0.7842
18688/40000 [=============>................] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7854
20224/40000 [==============>...............] - ETA: 0s - loss: 0.4770 - categorical_accuracy: 0.7862
21856/40000 [===============>..............] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.7863
23360/40000 [================>.............] - ETA: 0s - loss: 0.4765 - categorical_accuracy: 0.7865
24928/40000 [=================>............] - ETA: 0s - loss: 0.4750 - categorical_accuracy: 0.7876
26432/40000 [==================>...........] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7873
28064/40000 [====================>.........] - ETA: 0s - loss: 0.4753 - categorical_accuracy: 0.7870
29440/40000 [=====================>........] - ETA: 0s - loss: 0.4747 - categorical_accuracy: 0.7869
31104/40000 [======================>.......] - ETA: 0s - loss: 0.4747 - categorical_accuracy: 0.7872
32608/40000 [=======================>......] - ETA: 0s - loss: 0.4744 - categorical_accuracy: 0.7872
34240/40000 [========================>.....] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7873
35776/40000 [=========================>....] - ETA: 0s - loss: 0.4739 - categorical_accuracy: 0.7875
37408/40000 [===========================>..] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7880
38976/40000 [============================>.] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7883
40000/40000 [==============================] - 2s 51us/step - loss: 0.4743 - categorical_accuracy: 0.7879 - val_loss: 0.4529 - val_categorical_accuracy: 0.7948

Epoch 00006: val_loss did not improve from 0.45112
Epoch 7/10

   32/40000 [..............................] - ETA: 2s - loss: 0.5185 - categorical_accuracy: 0.6875
 1568/40000 [>.............................] - ETA: 1s - loss: 0.4809 - categorical_accuracy: 0.7787
 3136/40000 [=>............................] - ETA: 1s - loss: 0.4772 - categorical_accuracy: 0.7822
 4672/40000 [==>...........................] - ETA: 1s - loss: 0.4733 - categorical_accuracy: 0.7872
 6176/40000 [===>..........................] - ETA: 1s - loss: 0.4745 - categorical_accuracy: 0.7858
 7776/40000 [====>.........................] - ETA: 1s - loss: 0.4741 - categorical_accuracy: 0.7842
 9376/40000 [======>.......................] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7850
10912/40000 [=======>......................] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7867
12512/40000 [========>.....................] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.7856
14144/40000 [=========>....................] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7850
15712/40000 [==========>...................] - ETA: 0s - loss: 0.4750 - categorical_accuracy: 0.7844
17376/40000 [============>.................] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.7849
18976/40000 [=============>................] - ETA: 0s - loss: 0.4746 - categorical_accuracy: 0.7849
20544/40000 [==============>...............] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7852
22112/40000 [===============>..............] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.7859
23744/40000 [================>.............] - ETA: 0s - loss: 0.4753 - categorical_accuracy: 0.7853
25280/40000 [=================>............] - ETA: 0s - loss: 0.4754 - categorical_accuracy: 0.7850
26912/40000 [===================>..........] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7866
28384/40000 [====================>.........] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7867
29952/40000 [=====================>........] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7865
31488/40000 [======================>.......] - ETA: 0s - loss: 0.4738 - categorical_accuracy: 0.7863
33088/40000 [=======================>......] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7866
34592/40000 [========================>.....] - ETA: 0s - loss: 0.4730 - categorical_accuracy: 0.7866
36192/40000 [==========================>...] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7871
37728/40000 [===========================>..] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7872
39360/40000 [============================>.] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7871
40000/40000 [==============================] - 2s 52us/step - loss: 0.4732 - categorical_accuracy: 0.7873 - val_loss: 0.4512 - val_categorical_accuracy: 0.7936

Epoch 00007: val_loss did not improve from 0.45112
Epoch 8/10

   32/40000 [..............................] - ETA: 2s - loss: 0.5546 - categorical_accuracy: 0.7812
 1632/40000 [>.............................] - ETA: 1s - loss: 0.4686 - categorical_accuracy: 0.8009
 3200/40000 [=>............................] - ETA: 1s - loss: 0.4654 - categorical_accuracy: 0.7925
 4800/40000 [==>...........................] - ETA: 1s - loss: 0.4678 - categorical_accuracy: 0.7879
 6400/40000 [===>..........................] - ETA: 1s - loss: 0.4712 - categorical_accuracy: 0.7873
 7968/40000 [====>.........................] - ETA: 1s - loss: 0.4664 - categorical_accuracy: 0.7905
 9568/40000 [======>.......................] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7878
11136/40000 [=======>......................] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7875
12736/40000 [========>.....................] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.7887
14304/40000 [=========>....................] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.7875
15904/40000 [==========>...................] - ETA: 0s - loss: 0.4723 - categorical_accuracy: 0.7881
17504/40000 [============>.................] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7872
19072/40000 [=============>................] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.7875
20672/40000 [==============>...............] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.7866
22272/40000 [===============>..............] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7865
23872/40000 [================>.............] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.7868
25440/40000 [==================>...........] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.7863
26944/40000 [===================>..........] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.7854
28544/40000 [====================>.........] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7853
30112/40000 [=====================>........] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7860
31712/40000 [======================>.......] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.7854
33280/40000 [=======================>......] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7858
34880/40000 [=========================>....] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7859
36320/40000 [==========================>...] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.7868
37888/40000 [===========================>..] - ETA: 0s - loss: 0.4725 - categorical_accuracy: 0.7860
39424/40000 [============================>.] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.7862
40000/40000 [==============================] - 2s 50us/step - loss: 0.4725 - categorical_accuracy: 0.7865 - val_loss: 0.4505 - val_categorical_accuracy: 0.7946

Epoch 00008: val_loss improved from 0.45112 to 0.45046, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 9/10

   32/40000 [..............................] - ETA: 3s - loss: 0.4492 - categorical_accuracy: 0.7812
 1504/40000 [>.............................] - ETA: 1s - loss: 0.4579 - categorical_accuracy: 0.7932
 3104/40000 [=>............................] - ETA: 1s - loss: 0.4582 - categorical_accuracy: 0.7912
 4736/40000 [==>...........................] - ETA: 1s - loss: 0.4675 - categorical_accuracy: 0.7853
 6304/40000 [===>..........................] - ETA: 1s - loss: 0.4661 - categorical_accuracy: 0.7889
 7904/40000 [====>.........................] - ETA: 1s - loss: 0.4700 - categorical_accuracy: 0.7871
 9440/40000 [======>.......................] - ETA: 0s - loss: 0.4702 - categorical_accuracy: 0.7864
11008/40000 [=======>......................] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7894
12608/40000 [========>.....................] - ETA: 0s - loss: 0.4683 - categorical_accuracy: 0.7903
14208/40000 [=========>....................] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.7883
15680/40000 [==========>...................] - ETA: 0s - loss: 0.4702 - categorical_accuracy: 0.7887
17216/40000 [===========>..................] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7886
18816/40000 [=============>................] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.7886
20416/40000 [==============>...............] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7883
22016/40000 [===============>..............] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7882
23584/40000 [================>.............] - ETA: 0s - loss: 0.4747 - categorical_accuracy: 0.7875
25056/40000 [=================>............] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.7885
26656/40000 [==================>...........] - ETA: 0s - loss: 0.4745 - categorical_accuracy: 0.7883
28256/40000 [====================>.........] - ETA: 0s - loss: 0.4753 - categorical_accuracy: 0.7874
29728/40000 [=====================>........] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7876
31360/40000 [======================>.......] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7872
32928/40000 [=======================>......] - ETA: 0s - loss: 0.4758 - categorical_accuracy: 0.7870
34496/40000 [========================>.....] - ETA: 0s - loss: 0.4767 - categorical_accuracy: 0.7867
36128/40000 [==========================>...] - ETA: 0s - loss: 0.4760 - categorical_accuracy: 0.7868
37760/40000 [===========================>..] - ETA: 0s - loss: 0.4757 - categorical_accuracy: 0.7869
39360/40000 [============================>.] - ETA: 0s - loss: 0.4750 - categorical_accuracy: 0.7875
40000/40000 [==============================] - 2s 50us/step - loss: 0.4745 - categorical_accuracy: 0.7876 - val_loss: 0.4462 - val_categorical_accuracy: 0.7952

Epoch 00009: val_loss improved from 0.45046 to 0.44623, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 10/10

   32/40000 [..............................] - ETA: 2s - loss: 0.4323 - categorical_accuracy: 0.7812
 1472/40000 [>.............................] - ETA: 1s - loss: 0.4745 - categorical_accuracy: 0.7874
 3072/40000 [=>............................] - ETA: 1s - loss: 0.4731 - categorical_accuracy: 0.7871
 4576/40000 [==>...........................] - ETA: 1s - loss: 0.4733 - categorical_accuracy: 0.7869
 6208/40000 [===>..........................] - ETA: 1s - loss: 0.4749 - categorical_accuracy: 0.7853
 7776/40000 [====>.........................] - ETA: 1s - loss: 0.4719 - categorical_accuracy: 0.7885
 9408/40000 [======>.......................] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.7879
10848/40000 [=======>......................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7882
12448/40000 [========>.....................] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7855
14048/40000 [=========>....................] - ETA: 0s - loss: 0.4712 - categorical_accuracy: 0.7881
15680/40000 [==========>...................] - ETA: 0s - loss: 0.4700 - categorical_accuracy: 0.7885
17184/40000 [===========>..................] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7883
18784/40000 [=============>................] - ETA: 0s - loss: 0.4745 - categorical_accuracy: 0.7863
20384/40000 [==============>...............] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7865
21952/40000 [===============>..............] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7855
23520/40000 [================>.............] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7856
24992/40000 [=================>............] - ETA: 0s - loss: 0.4755 - categorical_accuracy: 0.7861
26560/40000 [==================>...........] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7867
28128/40000 [====================>.........] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7873
29728/40000 [=====================>........] - ETA: 0s - loss: 0.4735 - categorical_accuracy: 0.7877
31232/40000 [======================>.......] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.7879
32864/40000 [=======================>......] - ETA: 0s - loss: 0.4735 - categorical_accuracy: 0.7873
34432/40000 [========================>.....] - ETA: 0s - loss: 0.4724 - categorical_accuracy: 0.7880
36032/40000 [==========================>...] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7878
37632/40000 [===========================>..] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.7883
39168/40000 [============================>.] - ETA: 0s - loss: 0.4721 - categorical_accuracy: 0.7882
40000/40000 [==============================] - 2s 51us/step - loss: 0.4718 - categorical_accuracy: 0.7884 - val_loss: 0.4467 - val_categorical_accuracy: 0.7955

Epoch 00010: val_loss did not improve from 0.44623
                         : Elapsed time for training with 40000 events: [1;31m21.7 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 40000 events: [1;31m15 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 20000 bkg: 20000
                         : #events: (unweighted) sig: 20000 bkg: 20000
                         : Training 10 Decision Trees ... patience please
                         : Elapsed time for training with 40000 events: [1;31m1.23 sec[0m         
BDT                      : [dataset] : Evaluation of BDT on training sample (40000 events)
                         : Elapsed time for evaluation of 40000 events: [1;31m0.0301 sec[0m       
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_BDT.class.C[0m
                         : MVAOutput.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.354e-01
                         :    2 : mfchi2     : 2.587e-01
                         :    3 : gm2e       : 4.743e-02
                         :    4 : gm1p3cms   : 2.563e-02
                         :    5 : gm1e925    : 2.412e-02
                         :    6 : gm2p3cms   : 2.146e-02
                         :    7 : gmthetacms : 2.061e-02
                         :    8 : gm2e925    : 1.755e-02
                         :    9 : pi0p3cms   : 1.660e-02
                         :   10 : gm1e       : 1.012e-02
                         :   11 : gm1eerror  : 8.514e-03
                         :   12 : ediff      : 7.705e-03
                         :   13 : gm2eerror  : 6.164e-03
                         : --------------------------------------------
BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 3.929e-01
                         :    2 : gm2e       : 2.661e-01
                         :    3 : mfchi2     : 1.634e-01
                         :    4 : gm1e925    : 7.706e-02
                         :    5 : gm1p3cms   : 3.203e-02
                         :    6 : gm2p3cms   : 2.163e-02
                         :    7 : pi0p3cms   : 2.117e-02
                         :    8 : gmthetacms : 2.069e-02
                         :    9 : gm1e       : 5.004e-03
                         :   10 : gm2e925    : 0.000e+00
                         :   11 : ediff      : 0.000e+00
                         :   12 : gm1eerror  : 0.000e+00
                         :   13 : gm2eerror  : 0.000e+00
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (40000 events)
                         : Elapsed time for evaluation of 40000 events: [1;31m0.0305 sec[0m       
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.018446     0.99782   [     -3.6658      5.7307 ]
                         :   pi0p3cms:    0.017814     0.99746   [     -3.3551      5.7307 ]
                         :       gm1e:    0.018538     0.99663   [     -3.2330      5.7307 ]
                         :       gm2e:    0.013670      1.0034   [     -3.1838      5.7307 ]
                         :    gm1e925:     0.70019      2.0961   [     -3.3784      5.7307 ]
                         :    gm2e925:     0.70019      2.0961   [     -3.3784      5.7307 ]
                         :      ediff:    0.019437     0.98972   [     -3.1711      5.7307 ]
                         :  gm1eerror:    0.020640     0.98991   [     -3.1203      5.7307 ]
                         :  gm2eerror:    0.014827      1.0009   [     -3.0400      5.7307 ]
                         :   gm1p3cms:    0.018382     0.99556   [     -3.2662      5.7307 ]
                         :   gm2p3cms:    0.013000      1.0043   [     -3.2478      5.7307 ]
                         : gmthetacms:   -0.010556     0.99831   [     -3.1764      5.7307 ]
                         :     mfchi2:  -0.0044008     0.99177   [     -2.2435      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.018446     0.99782   [     -3.6658      5.7307 ]
                         :   pi0p3cms:    0.017814     0.99746   [     -3.3551      5.7307 ]
                         :       gm1e:    0.018538     0.99663   [     -3.2330      5.7307 ]
                         :       gm2e:    0.013670      1.0034   [     -3.1838      5.7307 ]
                         :    gm1e925:     0.70019      2.0961   [     -3.3784      5.7307 ]
                         :    gm2e925:     0.70019      2.0961   [     -3.3784      5.7307 ]
                         :      ediff:    0.019437     0.98972   [     -3.1711      5.7307 ]
                         :  gm1eerror:    0.020640     0.98991   [     -3.1203      5.7307 ]
                         :  gm2eerror:    0.014827      1.0009   [     -3.0400      5.7307 ]
                         :   gm1p3cms:    0.018382     0.99556   [     -3.2662      5.7307 ]
                         :   gm2p3cms:    0.013000      1.0043   [     -3.2478      5.7307 ]
                         : gmthetacms:   -0.010556     0.99831   [     -3.1764      5.7307 ]
                         :     mfchi2:  -0.0044008     0.99177   [     -2.2435      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59641     0.55647   [   0.0024752      5.5257 ]
                         :   pi0p3cms:     0.75321     0.74540   [   0.0073237      8.2493 ]
                         :       gm1e:     0.44145     0.41789   [    0.062132      4.8358 ]
                         :       gm2e:     0.18197     0.17519   [    0.060001      2.0981 ]
                         :    gm1e925:     0.95284    0.061086   [     0.19151      1.0000 ]
                         :    gm2e925:     0.95284    0.061086   [     0.19151      1.0000 ]
                         :      ediff:     0.25947     0.34292   [  2.2352e-07      4.7205 ]
                         :  gm1eerror:  0.00013654  0.00032504   [  1.8278e-06    0.011124 ]
                         :  gm2eerror:  2.6640e-05  7.0468e-05   [  1.7062e-06   0.0023600 ]
                         :   gm1p3cms:     0.55078     0.56321   [    0.047244      7.2082 ]
                         :   gm2p3cms:     0.22472     0.23490   [    0.043337      2.8939 ]
                         : gmthetacms:     0.73451     0.52924   [    0.041040      3.0902 ]
                         :     mfchi2:      8.7944      11.463   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59641     0.55647   [   0.0024752      5.5257 ]
                         :   pi0p3cms:     0.75321     0.74540   [   0.0073237      8.2493 ]
                         :       gm1e:     0.44145     0.41789   [    0.062132      4.8358 ]
                         :       gm2e:     0.18197     0.17519   [    0.060001      2.0981 ]
                         :    gm1e925:     0.95284    0.061086   [     0.19151      1.0000 ]
                         :    gm2e925:     0.95284    0.061086   [     0.19151      1.0000 ]
                         :      ediff:     0.25947     0.34292   [  2.2352e-07      4.7205 ]
                         :  gm1eerror:  0.00013654  0.00032504   [  1.8278e-06    0.011124 ]
                         :  gm2eerror:  2.6640e-05  7.0468e-05   [  1.7062e-06   0.0023600 ]
                         :   gm1p3cms:     0.55078     0.56321   [    0.047244      7.2082 ]
                         :   gm2p3cms:     0.22472     0.23490   [    0.043337      2.8939 ]
                         : gmthetacms:     0.73451     0.52924   [    0.041040      3.0902 ]
                         :     mfchi2:      8.7944      11.463   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       PyKeras        : 0.873
                         : dataset       GTB            : 0.872
                         : dataset       BDT            : 0.864
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              PyKeras        : 0.262 (0.266)       0.662 (0.662)      0.860 (0.864)
                         : dataset              GTB            : 0.268 (0.361)       0.657 (0.703)      0.857 (0.875)
                         : dataset              BDT            : 0.000 (0.000)       0.641 (0.647)      0.846 (0.851)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 40000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 40000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
