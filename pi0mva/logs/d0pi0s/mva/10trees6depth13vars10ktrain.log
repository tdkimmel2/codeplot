DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : Booking method: [1mBDT[0m
                         : 
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 10000
                         : Signal     -- testing events             : 10000
                         : Signal     -- training and testing events: 20000
                         : Background -- training events            : 10000
                         : Background -- testing events             : 10000
                         : Background -- training and testing events: 20000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.976  +0.956  +0.757  -0.198  -0.198  +0.725    +0.768    +0.631   +0.938   +0.758     -0.684  -0.209
                         :   pi0p3cms:  +0.976   +1.000  +0.933  +0.740  -0.184  -0.184  +0.706    +0.773    +0.640   +0.961   +0.780     -0.669  -0.186
                         :       gm1e:  +0.956   +0.933  +1.000  +0.533  -0.135  -0.135  +0.895    +0.828    +0.441   +0.977   +0.545     -0.619  -0.189
                         :       gm2e:  +0.757   +0.740  +0.533  +1.000  -0.273  -0.273  +0.100    +0.379    +0.850   +0.534   +0.979     -0.561  -0.194
                         :    gm1e925:  -0.198   -0.184  -0.135  -0.273  +1.000  +1.000  -0.015    -0.092    -0.269   -0.128   -0.258     +0.084  -0.032
                         :    gm2e925:  -0.198   -0.184  -0.135  -0.273  +1.000  +1.000  -0.015    -0.092    -0.269   -0.128   -0.258     +0.084  -0.032
                         :      ediff:  +0.725   +0.706  +0.895  +0.100  -0.015  -0.015  +1.000    +0.774    +0.070   +0.867   +0.125     -0.432  -0.120
                         :  gm1eerror:  +0.768   +0.773  +0.828  +0.379  -0.092  -0.092  +0.774    +1.000    +0.356   +0.833   +0.403     -0.375  -0.116
                         :  gm2eerror:  +0.631   +0.640  +0.441  +0.850  -0.269  -0.269  +0.070    +0.356    +1.000   +0.457   +0.860     -0.360  -0.130
                         :   gm1p3cms:  +0.938   +0.961  +0.977  +0.534  -0.128  -0.128  +0.867    +0.833    +0.457   +1.000   +0.577     -0.613  -0.170
                         :   gm2p3cms:  +0.758   +0.780  +0.545  +0.979  -0.258  -0.258  +0.125    +0.403    +0.860   +0.577   +1.000     -0.562  -0.178
                         : gmthetacms:  -0.684   -0.669  -0.619  -0.561  +0.084  +0.084  -0.432    -0.375    -0.360   -0.613   -0.562     +1.000  +0.209
                         :     mfchi2:  -0.209   -0.186  -0.189  -0.194  -0.032  -0.032  -0.120    -0.116    -0.130   -0.170   -0.178     +0.209  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.977  +0.967  +0.647  -0.078  -0.078  +0.850    +0.803    +0.518   +0.951   +0.647     -0.699  -0.142
                         :   pi0p3cms:  +0.977   +1.000  +0.946  +0.637  -0.072  -0.072  +0.830    +0.803    +0.524   +0.970   +0.676     -0.707  -0.129
                         :       gm1e:  +0.967   +0.946  +1.000  +0.448  -0.071  -0.071  +0.953    +0.857    +0.360   +0.980   +0.459     -0.607  -0.139
                         :       gm2e:  +0.647   +0.637  +0.448  +1.000  -0.071  -0.071  +0.158    +0.333    +0.829   +0.450   +0.965     -0.529  -0.123
                         :    gm1e925:  -0.078   -0.072  -0.071  -0.071  +1.000  +1.000  -0.054    -0.041    -0.056   -0.065   -0.066     +0.056  +0.015
                         :    gm2e925:  -0.078   -0.072  -0.071  -0.071  +1.000  +1.000  -0.054    -0.041    -0.056   -0.065   -0.066     +0.056  +0.015
                         :      ediff:  +0.850   +0.830  +0.953  +0.158  -0.054  -0.054  +1.000    +0.834    +0.118   +0.930   +0.181     -0.492  -0.112
                         :  gm1eerror:  +0.803   +0.803  +0.857  +0.333  -0.041  -0.041  +0.834    +1.000    +0.285   +0.854   +0.349     -0.374  -0.118
                         :  gm2eerror:  +0.518   +0.524  +0.360  +0.829  -0.056  -0.056  +0.118    +0.285    +1.000   +0.371   +0.820     -0.323  -0.101
                         :   gm1p3cms:  +0.951   +0.970  +0.980  +0.450  -0.065  -0.065  +0.930    +0.854    +0.371   +1.000   +0.485     -0.620  -0.127
                         :   gm2p3cms:  +0.647   +0.676  +0.459  +0.965  -0.066  -0.066  +0.181    +0.349    +0.820   +0.485   +1.000     -0.572  -0.110
                         : gmthetacms:  -0.699   -0.707  -0.607  -0.529  +0.056  +0.056  -0.492    -0.374    -0.323   -0.620   -0.572     +1.000  +0.075
                         :     mfchi2:  -0.142   -0.129  -0.139  -0.123  +0.015  +0.015  -0.112    -0.118    -0.101   -0.127   -0.110     +0.075  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [1mTrain all methods[0m
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0031512     0.99882   [     -3.3750      5.7307 ]
                         :   pi0p3cms:   0.0031209     0.99882   [     -3.3767      5.7307 ]
                         :       gm1e:   0.0030234     0.99830   [     -3.3720      5.7307 ]
                         :       gm2e:   0.0035679      1.0009   [     -3.2180      5.7307 ]
                         :    gm1e925:     0.73273      2.1247   [     -3.3422      5.7307 ]
                         :    gm2e925:     0.73273      2.1247   [     -3.3422      5.7307 ]
                         :      ediff:   0.0029374     0.99815   [     -3.2399      5.7307 ]
                         :  gm1eerror:   0.0055472     0.99324   [     -3.1522      5.7307 ]
                         :  gm2eerror:   0.0039445     0.99745   [     -3.1447      5.7307 ]
                         :   gm1p3cms:   0.0030584     0.99823   [     -3.3741      5.7307 ]
                         :   gm2p3cms:   0.0035013      1.0004   [     -3.3505      5.7307 ]
                         : gmthetacms:   0.0035246      1.0004   [     -3.3772      5.7307 ]
                         :     mfchi2:   0.0076028     0.98851   [     -2.2125      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 2.857e-01
                         :    2 : gm1e       : 2.559e-01
                         :    3 : gmthetacms : 2.513e-01
                         :    4 : pi0p3cms   : 2.436e-01
                         :    5 : gm1eerror  : 2.390e-01
                         :    6 : mfchi2     : 2.363e-01
                         :    7 : gm2e       : 2.355e-01
                         :    8 : gm1p3cms   : 2.183e-01
                         :    9 : gm2eerror  : 2.158e-01
                         :   10 : gm2p3cms   : 1.962e-01
                         :   11 : ediff      : 1.350e-01
                         :   12 : gm1e925    : 7.653e-02
                         :   13 : gm2e925    : 7.653e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0031512     0.99882   [     -3.3750      5.7307 ]
                         :   pi0p3cms:   0.0031209     0.99882   [     -3.3767      5.7307 ]
                         :       gm1e:   0.0030234     0.99830   [     -3.3720      5.7307 ]
                         :       gm2e:   0.0035679      1.0009   [     -3.2180      5.7307 ]
                         :    gm1e925:     0.73273      2.1247   [     -3.3422      5.7307 ]
                         :    gm2e925:     0.73273      2.1247   [     -3.3422      5.7307 ]
                         :      ediff:   0.0029374     0.99815   [     -3.2399      5.7307 ]
                         :  gm1eerror:   0.0055472     0.99324   [     -3.1522      5.7307 ]
                         :  gm2eerror:   0.0039445     0.99745   [     -3.1447      5.7307 ]
                         :   gm1p3cms:   0.0030584     0.99823   [     -3.3741      5.7307 ]
                         :   gm2p3cms:   0.0035013      1.0004   [     -3.3505      5.7307 ]
                         : gmthetacms:   0.0035246      1.0004   [     -3.3772      5.7307 ]
                         :     mfchi2:   0.0076028     0.98851   [     -2.2125      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 20000 samples, validate on 20000 samples
Epoch 1/10

   32/20000 [..............................] - ETA: 2:22 - loss: 0.5984 - categorical_accuracy: 0.6250
 1248/20000 [>.............................] - ETA: 4s - loss: 0.7034 - categorical_accuracy: 0.6138  
 2528/20000 [==>...........................] - ETA: 2s - loss: 0.6971 - categorical_accuracy: 0.6274
 3872/20000 [====>.........................] - ETA: 1s - loss: 0.6684 - categorical_accuracy: 0.6511
 5216/20000 [======>.......................] - ETA: 1s - loss: 0.6527 - categorical_accuracy: 0.6651
 6752/20000 [=========>....................] - ETA: 0s - loss: 0.6314 - categorical_accuracy: 0.6782
 8256/20000 [===========>..................] - ETA: 0s - loss: 0.6186 - categorical_accuracy: 0.6869
 9824/20000 [=============>................] - ETA: 0s - loss: 0.6096 - categorical_accuracy: 0.6962
11456/20000 [================>.............] - ETA: 0s - loss: 0.5994 - categorical_accuracy: 0.7022
12960/20000 [==================>...........] - ETA: 0s - loss: 0.5942 - categorical_accuracy: 0.7059
14496/20000 [====================>.........] - ETA: 0s - loss: 0.5866 - categorical_accuracy: 0.7106
16032/20000 [=======================>......] - ETA: 0s - loss: 0.5798 - categorical_accuracy: 0.7154
17472/20000 [=========================>....] - ETA: 0s - loss: 0.5751 - categorical_accuracy: 0.7181
19104/20000 [===========================>..] - ETA: 0s - loss: 0.5704 - categorical_accuracy: 0.7217
20000/20000 [==============================] - 1s 67us/step - loss: 0.5682 - categorical_accuracy: 0.7230 - val_loss: 0.4791 - val_categorical_accuracy: 0.7776

Epoch 00001: val_loss improved from inf to 0.47910, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/10

   32/20000 [..............................] - ETA: 1s - loss: 0.4923 - categorical_accuracy: 0.8438
 1568/20000 [=>............................] - ETA: 0s - loss: 0.5161 - categorical_accuracy: 0.7570
 3232/20000 [===>..........................] - ETA: 0s - loss: 0.5224 - categorical_accuracy: 0.7537
 4704/20000 [======>.......................] - ETA: 0s - loss: 0.5185 - categorical_accuracy: 0.7579
 6336/20000 [========>.....................] - ETA: 0s - loss: 0.5156 - categorical_accuracy: 0.7631
 7904/20000 [==========>...................] - ETA: 0s - loss: 0.5163 - categorical_accuracy: 0.7628
 9504/20000 [=============>................] - ETA: 0s - loss: 0.5161 - categorical_accuracy: 0.7618
11136/20000 [===============>..............] - ETA: 0s - loss: 0.5150 - categorical_accuracy: 0.7633
12768/20000 [==================>...........] - ETA: 0s - loss: 0.5113 - categorical_accuracy: 0.7652
14400/20000 [====================>.........] - ETA: 0s - loss: 0.5111 - categorical_accuracy: 0.7656
16000/20000 [=======================>......] - ETA: 0s - loss: 0.5097 - categorical_accuracy: 0.7671
17536/20000 [=========================>....] - ETA: 0s - loss: 0.5106 - categorical_accuracy: 0.7668
19104/20000 [===========================>..] - ETA: 0s - loss: 0.5102 - categorical_accuracy: 0.7673
20000/20000 [==============================] - 1s 50us/step - loss: 0.5093 - categorical_accuracy: 0.7678 - val_loss: 0.4740 - val_categorical_accuracy: 0.7817

Epoch 00002: val_loss improved from 0.47910 to 0.47399, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/10

   32/20000 [..............................] - ETA: 0s - loss: 0.5340 - categorical_accuracy: 0.6562
 1472/20000 [=>............................] - ETA: 0s - loss: 0.4994 - categorical_accuracy: 0.7758
 3104/20000 [===>..........................] - ETA: 0s - loss: 0.5069 - categorical_accuracy: 0.7703
 4704/20000 [======>.......................] - ETA: 0s - loss: 0.4969 - categorical_accuracy: 0.7785
 6368/20000 [========>.....................] - ETA: 0s - loss: 0.5008 - categorical_accuracy: 0.7756
 8000/20000 [===========>..................] - ETA: 0s - loss: 0.5005 - categorical_accuracy: 0.7741
 9632/20000 [=============>................] - ETA: 0s - loss: 0.4982 - categorical_accuracy: 0.7740
11264/20000 [===============>..............] - ETA: 0s - loss: 0.5003 - categorical_accuracy: 0.7713
12800/20000 [==================>...........] - ETA: 0s - loss: 0.4997 - categorical_accuracy: 0.7716
14400/20000 [====================>.........] - ETA: 0s - loss: 0.4994 - categorical_accuracy: 0.7711
16032/20000 [=======================>......] - ETA: 0s - loss: 0.4969 - categorical_accuracy: 0.7721
17568/20000 [=========================>....] - ETA: 0s - loss: 0.4965 - categorical_accuracy: 0.7724
19232/20000 [===========================>..] - ETA: 0s - loss: 0.4957 - categorical_accuracy: 0.7737
20000/20000 [==============================] - 1s 51us/step - loss: 0.4970 - categorical_accuracy: 0.7726 - val_loss: 0.4708 - val_categorical_accuracy: 0.7839

Epoch 00003: val_loss improved from 0.47399 to 0.47077, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/10

   32/20000 [..............................] - ETA: 0s - loss: 0.5032 - categorical_accuracy: 0.7812
 1632/20000 [=>............................] - ETA: 0s - loss: 0.5008 - categorical_accuracy: 0.7782
 3232/20000 [===>..........................] - ETA: 0s - loss: 0.5042 - categorical_accuracy: 0.7791
 4864/20000 [======>.......................] - ETA: 0s - loss: 0.4986 - categorical_accuracy: 0.7775
 6464/20000 [========>.....................] - ETA: 0s - loss: 0.4950 - categorical_accuracy: 0.7769
 8064/20000 [===========>..................] - ETA: 0s - loss: 0.4936 - categorical_accuracy: 0.7779
 9664/20000 [=============>................] - ETA: 0s - loss: 0.4887 - categorical_accuracy: 0.7798
11296/20000 [===============>..............] - ETA: 0s - loss: 0.4895 - categorical_accuracy: 0.7787
12896/20000 [==================>...........] - ETA: 0s - loss: 0.4907 - categorical_accuracy: 0.7785
14496/20000 [====================>.........] - ETA: 0s - loss: 0.4918 - categorical_accuracy: 0.7779
16064/20000 [=======================>......] - ETA: 0s - loss: 0.4933 - categorical_accuracy: 0.7756
17728/20000 [=========================>....] - ETA: 0s - loss: 0.4910 - categorical_accuracy: 0.7769
19328/20000 [===========================>..] - ETA: 0s - loss: 0.4933 - categorical_accuracy: 0.7757
20000/20000 [==============================] - 1s 50us/step - loss: 0.4926 - categorical_accuracy: 0.7760 - val_loss: 0.4693 - val_categorical_accuracy: 0.7847

Epoch 00004: val_loss improved from 0.47077 to 0.46933, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/10

   32/20000 [..............................] - ETA: 0s - loss: 0.4999 - categorical_accuracy: 0.7812
 1600/20000 [=>............................] - ETA: 0s - loss: 0.4928 - categorical_accuracy: 0.7625
 2848/20000 [===>..........................] - ETA: 0s - loss: 0.4901 - categorical_accuracy: 0.7739
 4448/20000 [=====>........................] - ETA: 0s - loss: 0.4913 - categorical_accuracy: 0.7756
 6080/20000 [========>.....................] - ETA: 0s - loss: 0.4945 - categorical_accuracy: 0.7765
 7680/20000 [==========>...................] - ETA: 0s - loss: 0.4907 - categorical_accuracy: 0.7772
 9344/20000 [=============>................] - ETA: 0s - loss: 0.4934 - categorical_accuracy: 0.7762
10976/20000 [===============>..............] - ETA: 0s - loss: 0.4882 - categorical_accuracy: 0.7797
12608/20000 [=================>............] - ETA: 0s - loss: 0.4911 - categorical_accuracy: 0.7770
14208/20000 [====================>.........] - ETA: 0s - loss: 0.4899 - categorical_accuracy: 0.7774
15744/20000 [======================>.......] - ETA: 0s - loss: 0.4893 - categorical_accuracy: 0.7784
17248/20000 [========================>.....] - ETA: 0s - loss: 0.4882 - categorical_accuracy: 0.7796
18816/20000 [===========================>..] - ETA: 0s - loss: 0.4885 - categorical_accuracy: 0.7796
20000/20000 [==============================] - 1s 51us/step - loss: 0.4889 - categorical_accuracy: 0.7788 - val_loss: 0.4680 - val_categorical_accuracy: 0.7865

Epoch 00005: val_loss improved from 0.46933 to 0.46802, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/10

   32/20000 [..............................] - ETA: 1s - loss: 0.5693 - categorical_accuracy: 0.8125
 1568/20000 [=>............................] - ETA: 0s - loss: 0.5061 - categorical_accuracy: 0.7736
 3168/20000 [===>..........................] - ETA: 0s - loss: 0.4968 - categorical_accuracy: 0.7787
 4768/20000 [======>.......................] - ETA: 0s - loss: 0.4976 - categorical_accuracy: 0.7756
 6368/20000 [========>.....................] - ETA: 0s - loss: 0.4959 - categorical_accuracy: 0.7736
 7968/20000 [==========>...................] - ETA: 0s - loss: 0.4936 - categorical_accuracy: 0.7771
 9568/20000 [=============>................] - ETA: 0s - loss: 0.4884 - categorical_accuracy: 0.7803
11168/20000 [===============>..............] - ETA: 0s - loss: 0.4889 - categorical_accuracy: 0.7805
12768/20000 [==================>...........] - ETA: 0s - loss: 0.4880 - categorical_accuracy: 0.7811
14208/20000 [====================>.........] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.7809
15808/20000 [======================>.......] - ETA: 0s - loss: 0.4858 - categorical_accuracy: 0.7812
17344/20000 [=========================>....] - ETA: 0s - loss: 0.4850 - categorical_accuracy: 0.7818
18944/20000 [===========================>..] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.7816
20000/20000 [==============================] - 1s 50us/step - loss: 0.4852 - categorical_accuracy: 0.7811 - val_loss: 0.4618 - val_categorical_accuracy: 0.7875

Epoch 00006: val_loss improved from 0.46802 to 0.46177, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/10

   32/20000 [..............................] - ETA: 0s - loss: 0.5242 - categorical_accuracy: 0.6562
 1568/20000 [=>............................] - ETA: 0s - loss: 0.4928 - categorical_accuracy: 0.7774
 3136/20000 [===>..........................] - ETA: 0s - loss: 0.4872 - categorical_accuracy: 0.7790
 4736/20000 [======>.......................] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.7825
 6368/20000 [========>.....................] - ETA: 0s - loss: 0.4852 - categorical_accuracy: 0.7798
 7968/20000 [==========>...................] - ETA: 0s - loss: 0.4837 - categorical_accuracy: 0.7816
 9632/20000 [=============>................] - ETA: 0s - loss: 0.4846 - categorical_accuracy: 0.7808
11168/20000 [===============>..............] - ETA: 0s - loss: 0.4838 - categorical_accuracy: 0.7833
12640/20000 [=================>............] - ETA: 0s - loss: 0.4857 - categorical_accuracy: 0.7815
14272/20000 [====================>.........] - ETA: 0s - loss: 0.4883 - categorical_accuracy: 0.7792
15904/20000 [======================>.......] - ETA: 0s - loss: 0.4872 - categorical_accuracy: 0.7806
17504/20000 [=========================>....] - ETA: 0s - loss: 0.4875 - categorical_accuracy: 0.7806
19136/20000 [===========================>..] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.7815
20000/20000 [==============================] - 1s 50us/step - loss: 0.4833 - categorical_accuracy: 0.7829 - val_loss: 0.4567 - val_categorical_accuracy: 0.7880

Epoch 00007: val_loss improved from 0.46177 to 0.45668, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/10

   32/20000 [..............................] - ETA: 0s - loss: 0.5236 - categorical_accuracy: 0.7188
 1600/20000 [=>............................] - ETA: 0s - loss: 0.4918 - categorical_accuracy: 0.7638
 3168/20000 [===>..........................] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.7746
 4832/20000 [======>.......................] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.7761
 6432/20000 [========>.....................] - ETA: 0s - loss: 0.4859 - categorical_accuracy: 0.7766
 8064/20000 [===========>..................] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7773
 9664/20000 [=============>................] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.7803
11328/20000 [===============>..............] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.7825
12544/20000 [=================>............] - ETA: 0s - loss: 0.4791 - categorical_accuracy: 0.7816
14112/20000 [====================>.........] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.7800
15712/20000 [======================>.......] - ETA: 0s - loss: 0.4815 - categorical_accuracy: 0.7806
17344/20000 [=========================>....] - ETA: 0s - loss: 0.4819 - categorical_accuracy: 0.7821
18912/20000 [===========================>..] - ETA: 0s - loss: 0.4824 - categorical_accuracy: 0.7817
20000/20000 [==============================] - 1s 51us/step - loss: 0.4827 - categorical_accuracy: 0.7813 - val_loss: 0.4608 - val_categorical_accuracy: 0.7879

Epoch 00008: val_loss did not improve from 0.45668
Epoch 9/10

   32/20000 [..............................] - ETA: 1s - loss: 0.4736 - categorical_accuracy: 0.7812
 1600/20000 [=>............................] - ETA: 0s - loss: 0.4882 - categorical_accuracy: 0.7756
 3232/20000 [===>..........................] - ETA: 0s - loss: 0.4846 - categorical_accuracy: 0.7772
 4768/20000 [======>.......................] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.7804
 6400/20000 [========>.....................] - ETA: 0s - loss: 0.4757 - categorical_accuracy: 0.7862
 7968/20000 [==========>...................] - ETA: 0s - loss: 0.4735 - categorical_accuracy: 0.7888
 9632/20000 [=============>................] - ETA: 0s - loss: 0.4774 - categorical_accuracy: 0.7862
11168/20000 [===============>..............] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.7823
12768/20000 [==================>...........] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.7825
14368/20000 [====================>.........] - ETA: 0s - loss: 0.4804 - categorical_accuracy: 0.7840
16000/20000 [=======================>......] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.7843
17600/20000 [=========================>....] - ETA: 0s - loss: 0.4793 - categorical_accuracy: 0.7835
19232/20000 [===========================>..] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7824
20000/20000 [==============================] - 1s 50us/step - loss: 0.4795 - categorical_accuracy: 0.7835 - val_loss: 0.4545 - val_categorical_accuracy: 0.7904

Epoch 00009: val_loss improved from 0.45668 to 0.45449, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 10/10

   32/20000 [..............................] - ETA: 0s - loss: 0.6937 - categorical_accuracy: 0.7812
 1600/20000 [=>............................] - ETA: 0s - loss: 0.4770 - categorical_accuracy: 0.7906
 3168/20000 [===>..........................] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.7847
 4832/20000 [======>.......................] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7846
 6432/20000 [========>.....................] - ETA: 0s - loss: 0.4824 - categorical_accuracy: 0.7833
 8096/20000 [===========>..................] - ETA: 0s - loss: 0.4808 - categorical_accuracy: 0.7833
 9536/20000 [=============>................] - ETA: 0s - loss: 0.4804 - categorical_accuracy: 0.7841
11072/20000 [===============>..............] - ETA: 0s - loss: 0.4801 - categorical_accuracy: 0.7840
12512/20000 [=================>............] - ETA: 0s - loss: 0.4786 - categorical_accuracy: 0.7850
14112/20000 [====================>.........] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.7851
15744/20000 [======================>.......] - ETA: 0s - loss: 0.4784 - categorical_accuracy: 0.7848
17344/20000 [=========================>....] - ETA: 0s - loss: 0.4790 - categorical_accuracy: 0.7849
18944/20000 [===========================>..] - ETA: 0s - loss: 0.4798 - categorical_accuracy: 0.7844
20000/20000 [==============================] - 1s 51us/step - loss: 0.4793 - categorical_accuracy: 0.7843 - val_loss: 0.4559 - val_categorical_accuracy: 0.7884

Epoch 00010: val_loss did not improve from 0.45449
                         : Elapsed time for training with 20000 events: [1;31m11.4 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 20000 events: [1;31m6.17 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 10000 bkg: 10000
                         : #events: (unweighted) sig: 10000 bkg: 10000
                         : Training 10 Decision Trees ... patience please
                         : Elapsed time for training with 20000 events: [1;31m0.528 sec[0m         
BDT                      : [dataset] : Evaluation of BDT on training sample (20000 events)
                         : Elapsed time for evaluation of 20000 events: [1;31m0.015 sec[0m       
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_BDT.class.C[0m
                         : MVAOutput.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 4.945e-01
                         :    2 : mfchi2     : 2.549e-01
                         :    3 : gm2e       : 5.160e-02
                         :    4 : gm2p3cms   : 2.801e-02
                         :    5 : gmthetacms : 2.746e-02
                         :    6 : gm1p3cms   : 2.602e-02
                         :    7 : gm1e925    : 2.348e-02
                         :    8 : pi0p3cms   : 2.319e-02
                         :    9 : gm2e925    : 2.185e-02
                         :   10 : gm1e       : 1.448e-02
                         :   11 : gm1eerror  : 1.368e-02
                         :   12 : ediff      : 1.239e-02
                         :   13 : gm2eerror  : 8.392e-03
                         : --------------------------------------------
BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 3.671e-01
                         :    2 : mfchi2     : 2.586e-01
                         :    3 : gm2e       : 2.311e-01
                         :    4 : gm1e925    : 6.502e-02
                         :    5 : gm2p3cms   : 3.034e-02
                         :    6 : pi0p3cms   : 2.396e-02
                         :    7 : gm1p3cms   : 1.882e-02
                         :    8 : gmthetacms : 4.193e-03
                         :    9 : gm1e       : 8.761e-04
                         :   10 : gm2e925    : 0.000e+00
                         :   11 : ediff      : 0.000e+00
                         :   12 : gm1eerror  : 0.000e+00
                         :   13 : gm2eerror  : 0.000e+00
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (20000 events)
                         : Elapsed time for evaluation of 20000 events: [1;31m0.0174 sec[0m       
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.024878     0.98827   [     -3.3567      5.7307 ]
                         :   pi0p3cms:    0.024357     0.98808   [     -3.1973      5.7307 ]
                         :       gm1e:    0.022319     0.99121   [     -3.3419      5.7307 ]
                         :       gm2e:    0.023584     0.99197   [     -3.2672      5.7307 ]
                         :    gm1e925:     0.70461      2.1043   [     -3.6164      5.7307 ]
                         :    gm2e925:     0.70461      2.1043   [     -3.6164      5.7307 ]
                         :      ediff:    0.017527     0.99299   [     -3.2423      5.7307 ]
                         :  gm1eerror:    0.024705     0.98259   [     -3.1523      5.7307 ]
                         :  gm2eerror:    0.021860     0.98751   [     -3.1516      3.9994 ]
                         :   gm1p3cms:    0.023733     0.98754   [     -3.2743      5.7307 ]
                         :   gm2p3cms:    0.019450     0.99722   [     -3.1333      4.1435 ]
                         : gmthetacms:   -0.018842     0.98729   [     -3.1338      5.7307 ]
                         :     mfchi2:  -0.0046420     0.98567   [     -2.2125      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.024878     0.98827   [     -3.3567      5.7307 ]
                         :   pi0p3cms:    0.024357     0.98808   [     -3.1973      5.7307 ]
                         :       gm1e:    0.022319     0.99121   [     -3.3419      5.7307 ]
                         :       gm2e:    0.023584     0.99197   [     -3.2672      5.7307 ]
                         :    gm1e925:     0.70461      2.1043   [     -3.6164      5.7307 ]
                         :    gm2e925:     0.70461      2.1043   [     -3.6164      5.7307 ]
                         :      ediff:    0.017527     0.99299   [     -3.2423      5.7307 ]
                         :  gm1eerror:    0.024705     0.98259   [     -3.1523      5.7307 ]
                         :  gm2eerror:    0.021860     0.98751   [     -3.1516      3.9994 ]
                         :   gm1p3cms:    0.023733     0.98754   [     -3.2743      5.7307 ]
                         :   gm2p3cms:    0.019450     0.99722   [     -3.1333      4.1435 ]
                         : gmthetacms:   -0.018842     0.98729   [     -3.1338      5.7307 ]
                         :     mfchi2:  -0.0046420     0.98567   [     -2.2125      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59789     0.55490   [   0.0049119      4.9404 ]
                         :   pi0p3cms:     0.75554     0.74358   [    0.011479      7.1892 ]
                         :       gm1e:     0.44251     0.41797   [    0.063063      4.8358 ]
                         :       gm2e:     0.18208     0.17424   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95285    0.061070   [     0.21284      1.0000 ]
                         :    gm2e925:     0.95285    0.061070   [     0.21284      1.0000 ]
                         :      ediff:     0.26043     0.34430   [  2.2352e-07      4.7205 ]
                         :  gm1eerror:  0.00013603  0.00032108   [  1.8598e-06   0.0088087 ]
                         :  gm2eerror:  2.6368e-05  6.7854e-05   [  1.7062e-06   0.0015329 ]
                         :   gm1p3cms:     0.55257     0.56342   [    0.048464      6.9342 ]
                         :   gm2p3cms:     0.22493     0.23396   [    0.043817      2.6974 ]
                         : gmthetacms:     0.72747     0.52318   [    0.044029      3.0902 ]
                         :     mfchi2:      8.7557      11.432   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59789     0.55490   [   0.0049119      4.9404 ]
                         :   pi0p3cms:     0.75554     0.74358   [    0.011479      7.1892 ]
                         :       gm1e:     0.44251     0.41797   [    0.063063      4.8358 ]
                         :       gm2e:     0.18208     0.17424   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95285    0.061070   [     0.21284      1.0000 ]
                         :    gm2e925:     0.95285    0.061070   [     0.21284      1.0000 ]
                         :      ediff:     0.26043     0.34430   [  2.2352e-07      4.7205 ]
                         :  gm1eerror:  0.00013603  0.00032108   [  1.8598e-06   0.0088087 ]
                         :  gm2eerror:  2.6368e-05  6.7854e-05   [  1.7062e-06   0.0015329 ]
                         :   gm1p3cms:     0.55257     0.56342   [    0.048464      6.9342 ]
                         :   gm2p3cms:     0.22493     0.23396   [    0.043817      2.6974 ]
                         : gmthetacms:     0.72747     0.52318   [    0.044029      3.0902 ]
                         :     mfchi2:      8.7557      11.432   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       GTB            : 0.869
                         : dataset       PyKeras        : 0.868
                         : dataset       BDT            : 0.864
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              GTB            : 0.258 (0.431)       0.653 (0.734)      0.854 (0.886)
                         : dataset              PyKeras        : 0.252 (0.266)       0.654 (0.658)      0.852 (0.858)
                         : dataset              BDT            : 0.000 (0.000)       0.647 (0.656)      0.847 (0.851)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 20000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 20000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
