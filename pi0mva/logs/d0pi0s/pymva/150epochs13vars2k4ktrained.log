DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : [1mTrain all methods[0m
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 2000
                         : Signal     -- testing events             : 2000
                         : Signal     -- training and testing events: 4000
                         : Background -- training events            : 4000
                         : Background -- testing events             : 4000
                         : Background -- training and testing events: 8000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.974  +0.956  +0.746  -0.173  -0.173  +0.733    +0.822    +0.633   +0.936   +0.752     -0.682  -0.203
                         :   pi0p3cms:  +0.974   +1.000  +0.934  +0.724  -0.160  -0.160  +0.718    +0.826    +0.631   +0.962   +0.771     -0.669  -0.183
                         :       gm1e:  +0.956   +0.934  +1.000  +0.520  -0.111  -0.111  +0.900    +0.884    +0.438   +0.976   +0.538     -0.615  -0.182
                         :       gm2e:  +0.746   +0.724  +0.520  +1.000  -0.259  -0.259  +0.095    +0.402    +0.862   +0.517   +0.977     -0.558  -0.191
                         :    gm1e925:  -0.173   -0.160  -0.111  -0.259  +1.000  +1.000  +0.004    -0.082    -0.282   -0.104   -0.242     +0.063  -0.026
                         :    gm2e925:  -0.173   -0.160  -0.111  -0.259  +1.000  +1.000  +0.004    -0.082    -0.282   -0.104   -0.242     +0.063  -0.026
                         :      ediff:  +0.733   +0.718  +0.900  +0.095  +0.004  +0.004  +1.000    +0.825    +0.070   +0.873   +0.128     -0.431  -0.115
                         :  gm1eerror:  +0.822   +0.826  +0.884  +0.402  -0.082  -0.082  +0.825    +1.000    +0.372   +0.885   +0.432     -0.408  -0.130
                         :  gm2eerror:  +0.633   +0.631  +0.438  +0.862  -0.282  -0.282  +0.070    +0.372    +1.000   +0.447   +0.863     -0.379  -0.138
                         :   gm1p3cms:  +0.936   +0.962  +0.976  +0.517  -0.104  -0.104  +0.873    +0.885    +0.447   +1.000   +0.568     -0.610  -0.167
                         :   gm2p3cms:  +0.752   +0.771  +0.538  +0.977  -0.242  -0.242  +0.128    +0.432    +0.863   +0.568   +1.000     -0.565  -0.176
                         : gmthetacms:  -0.682   -0.669  -0.615  -0.558  +0.063  +0.063  -0.431    -0.408    -0.379   -0.610   -0.565     +1.000  +0.202
                         :     mfchi2:  -0.203   -0.183  -0.182  -0.191  -0.026  -0.026  -0.115    -0.130    -0.138   -0.167   -0.176     +0.202  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.974  +0.967  +0.636  -0.075  -0.075  +0.856    +0.783    +0.491   +0.949   +0.636     -0.712  -0.139
                         :   pi0p3cms:  +0.974   +1.000  +0.943  +0.626  -0.071  -0.071  +0.832    +0.780    +0.498   +0.970   +0.669     -0.724  -0.128
                         :       gm1e:  +0.967   +0.943  +1.000  +0.437  -0.067  -0.067  +0.956    +0.837    +0.335   +0.977   +0.448     -0.615  -0.138
                         :       gm2e:  +0.636   +0.626  +0.437  +1.000  -0.071  -0.071  +0.154    +0.309    +0.813   +0.441   +0.960     -0.548  -0.116
                         :    gm1e925:  -0.075   -0.071  -0.067  -0.071  +1.000  +1.000  -0.050    -0.036    -0.062   -0.064   -0.067     +0.048  -0.025
                         :    gm2e925:  -0.075   -0.071  -0.067  -0.071  +1.000  +1.000  -0.050    -0.036    -0.062   -0.064   -0.067     +0.048  -0.025
                         :      ediff:  +0.856   +0.832  +0.956  +0.154  -0.050  -0.050  +1.000    +0.819    +0.103   +0.930   +0.180     -0.497  -0.114
                         :  gm1eerror:  +0.783   +0.780  +0.837  +0.309  -0.036  -0.036  +0.819    +1.000    +0.251   +0.831   +0.330     -0.375  -0.122
                         :  gm2eerror:  +0.491   +0.498  +0.335  +0.813  -0.062  -0.062  +0.103    +0.251    +1.000   +0.347   +0.804     -0.337  -0.099
                         :   gm1p3cms:  +0.949   +0.970  +0.977  +0.441  -0.064  -0.064  +0.930    +0.831    +0.347   +1.000   +0.480     -0.633  -0.127
                         :   gm2p3cms:  +0.636   +0.669  +0.448  +0.960  -0.067  -0.067  +0.180    +0.330    +0.804   +0.480   +1.000     -0.589  -0.109
                         : gmthetacms:  -0.712   -0.724  -0.615  -0.548  +0.048  +0.048  -0.497    -0.375    -0.337   -0.633   -0.589     +1.000  +0.079
                         :     mfchi2:  -0.139   -0.128  -0.138  -0.116  -0.025  -0.025  -0.114    -0.122    -0.099   -0.127   -0.109     +0.079  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.010018     0.99927   [     -3.0306      5.7307 ]
                         :   pi0p3cms:   0.0093802     0.99589   [     -3.0314      5.7307 ]
                         :       gm1e:    0.010256     0.99967   [     -3.0273      5.7307 ]
                         :       gm2e:    0.010133     0.99968   [     -2.8853      5.7307 ]
                         :    gm1e925:     0.83941      2.2134   [     -2.9863      5.7307 ]
                         :    gm2e925:     0.83941      2.2134   [     -2.9863      5.7307 ]
                         :      ediff:    0.010912      1.0035   [     -2.8887      5.7307 ]
                         :  gm1eerror:    0.010958     0.99762   [     -2.7514      5.7307 ]
                         :  gm2eerror:    0.011029     0.99754   [     -2.7816      5.7307 ]
                         :   gm1p3cms:   0.0099289     0.99842   [     -3.0243      5.7307 ]
                         :   gm2p3cms:    0.010637      1.0020   [     -3.0096      5.7307 ]
                         : gmthetacms:   0.0096816     0.99763   [     -3.0311      5.7307 ]
                         :     mfchi2:    0.013983     0.99497   [     -2.2073      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 3.067e-01
                         :    2 : gm1e       : 2.729e-01
                         :    3 : gmthetacms : 2.708e-01
                         :    4 : pi0p3cms   : 2.624e-01
                         :    5 : gm2e       : 2.543e-01
                         :    6 : gm1eerror  : 2.539e-01
                         :    7 : mfchi2     : 2.469e-01
                         :    8 : gm1p3cms   : 2.350e-01
                         :    9 : gm2eerror  : 2.344e-01
                         :   10 : gm2p3cms   : 2.120e-01
                         :   11 : ediff      : 1.374e-01
                         :   12 : gm1e925    : 8.489e-02
                         :   13 : gm2e925    : 8.489e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.010018     0.99927   [     -3.0306      5.7307 ]
                         :   pi0p3cms:   0.0093802     0.99589   [     -3.0314      5.7307 ]
                         :       gm1e:    0.010256     0.99967   [     -3.0273      5.7307 ]
                         :       gm2e:    0.010133     0.99968   [     -2.8853      5.7307 ]
                         :    gm1e925:     0.83941      2.2134   [     -2.9863      5.7307 ]
                         :    gm2e925:     0.83941      2.2134   [     -2.9863      5.7307 ]
                         :      ediff:    0.010912      1.0035   [     -2.8887      5.7307 ]
                         :  gm1eerror:    0.010958     0.99762   [     -2.7514      5.7307 ]
                         :  gm2eerror:    0.011029     0.99754   [     -2.7816      5.7307 ]
                         :   gm1p3cms:   0.0099289     0.99842   [     -3.0243      5.7307 ]
                         :   gm2p3cms:    0.010637      1.0020   [     -3.0096      5.7307 ]
                         : gmthetacms:   0.0096816     0.99763   [     -3.0311      5.7307 ]
                         :     mfchi2:    0.013983     0.99497   [     -2.2073      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 6000 samples, validate on 6000 samples
Epoch 1/150

  32/6000 [..............................] - ETA: 29s - loss: 0.9841 - categorical_accuracy: 0.5938
1504/6000 [======>.......................] - ETA: 0s - loss: 0.7067 - categorical_accuracy: 0.6483 
3136/6000 [==============>...............] - ETA: 0s - loss: 0.6378 - categorical_accuracy: 0.6834
4736/6000 [======================>.......] - ETA: 0s - loss: 0.5981 - categorical_accuracy: 0.7014
6000/6000 [==============================] - 0s 83us/step - loss: 0.5776 - categorical_accuracy: 0.7145 - val_loss: 0.4571 - val_categorical_accuracy: 0.7902

Epoch 00001: val_loss improved from inf to 0.45711, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5607 - categorical_accuracy: 0.6250
1504/6000 [======>.......................] - ETA: 0s - loss: 0.5145 - categorical_accuracy: 0.7653
3200/6000 [===============>..............] - ETA: 0s - loss: 0.5163 - categorical_accuracy: 0.7619
4768/6000 [======================>.......] - ETA: 0s - loss: 0.5034 - categorical_accuracy: 0.7678
6000/6000 [==============================] - 0s 51us/step - loss: 0.4988 - categorical_accuracy: 0.7703 - val_loss: 0.4408 - val_categorical_accuracy: 0.8013

Epoch 00002: val_loss improved from 0.45711 to 0.44082, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3420 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4776 - categorical_accuracy: 0.7788
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4739 - categorical_accuracy: 0.7859
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4716 - categorical_accuracy: 0.7930
6000/6000 [==============================] - 0s 50us/step - loss: 0.4731 - categorical_accuracy: 0.7890 - val_loss: 0.4349 - val_categorical_accuracy: 0.8100

Epoch 00003: val_loss improved from 0.44082 to 0.43485, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4071 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4672 - categorical_accuracy: 0.7844
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4685 - categorical_accuracy: 0.7856
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4635 - categorical_accuracy: 0.7888
6000/6000 [==============================] - 0s 52us/step - loss: 0.4564 - categorical_accuracy: 0.7915 - val_loss: 0.4287 - val_categorical_accuracy: 0.8123

Epoch 00004: val_loss improved from 0.43485 to 0.42871, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4466 - categorical_accuracy: 0.7812
1504/6000 [======>.......................] - ETA: 0s - loss: 0.4531 - categorical_accuracy: 0.8019
3104/6000 [==============>...............] - ETA: 0s - loss: 0.4637 - categorical_accuracy: 0.7948
4608/6000 [======================>.......] - ETA: 0s - loss: 0.4564 - categorical_accuracy: 0.7971
5792/6000 [===========================>..] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.7939
6000/6000 [==============================] - 0s 58us/step - loss: 0.4609 - categorical_accuracy: 0.7950 - val_loss: 0.4340 - val_categorical_accuracy: 0.8125

Epoch 00005: val_loss did not improve from 0.42871
Epoch 6/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.7500
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4484 - categorical_accuracy: 0.8101
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4664 - categorical_accuracy: 0.7946
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4620 - categorical_accuracy: 0.7984
6000/6000 [==============================] - 0s 50us/step - loss: 0.4601 - categorical_accuracy: 0.7982 - val_loss: 0.4266 - val_categorical_accuracy: 0.8150

Epoch 00006: val_loss improved from 0.42871 to 0.42665, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.8750
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4200 - categorical_accuracy: 0.8214
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4442 - categorical_accuracy: 0.8044
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4508 - categorical_accuracy: 0.8004
6000/6000 [==============================] - 0s 50us/step - loss: 0.4554 - categorical_accuracy: 0.7965 - val_loss: 0.4257 - val_categorical_accuracy: 0.8188

Epoch 00007: val_loss improved from 0.42665 to 0.42573, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4207 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4439 - categorical_accuracy: 0.7994
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4435 - categorical_accuracy: 0.8054
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4448 - categorical_accuracy: 0.8049
6000/6000 [==============================] - 0s 50us/step - loss: 0.4519 - categorical_accuracy: 0.8037 - val_loss: 0.4272 - val_categorical_accuracy: 0.8180

Epoch 00008: val_loss did not improve from 0.42573
Epoch 9/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4790 - categorical_accuracy: 0.8125
1440/6000 [======>.......................] - ETA: 0s - loss: 0.4584 - categorical_accuracy: 0.7972
3104/6000 [==============>...............] - ETA: 0s - loss: 0.4494 - categorical_accuracy: 0.8022
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4547 - categorical_accuracy: 0.8025
6000/6000 [==============================] - 0s 50us/step - loss: 0.4507 - categorical_accuracy: 0.8028 - val_loss: 0.4217 - val_categorical_accuracy: 0.8193

Epoch 00009: val_loss improved from 0.42573 to 0.42172, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 10/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3653 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4456 - categorical_accuracy: 0.8156
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4467 - categorical_accuracy: 0.8091
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4439 - categorical_accuracy: 0.8070
6000/6000 [==============================] - 0s 50us/step - loss: 0.4440 - categorical_accuracy: 0.8067 - val_loss: 0.4200 - val_categorical_accuracy: 0.8193

Epoch 00010: val_loss improved from 0.42172 to 0.41999, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 11/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3219 - categorical_accuracy: 0.8125
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4561 - categorical_accuracy: 0.7855
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4433 - categorical_accuracy: 0.7983
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4441 - categorical_accuracy: 0.7986
6000/6000 [==============================] - 0s 50us/step - loss: 0.4431 - categorical_accuracy: 0.8032 - val_loss: 0.4197 - val_categorical_accuracy: 0.8162

Epoch 00011: val_loss improved from 0.41999 to 0.41966, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 12/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3007 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4209 - categorical_accuracy: 0.8094
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4407 - categorical_accuracy: 0.8070
4960/6000 [=======================>......] - ETA: 0s - loss: 0.4377 - categorical_accuracy: 0.8089
6000/6000 [==============================] - 0s 50us/step - loss: 0.4423 - categorical_accuracy: 0.8047 - val_loss: 0.4209 - val_categorical_accuracy: 0.8188

Epoch 00012: val_loss did not improve from 0.41966
Epoch 13/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4670 - categorical_accuracy: 0.7188
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4510 - categorical_accuracy: 0.8009
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4497 - categorical_accuracy: 0.8041
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4445 - categorical_accuracy: 0.8052
6000/6000 [==============================] - 0s 50us/step - loss: 0.4434 - categorical_accuracy: 0.8072 - val_loss: 0.4170 - val_categorical_accuracy: 0.8180

Epoch 00013: val_loss improved from 0.41966 to 0.41702, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 14/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3944 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4259 - categorical_accuracy: 0.8181
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4273 - categorical_accuracy: 0.8150
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4407 - categorical_accuracy: 0.8096
6000/6000 [==============================] - 0s 50us/step - loss: 0.4356 - categorical_accuracy: 0.8125 - val_loss: 0.4168 - val_categorical_accuracy: 0.8195

Epoch 00014: val_loss improved from 0.41702 to 0.41683, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 15/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2279 - categorical_accuracy: 0.9688
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4257 - categorical_accuracy: 0.8156
3136/6000 [==============>...............] - ETA: 0s - loss: 0.4387 - categorical_accuracy: 0.8099
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4282 - categorical_accuracy: 0.8167
6000/6000 [==============================] - 0s 50us/step - loss: 0.4331 - categorical_accuracy: 0.8153 - val_loss: 0.4180 - val_categorical_accuracy: 0.8177

Epoch 00015: val_loss did not improve from 0.41683
Epoch 16/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5389 - categorical_accuracy: 0.7188
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4310 - categorical_accuracy: 0.8163
3136/6000 [==============>...............] - ETA: 0s - loss: 0.4402 - categorical_accuracy: 0.8144
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4356 - categorical_accuracy: 0.8148
6000/6000 [==============================] - 0s 51us/step - loss: 0.4369 - categorical_accuracy: 0.8155 - val_loss: 0.4173 - val_categorical_accuracy: 0.8193

Epoch 00016: val_loss did not improve from 0.41683
Epoch 17/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4512 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.7904
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4460 - categorical_accuracy: 0.8062
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4405 - categorical_accuracy: 0.8085
6000/6000 [==============================] - 0s 50us/step - loss: 0.4370 - categorical_accuracy: 0.8115 - val_loss: 0.4156 - val_categorical_accuracy: 0.8202

Epoch 00017: val_loss improved from 0.41683 to 0.41563, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 18/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.7812
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4362 - categorical_accuracy: 0.8190
3104/6000 [==============>...............] - ETA: 0s - loss: 0.4406 - categorical_accuracy: 0.8151
4672/6000 [======================>.......] - ETA: 0s - loss: 0.4363 - categorical_accuracy: 0.8181
6000/6000 [==============================] - 0s 51us/step - loss: 0.4380 - categorical_accuracy: 0.8173 - val_loss: 0.4138 - val_categorical_accuracy: 0.8195

Epoch 00018: val_loss improved from 0.41563 to 0.41376, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 19/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2420 - categorical_accuracy: 0.9375
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4271 - categorical_accuracy: 0.8138
2944/6000 [=============>................] - ETA: 0s - loss: 0.4492 - categorical_accuracy: 0.8033
3968/6000 [==================>...........] - ETA: 0s - loss: 0.4369 - categorical_accuracy: 0.8117
4960/6000 [=======================>......] - ETA: 0s - loss: 0.4307 - categorical_accuracy: 0.8157
6000/6000 [==============================] - 0s 70us/step - loss: 0.4342 - categorical_accuracy: 0.8127 - val_loss: 0.4135 - val_categorical_accuracy: 0.8200

Epoch 00019: val_loss improved from 0.41376 to 0.41347, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 20/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4305 - categorical_accuracy: 0.7500
1152/6000 [====>.........................] - ETA: 0s - loss: 0.4693 - categorical_accuracy: 0.7804
2240/6000 [==========>...................] - ETA: 0s - loss: 0.4428 - categorical_accuracy: 0.8049
3552/6000 [================>.............] - ETA: 0s - loss: 0.4373 - categorical_accuracy: 0.8091
5152/6000 [========================>.....] - ETA: 0s - loss: 0.4336 - categorical_accuracy: 0.8100
6000/6000 [==============================] - 0s 58us/step - loss: 0.4291 - categorical_accuracy: 0.8123 - val_loss: 0.4124 - val_categorical_accuracy: 0.8197

Epoch 00020: val_loss improved from 0.41347 to 0.41237, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 21/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4567 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4428 - categorical_accuracy: 0.7944
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4382 - categorical_accuracy: 0.8071
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4286 - categorical_accuracy: 0.8121
6000/6000 [==============================] - 0s 50us/step - loss: 0.4259 - categorical_accuracy: 0.8138 - val_loss: 0.4123 - val_categorical_accuracy: 0.8205

Epoch 00021: val_loss improved from 0.41237 to 0.41229, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 22/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3395 - categorical_accuracy: 0.8750
1280/6000 [=====>........................] - ETA: 0s - loss: 0.4138 - categorical_accuracy: 0.8156
2784/6000 [============>.................] - ETA: 0s - loss: 0.4174 - categorical_accuracy: 0.8186
4448/6000 [=====================>........] - ETA: 0s - loss: 0.4227 - categorical_accuracy: 0.8150
6000/6000 [==============================] - 0s 52us/step - loss: 0.4308 - categorical_accuracy: 0.8117 - val_loss: 0.4158 - val_categorical_accuracy: 0.8200

Epoch 00022: val_loss did not improve from 0.41229
Epoch 23/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3561 - categorical_accuracy: 0.8750
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4364 - categorical_accuracy: 0.8042
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4301 - categorical_accuracy: 0.8147
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4289 - categorical_accuracy: 0.8139
6000/6000 [==============================] - 0s 50us/step - loss: 0.4251 - categorical_accuracy: 0.8173 - val_loss: 0.4167 - val_categorical_accuracy: 0.8178

Epoch 00023: val_loss did not improve from 0.41229
Epoch 24/150

  32/6000 [..............................] - ETA: 0s - loss: 0.6737 - categorical_accuracy: 0.7500
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4394 - categorical_accuracy: 0.8144
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4286 - categorical_accuracy: 0.8218
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4274 - categorical_accuracy: 0.8243
6000/6000 [==============================] - 0s 49us/step - loss: 0.4277 - categorical_accuracy: 0.8217 - val_loss: 0.4129 - val_categorical_accuracy: 0.8203

Epoch 00024: val_loss did not improve from 0.41229
Epoch 25/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2976 - categorical_accuracy: 0.8750
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4357 - categorical_accuracy: 0.8156
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4342 - categorical_accuracy: 0.8162
4672/6000 [======================>.......] - ETA: 0s - loss: 0.4340 - categorical_accuracy: 0.8168
6000/6000 [==============================] - 0s 51us/step - loss: 0.4309 - categorical_accuracy: 0.8162 - val_loss: 0.4122 - val_categorical_accuracy: 0.8202

Epoch 00025: val_loss improved from 0.41229 to 0.41223, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 26/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3885 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4129 - categorical_accuracy: 0.8325
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4349 - categorical_accuracy: 0.8166
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4298 - categorical_accuracy: 0.8171
6000/6000 [==============================] - 0s 51us/step - loss: 0.4264 - categorical_accuracy: 0.8182 - val_loss: 0.4128 - val_categorical_accuracy: 0.8172

Epoch 00026: val_loss did not improve from 0.41223
Epoch 27/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3955 - categorical_accuracy: 0.8438
1504/6000 [======>.......................] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.8185
2976/6000 [=============>................] - ETA: 0s - loss: 0.4279 - categorical_accuracy: 0.8179
4480/6000 [=====================>........] - ETA: 0s - loss: 0.4315 - categorical_accuracy: 0.8170
6000/6000 [==============================] - 0s 52us/step - loss: 0.4302 - categorical_accuracy: 0.8143 - val_loss: 0.4120 - val_categorical_accuracy: 0.8208

Epoch 00027: val_loss improved from 0.41223 to 0.41196, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 28/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3448 - categorical_accuracy: 0.9062
1568/6000 [======>.......................] - ETA: 0s - loss: 0.3812 - categorical_accuracy: 0.8476
3040/6000 [==============>...............] - ETA: 0s - loss: 0.4025 - categorical_accuracy: 0.8329
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4187 - categorical_accuracy: 0.8212
6000/6000 [==============================] - 0s 51us/step - loss: 0.4220 - categorical_accuracy: 0.8182 - val_loss: 0.4116 - val_categorical_accuracy: 0.8212

Epoch 00028: val_loss improved from 0.41196 to 0.41157, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 29/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3530 - categorical_accuracy: 0.9062
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4364 - categorical_accuracy: 0.8076
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4256 - categorical_accuracy: 0.8150
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4218 - categorical_accuracy: 0.8172
6000/6000 [==============================] - 0s 50us/step - loss: 0.4277 - categorical_accuracy: 0.8127 - val_loss: 0.4134 - val_categorical_accuracy: 0.8190

Epoch 00029: val_loss did not improve from 0.41157
Epoch 30/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4251 - categorical_accuracy: 0.8750
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4385 - categorical_accuracy: 0.8095
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4285 - categorical_accuracy: 0.8134
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4281 - categorical_accuracy: 0.8146
6000/6000 [==============================] - 0s 50us/step - loss: 0.4223 - categorical_accuracy: 0.8198 - val_loss: 0.4100 - val_categorical_accuracy: 0.8205

Epoch 00030: val_loss improved from 0.41157 to 0.41001, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 31/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3380 - categorical_accuracy: 0.8750
1504/6000 [======>.......................] - ETA: 0s - loss: 0.4247 - categorical_accuracy: 0.8152
3104/6000 [==============>...............] - ETA: 0s - loss: 0.4191 - categorical_accuracy: 0.8170
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4233 - categorical_accuracy: 0.8180
6000/6000 [==============================] - 0s 50us/step - loss: 0.4281 - categorical_accuracy: 0.8193 - val_loss: 0.4131 - val_categorical_accuracy: 0.8222

Epoch 00031: val_loss did not improve from 0.41001
Epoch 32/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3520 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4308 - categorical_accuracy: 0.8186
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4214 - categorical_accuracy: 0.8208
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4176 - categorical_accuracy: 0.8203
6000/6000 [==============================] - 0s 50us/step - loss: 0.4186 - categorical_accuracy: 0.8202 - val_loss: 0.4099 - val_categorical_accuracy: 0.8187

Epoch 00032: val_loss improved from 0.41001 to 0.40988, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 33/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4359 - categorical_accuracy: 0.8143
3136/6000 [==============>...............] - ETA: 0s - loss: 0.4362 - categorical_accuracy: 0.8160
4608/6000 [======================>.......] - ETA: 0s - loss: 0.4378 - categorical_accuracy: 0.8129
6000/6000 [==============================] - 0s 52us/step - loss: 0.4298 - categorical_accuracy: 0.8170 - val_loss: 0.4097 - val_categorical_accuracy: 0.8207

Epoch 00033: val_loss improved from 0.40988 to 0.40966, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 34/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2789 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4111 - categorical_accuracy: 0.8238
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4169 - categorical_accuracy: 0.8225
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4221 - categorical_accuracy: 0.8205
6000/6000 [==============================] - 0s 51us/step - loss: 0.4237 - categorical_accuracy: 0.8193 - val_loss: 0.4124 - val_categorical_accuracy: 0.8223

Epoch 00034: val_loss did not improve from 0.40966
Epoch 35/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3536 - categorical_accuracy: 0.8438
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4273 - categorical_accuracy: 0.8149
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4248 - categorical_accuracy: 0.8178
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4219 - categorical_accuracy: 0.8169
6000/6000 [==============================] - 0s 50us/step - loss: 0.4223 - categorical_accuracy: 0.8165 - val_loss: 0.4130 - val_categorical_accuracy: 0.8195

Epoch 00035: val_loss did not improve from 0.40966
Epoch 36/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3317 - categorical_accuracy: 0.8750
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8311
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4189 - categorical_accuracy: 0.8180
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4230 - categorical_accuracy: 0.8211
6000/6000 [==============================] - 0s 51us/step - loss: 0.4219 - categorical_accuracy: 0.8202 - val_loss: 0.4103 - val_categorical_accuracy: 0.8197

Epoch 00036: val_loss did not improve from 0.40966
Epoch 37/150

  32/6000 [..............................] - ETA: 0s - loss: 0.6215 - categorical_accuracy: 0.6875
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4486 - categorical_accuracy: 0.8037
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4311 - categorical_accuracy: 0.8171
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4285 - categorical_accuracy: 0.8185
6000/6000 [==============================] - 0s 50us/step - loss: 0.4213 - categorical_accuracy: 0.8215 - val_loss: 0.4091 - val_categorical_accuracy: 0.8208

Epoch 00037: val_loss improved from 0.40966 to 0.40906, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 38/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5046 - categorical_accuracy: 0.8438
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4276 - categorical_accuracy: 0.8060
2944/6000 [=============>................] - ETA: 0s - loss: 0.4191 - categorical_accuracy: 0.8139
4544/6000 [=====================>........] - ETA: 0s - loss: 0.4208 - categorical_accuracy: 0.8171
6000/6000 [==============================] - 0s 52us/step - loss: 0.4238 - categorical_accuracy: 0.8153 - val_loss: 0.4113 - val_categorical_accuracy: 0.8217

Epoch 00038: val_loss did not improve from 0.40906
Epoch 39/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3092 - categorical_accuracy: 0.8438
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4181 - categorical_accuracy: 0.8189
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4166 - categorical_accuracy: 0.8226
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4143 - categorical_accuracy: 0.8240
6000/6000 [==============================] - 0s 51us/step - loss: 0.4209 - categorical_accuracy: 0.8193 - val_loss: 0.4096 - val_categorical_accuracy: 0.8207

Epoch 00039: val_loss did not improve from 0.40906
Epoch 40/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3462 - categorical_accuracy: 0.9062
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4272 - categorical_accuracy: 0.8223
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4233 - categorical_accuracy: 0.8235
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.8212
6000/6000 [==============================] - 0s 50us/step - loss: 0.4243 - categorical_accuracy: 0.8222 - val_loss: 0.4143 - val_categorical_accuracy: 0.8192

Epoch 00040: val_loss did not improve from 0.40906
Epoch 41/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5480 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.3963 - categorical_accuracy: 0.8278
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4058 - categorical_accuracy: 0.8261
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4199 - categorical_accuracy: 0.8189
6000/6000 [==============================] - 0s 50us/step - loss: 0.4231 - categorical_accuracy: 0.8180 - val_loss: 0.4138 - val_categorical_accuracy: 0.8207

Epoch 00041: val_loss did not improve from 0.40906
Epoch 42/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3220 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8300
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4252 - categorical_accuracy: 0.8186
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4271 - categorical_accuracy: 0.8169
6000/6000 [==============================] - 0s 51us/step - loss: 0.4270 - categorical_accuracy: 0.8185 - val_loss: 0.4100 - val_categorical_accuracy: 0.8218

Epoch 00042: val_loss did not improve from 0.40906
Epoch 43/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4451 - categorical_accuracy: 0.7500
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4285 - categorical_accuracy: 0.8208
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4233 - categorical_accuracy: 0.8187
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4251 - categorical_accuracy: 0.8200
6000/6000 [==============================] - 0s 51us/step - loss: 0.4230 - categorical_accuracy: 0.8188 - val_loss: 0.4097 - val_categorical_accuracy: 0.8212

Epoch 00043: val_loss did not improve from 0.40906
Epoch 44/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3875 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4205 - categorical_accuracy: 0.8223
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4259 - categorical_accuracy: 0.8171
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4259 - categorical_accuracy: 0.8183
6000/6000 [==============================] - 0s 51us/step - loss: 0.4244 - categorical_accuracy: 0.8202 - val_loss: 0.4114 - val_categorical_accuracy: 0.8220

Epoch 00044: val_loss did not improve from 0.40906
Epoch 45/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2936 - categorical_accuracy: 0.9375
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4231 - categorical_accuracy: 0.8179
3328/6000 [===============>..............] - ETA: 0s - loss: 0.4325 - categorical_accuracy: 0.8107
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4337 - categorical_accuracy: 0.8121
6000/6000 [==============================] - 0s 50us/step - loss: 0.4272 - categorical_accuracy: 0.8168 - val_loss: 0.4085 - val_categorical_accuracy: 0.8207

Epoch 00045: val_loss improved from 0.40906 to 0.40846, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 46/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5930 - categorical_accuracy: 0.6562
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4440 - categorical_accuracy: 0.8064
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4282 - categorical_accuracy: 0.8144
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4202 - categorical_accuracy: 0.8180
6000/6000 [==============================] - 0s 52us/step - loss: 0.4195 - categorical_accuracy: 0.8183 - val_loss: 0.4102 - val_categorical_accuracy: 0.8200

Epoch 00046: val_loss did not improve from 0.40846
Epoch 47/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3883 - categorical_accuracy: 0.8125
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4118 - categorical_accuracy: 0.8233
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4183 - categorical_accuracy: 0.8192
4928/6000 [=======================>......] - ETA: 0s - loss: 0.4189 - categorical_accuracy: 0.8182
6000/6000 [==============================] - 0s 50us/step - loss: 0.4178 - categorical_accuracy: 0.8202 - val_loss: 0.4099 - val_categorical_accuracy: 0.8195

Epoch 00047: val_loss did not improve from 0.40846
Epoch 48/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4721 - categorical_accuracy: 0.7812
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.8221
3328/6000 [===============>..............] - ETA: 0s - loss: 0.4223 - categorical_accuracy: 0.8134
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4215 - categorical_accuracy: 0.8141
6000/6000 [==============================] - 0s 50us/step - loss: 0.4190 - categorical_accuracy: 0.8177 - val_loss: 0.4105 - val_categorical_accuracy: 0.8187

Epoch 00048: val_loss did not improve from 0.40846
Epoch 49/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.8125
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4168 - categorical_accuracy: 0.8185
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4172 - categorical_accuracy: 0.8153
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4186 - categorical_accuracy: 0.8170
6000/6000 [==============================] - 0s 51us/step - loss: 0.4210 - categorical_accuracy: 0.8167 - val_loss: 0.4100 - val_categorical_accuracy: 0.8198

Epoch 00049: val_loss did not improve from 0.40846
Epoch 50/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5173 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4203 - categorical_accuracy: 0.8211
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4241 - categorical_accuracy: 0.8180
4928/6000 [=======================>......] - ETA: 0s - loss: 0.4201 - categorical_accuracy: 0.8174
6000/6000 [==============================] - 0s 49us/step - loss: 0.4230 - categorical_accuracy: 0.8173 - val_loss: 0.4112 - val_categorical_accuracy: 0.8213

Epoch 00050: val_loss did not improve from 0.40846
Epoch 51/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2339 - categorical_accuracy: 0.9375
1504/6000 [======>.......................] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8185
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4220 - categorical_accuracy: 0.8166
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4176 - categorical_accuracy: 0.8207
6000/6000 [==============================] - 0s 51us/step - loss: 0.4207 - categorical_accuracy: 0.8200 - val_loss: 0.4111 - val_categorical_accuracy: 0.8200

Epoch 00051: val_loss did not improve from 0.40846
Epoch 52/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4323 - categorical_accuracy: 0.7812
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4329 - categorical_accuracy: 0.8205
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4190 - categorical_accuracy: 0.8225
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4165 - categorical_accuracy: 0.8235
6000/6000 [==============================] - 0s 50us/step - loss: 0.4191 - categorical_accuracy: 0.8215 - val_loss: 0.4115 - val_categorical_accuracy: 0.8203

Epoch 00052: val_loss did not improve from 0.40846
Epoch 53/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4988 - categorical_accuracy: 0.7188
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4265 - categorical_accuracy: 0.8042
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4094 - categorical_accuracy: 0.8190
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4132 - categorical_accuracy: 0.8191
6000/6000 [==============================] - 0s 50us/step - loss: 0.4161 - categorical_accuracy: 0.8193 - val_loss: 0.4099 - val_categorical_accuracy: 0.8182

Epoch 00053: val_loss did not improve from 0.40846
Epoch 54/150

  32/6000 [..............................] - ETA: 0s - loss: 0.6760 - categorical_accuracy: 0.7188
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4321 - categorical_accuracy: 0.8070
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4094 - categorical_accuracy: 0.8237
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4172 - categorical_accuracy: 0.8207
6000/6000 [==============================] - 0s 50us/step - loss: 0.4201 - categorical_accuracy: 0.8187 - val_loss: 0.4107 - val_categorical_accuracy: 0.8200

Epoch 00054: val_loss did not improve from 0.40846
Epoch 55/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3522 - categorical_accuracy: 0.8438
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4025 - categorical_accuracy: 0.8305
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4195 - categorical_accuracy: 0.8189
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4202 - categorical_accuracy: 0.8158
6000/6000 [==============================] - 0s 49us/step - loss: 0.4173 - categorical_accuracy: 0.8180 - val_loss: 0.4121 - val_categorical_accuracy: 0.8207

Epoch 00055: val_loss did not improve from 0.40846
Epoch 56/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5406 - categorical_accuracy: 0.7812
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4240 - categorical_accuracy: 0.8144
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4237 - categorical_accuracy: 0.8163
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4247 - categorical_accuracy: 0.8177
6000/6000 [==============================] - 0s 50us/step - loss: 0.4218 - categorical_accuracy: 0.8207 - val_loss: 0.4115 - val_categorical_accuracy: 0.8173

Epoch 00056: val_loss did not improve from 0.40846
Epoch 57/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3956 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.3935 - categorical_accuracy: 0.8376
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4152 - categorical_accuracy: 0.8228
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4122 - categorical_accuracy: 0.8215
6000/6000 [==============================] - 0s 50us/step - loss: 0.4155 - categorical_accuracy: 0.8187 - val_loss: 0.4093 - val_categorical_accuracy: 0.8185

Epoch 00057: val_loss did not improve from 0.40846
Epoch 58/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4092 - categorical_accuracy: 0.7812
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4047 - categorical_accuracy: 0.8278
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4116 - categorical_accuracy: 0.8213
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4160 - categorical_accuracy: 0.8191
6000/6000 [==============================] - 0s 50us/step - loss: 0.4166 - categorical_accuracy: 0.8185 - val_loss: 0.4127 - val_categorical_accuracy: 0.8190

Epoch 00058: val_loss did not improve from 0.40846
Epoch 59/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4605 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4339 - categorical_accuracy: 0.8033
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4266 - categorical_accuracy: 0.8113
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4235 - categorical_accuracy: 0.8148
6000/6000 [==============================] - 0s 50us/step - loss: 0.4186 - categorical_accuracy: 0.8180 - val_loss: 0.4101 - val_categorical_accuracy: 0.8175

Epoch 00059: val_loss did not improve from 0.40846
Epoch 60/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2159 - categorical_accuracy: 0.9062
1440/6000 [======>.......................] - ETA: 0s - loss: 0.4253 - categorical_accuracy: 0.8132
3072/6000 [==============>...............] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.8158
4672/6000 [======================>.......] - ETA: 0s - loss: 0.4231 - categorical_accuracy: 0.8172
6000/6000 [==============================] - 0s 51us/step - loss: 0.4228 - categorical_accuracy: 0.8173 - val_loss: 0.4108 - val_categorical_accuracy: 0.8187

Epoch 00060: val_loss did not improve from 0.40846
Epoch 61/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2835 - categorical_accuracy: 0.9375
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4187 - categorical_accuracy: 0.8329
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4140 - categorical_accuracy: 0.8298
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4175 - categorical_accuracy: 0.8241
6000/6000 [==============================] - 0s 50us/step - loss: 0.4174 - categorical_accuracy: 0.8230 - val_loss: 0.4131 - val_categorical_accuracy: 0.8162

Epoch 00061: val_loss did not improve from 0.40846
Epoch 62/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3584 - categorical_accuracy: 0.8438
1664/6000 [=======>......................] - ETA: 0s - loss: 0.3862 - categorical_accuracy: 0.8516
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4123 - categorical_accuracy: 0.8271
4960/6000 [=======================>......] - ETA: 0s - loss: 0.4147 - categorical_accuracy: 0.8228
6000/6000 [==============================] - 0s 49us/step - loss: 0.4182 - categorical_accuracy: 0.8198 - val_loss: 0.4120 - val_categorical_accuracy: 0.8213

Epoch 00062: val_loss did not improve from 0.40846
Epoch 63/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5296 - categorical_accuracy: 0.6875
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4139 - categorical_accuracy: 0.8197
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4092 - categorical_accuracy: 0.8191
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4093 - categorical_accuracy: 0.8183
6000/6000 [==============================] - 0s 51us/step - loss: 0.4152 - categorical_accuracy: 0.8165 - val_loss: 0.4108 - val_categorical_accuracy: 0.8198

Epoch 00063: val_loss did not improve from 0.40846
Epoch 64/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4511 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4160 - categorical_accuracy: 0.8241
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8221
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4140 - categorical_accuracy: 0.8217
6000/6000 [==============================] - 0s 50us/step - loss: 0.4159 - categorical_accuracy: 0.8210 - val_loss: 0.4117 - val_categorical_accuracy: 0.8172

Epoch 00064: val_loss did not improve from 0.40846
Epoch 65/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5519 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8266
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8193
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4205 - categorical_accuracy: 0.8204
6000/6000 [==============================] - 0s 50us/step - loss: 0.4176 - categorical_accuracy: 0.8200 - val_loss: 0.4084 - val_categorical_accuracy: 0.8200

Epoch 00065: val_loss improved from 0.40846 to 0.40842, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 66/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3376 - categorical_accuracy: 0.8750
1472/6000 [======>.......................] - ETA: 0s - loss: 0.4237 - categorical_accuracy: 0.8227
3072/6000 [==============>...............] - ETA: 0s - loss: 0.4201 - categorical_accuracy: 0.8258
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4203 - categorical_accuracy: 0.8244
6000/6000 [==============================] - 0s 51us/step - loss: 0.4199 - categorical_accuracy: 0.8210 - val_loss: 0.4112 - val_categorical_accuracy: 0.8178

Epoch 00066: val_loss did not improve from 0.40842
Epoch 67/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3473 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4191 - categorical_accuracy: 0.8125
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4288 - categorical_accuracy: 0.8150
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4237 - categorical_accuracy: 0.8190
6000/6000 [==============================] - 0s 51us/step - loss: 0.4210 - categorical_accuracy: 0.8217 - val_loss: 0.4096 - val_categorical_accuracy: 0.8200

Epoch 00067: val_loss did not improve from 0.40842
Epoch 68/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2900 - categorical_accuracy: 0.9062
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4216 - categorical_accuracy: 0.8150
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8166
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4159 - categorical_accuracy: 0.8185
6000/6000 [==============================] - 0s 50us/step - loss: 0.4196 - categorical_accuracy: 0.8182 - val_loss: 0.4117 - val_categorical_accuracy: 0.8198

Epoch 00068: val_loss did not improve from 0.40842
Epoch 69/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5479 - categorical_accuracy: 0.8438
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4092 - categorical_accuracy: 0.8255
3136/6000 [==============>...............] - ETA: 0s - loss: 0.4105 - categorical_accuracy: 0.8281
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4192 - categorical_accuracy: 0.8199
6000/6000 [==============================] - 0s 50us/step - loss: 0.4178 - categorical_accuracy: 0.8210 - val_loss: 0.4104 - val_categorical_accuracy: 0.8185

Epoch 00069: val_loss did not improve from 0.40842
Epoch 70/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3535 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4227 - categorical_accuracy: 0.8181
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4137 - categorical_accuracy: 0.8207
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4139 - categorical_accuracy: 0.8228
6000/6000 [==============================] - 0s 51us/step - loss: 0.4186 - categorical_accuracy: 0.8208 - val_loss: 0.4106 - val_categorical_accuracy: 0.8175

Epoch 00070: val_loss did not improve from 0.40842
Epoch 71/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3880 - categorical_accuracy: 0.7500
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4152 - categorical_accuracy: 0.8182
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4215 - categorical_accuracy: 0.8162
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8215
6000/6000 [==============================] - 0s 51us/step - loss: 0.4178 - categorical_accuracy: 0.8225 - val_loss: 0.4098 - val_categorical_accuracy: 0.8213

Epoch 00071: val_loss did not improve from 0.40842
Epoch 72/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2812 - categorical_accuracy: 0.9062
1568/6000 [======>.......................] - ETA: 0s - loss: 0.3900 - categorical_accuracy: 0.8316
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4094 - categorical_accuracy: 0.8242
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4169 - categorical_accuracy: 0.8223
6000/6000 [==============================] - 0s 51us/step - loss: 0.4145 - categorical_accuracy: 0.8218 - val_loss: 0.4111 - val_categorical_accuracy: 0.8202

Epoch 00072: val_loss did not improve from 0.40842
Epoch 73/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5020 - categorical_accuracy: 0.7812
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4049 - categorical_accuracy: 0.8290
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4144 - categorical_accuracy: 0.8218
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4116 - categorical_accuracy: 0.8236
6000/6000 [==============================] - 0s 50us/step - loss: 0.4156 - categorical_accuracy: 0.8203 - val_loss: 0.4105 - val_categorical_accuracy: 0.8190

Epoch 00073: val_loss did not improve from 0.40842
Epoch 74/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4223 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8143
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4138 - categorical_accuracy: 0.8229
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4201 - categorical_accuracy: 0.8201
6000/6000 [==============================] - 0s 50us/step - loss: 0.4164 - categorical_accuracy: 0.8213 - val_loss: 0.4120 - val_categorical_accuracy: 0.8198

Epoch 00074: val_loss did not improve from 0.40842
Epoch 75/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3499 - categorical_accuracy: 0.9375
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4309 - categorical_accuracy: 0.8143
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4211 - categorical_accuracy: 0.8197
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4127 - categorical_accuracy: 0.8208
6000/6000 [==============================] - 0s 51us/step - loss: 0.4146 - categorical_accuracy: 0.8225 - val_loss: 0.4089 - val_categorical_accuracy: 0.8225

Epoch 00075: val_loss did not improve from 0.40842
Epoch 76/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3786 - categorical_accuracy: 0.8125
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4140 - categorical_accuracy: 0.8249
3136/6000 [==============>...............] - ETA: 0s - loss: 0.4072 - categorical_accuracy: 0.8268
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4165 - categorical_accuracy: 0.8223
6000/6000 [==============================] - 0s 50us/step - loss: 0.4188 - categorical_accuracy: 0.8207 - val_loss: 0.4111 - val_categorical_accuracy: 0.8178

Epoch 00076: val_loss did not improve from 0.40842
Epoch 77/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4496 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4113 - categorical_accuracy: 0.8303
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4174 - categorical_accuracy: 0.8271
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4107 - categorical_accuracy: 0.8272
6000/6000 [==============================] - 0s 50us/step - loss: 0.4151 - categorical_accuracy: 0.8252 - val_loss: 0.4122 - val_categorical_accuracy: 0.8170

Epoch 00077: val_loss did not improve from 0.40842
Epoch 78/150

  32/6000 [..............................] - ETA: 0s - loss: 0.6236 - categorical_accuracy: 0.6875
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4038 - categorical_accuracy: 0.8288
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4211 - categorical_accuracy: 0.8168
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4210 - categorical_accuracy: 0.8189
6000/6000 [==============================] - 0s 50us/step - loss: 0.4204 - categorical_accuracy: 0.8187 - val_loss: 0.4087 - val_categorical_accuracy: 0.8222

Epoch 00078: val_loss did not improve from 0.40842
Epoch 79/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3013 - categorical_accuracy: 0.9062
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4045 - categorical_accuracy: 0.8301
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4158 - categorical_accuracy: 0.8270
4640/6000 [======================>.......] - ETA: 0s - loss: 0.4201 - categorical_accuracy: 0.8252
6000/6000 [==============================] - 0s 51us/step - loss: 0.4192 - categorical_accuracy: 0.8232 - val_loss: 0.4102 - val_categorical_accuracy: 0.8168

Epoch 00079: val_loss did not improve from 0.40842
Epoch 80/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4607 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4420 - categorical_accuracy: 0.8076
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4263 - categorical_accuracy: 0.8198
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4217 - categorical_accuracy: 0.8209
6000/6000 [==============================] - 0s 50us/step - loss: 0.4193 - categorical_accuracy: 0.8210 - val_loss: 0.4089 - val_categorical_accuracy: 0.8180

Epoch 00080: val_loss did not improve from 0.40842
Epoch 81/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3608 - categorical_accuracy: 0.7812
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4252 - categorical_accuracy: 0.8094
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4148 - categorical_accuracy: 0.8207
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4166 - categorical_accuracy: 0.8213
6000/6000 [==============================] - 0s 50us/step - loss: 0.4173 - categorical_accuracy: 0.8233 - val_loss: 0.4091 - val_categorical_accuracy: 0.8213

Epoch 00081: val_loss did not improve from 0.40842
Epoch 82/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2963 - categorical_accuracy: 0.8750
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4147 - categorical_accuracy: 0.8221
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4212 - categorical_accuracy: 0.8191
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4222 - categorical_accuracy: 0.8210
6000/6000 [==============================] - 0s 51us/step - loss: 0.4172 - categorical_accuracy: 0.8237 - val_loss: 0.4095 - val_categorical_accuracy: 0.8223

Epoch 00082: val_loss did not improve from 0.40842
Epoch 83/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4318 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4130 - categorical_accuracy: 0.8278
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4127 - categorical_accuracy: 0.8245
4544/6000 [=====================>........] - ETA: 0s - loss: 0.4179 - categorical_accuracy: 0.8217
5984/6000 [============================>.] - ETA: 0s - loss: 0.4155 - categorical_accuracy: 0.8230
6000/6000 [==============================] - 0s 53us/step - loss: 0.4165 - categorical_accuracy: 0.8227 - val_loss: 0.4110 - val_categorical_accuracy: 0.8217

Epoch 00083: val_loss did not improve from 0.40842
Epoch 84/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4347 - categorical_accuracy: 0.8125
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4136 - categorical_accuracy: 0.8221
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4123 - categorical_accuracy: 0.8247
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4108 - categorical_accuracy: 0.8242
6000/6000 [==============================] - 0s 50us/step - loss: 0.4133 - categorical_accuracy: 0.8233 - val_loss: 0.4117 - val_categorical_accuracy: 0.8203

Epoch 00084: val_loss did not improve from 0.40842
Epoch 85/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3993 - categorical_accuracy: 0.8125
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4305 - categorical_accuracy: 0.8275
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4233 - categorical_accuracy: 0.8250
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4179 - categorical_accuracy: 0.8247
6000/6000 [==============================] - 0s 53us/step - loss: 0.4162 - categorical_accuracy: 0.8242 - val_loss: 0.4115 - val_categorical_accuracy: 0.8173

Epoch 00085: val_loss did not improve from 0.40842
Epoch 86/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3519 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8238
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4153 - categorical_accuracy: 0.8202
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4093 - categorical_accuracy: 0.8237
6000/6000 [==============================] - 0s 51us/step - loss: 0.4143 - categorical_accuracy: 0.8200 - val_loss: 0.4110 - val_categorical_accuracy: 0.8205

Epoch 00086: val_loss did not improve from 0.40842
Epoch 87/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3019 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4273 - categorical_accuracy: 0.8213
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4230 - categorical_accuracy: 0.8196
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4181 - categorical_accuracy: 0.8210
6000/6000 [==============================] - 0s 50us/step - loss: 0.4172 - categorical_accuracy: 0.8202 - val_loss: 0.4101 - val_categorical_accuracy: 0.8208

Epoch 00087: val_loss did not improve from 0.40842
Epoch 88/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3522 - categorical_accuracy: 0.8438
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4069 - categorical_accuracy: 0.8281
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4085 - categorical_accuracy: 0.8264
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4132 - categorical_accuracy: 0.8243
6000/6000 [==============================] - 0s 51us/step - loss: 0.4128 - categorical_accuracy: 0.8233 - val_loss: 0.4096 - val_categorical_accuracy: 0.8177

Epoch 00088: val_loss did not improve from 0.40842
Epoch 89/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4599 - categorical_accuracy: 0.7812
1472/6000 [======>.......................] - ETA: 0s - loss: 0.4110 - categorical_accuracy: 0.8213
3008/6000 [==============>...............] - ETA: 0s - loss: 0.4069 - categorical_accuracy: 0.8248
4608/6000 [======================>.......] - ETA: 0s - loss: 0.4146 - categorical_accuracy: 0.8225
6000/6000 [==============================] - 0s 52us/step - loss: 0.4115 - categorical_accuracy: 0.8225 - val_loss: 0.4123 - val_categorical_accuracy: 0.8217

Epoch 00089: val_loss did not improve from 0.40842
Epoch 90/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5730 - categorical_accuracy: 0.7188
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4365 - categorical_accuracy: 0.8174
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4190 - categorical_accuracy: 0.8272
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4197 - categorical_accuracy: 0.8219
6000/6000 [==============================] - 0s 50us/step - loss: 0.4187 - categorical_accuracy: 0.8213 - val_loss: 0.4096 - val_categorical_accuracy: 0.8200

Epoch 00090: val_loss did not improve from 0.40842
Epoch 91/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3910 - categorical_accuracy: 0.9062
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4374 - categorical_accuracy: 0.8161
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4252 - categorical_accuracy: 0.8206
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4226 - categorical_accuracy: 0.8210
6000/6000 [==============================] - 0s 50us/step - loss: 0.4175 - categorical_accuracy: 0.8233 - val_loss: 0.4122 - val_categorical_accuracy: 0.8220

Epoch 00091: val_loss did not improve from 0.40842
Epoch 92/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4330 - categorical_accuracy: 0.8150
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4146 - categorical_accuracy: 0.8205
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4249 - categorical_accuracy: 0.8173
6000/6000 [==============================] - 0s 50us/step - loss: 0.4169 - categorical_accuracy: 0.8218 - val_loss: 0.4120 - val_categorical_accuracy: 0.8198

Epoch 00092: val_loss did not improve from 0.40842
Epoch 93/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3845 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4269 - categorical_accuracy: 0.8113
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4059 - categorical_accuracy: 0.8287
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4136 - categorical_accuracy: 0.8238
6000/6000 [==============================] - 0s 50us/step - loss: 0.4150 - categorical_accuracy: 0.8233 - val_loss: 0.4110 - val_categorical_accuracy: 0.8175

Epoch 00093: val_loss did not improve from 0.40842
Epoch 94/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4188 - categorical_accuracy: 0.8125
1632/6000 [=======>......................] - ETA: 0s - loss: 0.3856 - categorical_accuracy: 0.8401
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4106 - categorical_accuracy: 0.8303
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4111 - categorical_accuracy: 0.8277
6000/6000 [==============================] - 0s 50us/step - loss: 0.4162 - categorical_accuracy: 0.8253 - val_loss: 0.4135 - val_categorical_accuracy: 0.8182

Epoch 00094: val_loss did not improve from 0.40842
Epoch 95/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2649 - categorical_accuracy: 0.9375
1472/6000 [======>.......................] - ETA: 0s - loss: 0.4127 - categorical_accuracy: 0.8207
3008/6000 [==============>...............] - ETA: 0s - loss: 0.4165 - categorical_accuracy: 0.8195
4576/6000 [=====================>........] - ETA: 0s - loss: 0.4150 - categorical_accuracy: 0.8197
6000/6000 [==============================] - 0s 53us/step - loss: 0.4154 - categorical_accuracy: 0.8198 - val_loss: 0.4112 - val_categorical_accuracy: 0.8190

Epoch 00095: val_loss did not improve from 0.40842
Epoch 96/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5468 - categorical_accuracy: 0.7500
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4023 - categorical_accuracy: 0.8275
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4114 - categorical_accuracy: 0.8246
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8203
6000/6000 [==============================] - 0s 51us/step - loss: 0.4163 - categorical_accuracy: 0.8220 - val_loss: 0.4106 - val_categorical_accuracy: 0.8210

Epoch 00096: val_loss did not improve from 0.40842
Epoch 97/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3872 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8119
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4179 - categorical_accuracy: 0.8159
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4161 - categorical_accuracy: 0.8202
6000/6000 [==============================] - 0s 50us/step - loss: 0.4166 - categorical_accuracy: 0.8197 - val_loss: 0.4114 - val_categorical_accuracy: 0.8202

Epoch 00097: val_loss did not improve from 0.40842
Epoch 98/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5056 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4277 - categorical_accuracy: 0.8174
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4345 - categorical_accuracy: 0.8177
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4151 - categorical_accuracy: 0.8278
6000/6000 [==============================] - 0s 50us/step - loss: 0.4166 - categorical_accuracy: 0.8243 - val_loss: 0.4097 - val_categorical_accuracy: 0.8202

Epoch 00098: val_loss did not improve from 0.40842
Epoch 99/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2100 - categorical_accuracy: 0.9688
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4187 - categorical_accuracy: 0.8131
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4314 - categorical_accuracy: 0.8069
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4162 - categorical_accuracy: 0.8199
6000/6000 [==============================] - 0s 50us/step - loss: 0.4137 - categorical_accuracy: 0.8213 - val_loss: 0.4096 - val_categorical_accuracy: 0.8218

Epoch 00099: val_loss did not improve from 0.40842
Epoch 100/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4038 - categorical_accuracy: 0.7812
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.8203
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4211 - categorical_accuracy: 0.8255
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4105 - categorical_accuracy: 0.8319
6000/6000 [==============================] - 0s 50us/step - loss: 0.4128 - categorical_accuracy: 0.8277 - val_loss: 0.4089 - val_categorical_accuracy: 0.8203

Epoch 00100: val_loss did not improve from 0.40842
Epoch 101/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3347 - categorical_accuracy: 0.8438
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4071 - categorical_accuracy: 0.8291
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4209 - categorical_accuracy: 0.8191
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4207 - categorical_accuracy: 0.8190
6000/6000 [==============================] - 0s 50us/step - loss: 0.4168 - categorical_accuracy: 0.8207 - val_loss: 0.4099 - val_categorical_accuracy: 0.8177

Epoch 00101: val_loss did not improve from 0.40842
Epoch 102/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3988 - categorical_accuracy: 0.7812
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4140 - categorical_accuracy: 0.8213
3040/6000 [==============>...............] - ETA: 0s - loss: 0.4097 - categorical_accuracy: 0.8260
4672/6000 [======================>.......] - ETA: 0s - loss: 0.4150 - categorical_accuracy: 0.8232
6000/6000 [==============================] - 0s 51us/step - loss: 0.4142 - categorical_accuracy: 0.8248 - val_loss: 0.4118 - val_categorical_accuracy: 0.8215

Epoch 00102: val_loss did not improve from 0.40842
Epoch 103/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5361 - categorical_accuracy: 0.7188
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4351 - categorical_accuracy: 0.8149
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4339 - categorical_accuracy: 0.8181
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4231 - categorical_accuracy: 0.8187
6000/6000 [==============================] - 0s 51us/step - loss: 0.4168 - categorical_accuracy: 0.8220 - val_loss: 0.4110 - val_categorical_accuracy: 0.8193

Epoch 00103: val_loss did not improve from 0.40842
Epoch 104/150

  32/6000 [..............................] - ETA: 0s - loss: 0.7348 - categorical_accuracy: 0.7500
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4081 - categorical_accuracy: 0.8188
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4164 - categorical_accuracy: 0.8172
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4183 - categorical_accuracy: 0.8181
6000/6000 [==============================] - 0s 50us/step - loss: 0.4146 - categorical_accuracy: 0.8215 - val_loss: 0.4097 - val_categorical_accuracy: 0.8192

Epoch 00104: val_loss did not improve from 0.40842
Epoch 105/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5177 - categorical_accuracy: 0.8125
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.8213
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4234 - categorical_accuracy: 0.8189
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4138 - categorical_accuracy: 0.8221
5984/6000 [============================>.] - ETA: 0s - loss: 0.4152 - categorical_accuracy: 0.8232
6000/6000 [==============================] - 0s 56us/step - loss: 0.4161 - categorical_accuracy: 0.8230 - val_loss: 0.4111 - val_categorical_accuracy: 0.8178

Epoch 00105: val_loss did not improve from 0.40842
Epoch 106/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4214 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4221 - categorical_accuracy: 0.8260
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4220 - categorical_accuracy: 0.8189
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4224 - categorical_accuracy: 0.8177
6000/6000 [==============================] - 0s 50us/step - loss: 0.4189 - categorical_accuracy: 0.8195 - val_loss: 0.4123 - val_categorical_accuracy: 0.8178

Epoch 00106: val_loss did not improve from 0.40842
Epoch 107/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4442 - categorical_accuracy: 0.7500
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4128 - categorical_accuracy: 0.8342
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4162 - categorical_accuracy: 0.8267
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4165 - categorical_accuracy: 0.8239
6000/6000 [==============================] - 0s 50us/step - loss: 0.4174 - categorical_accuracy: 0.8245 - val_loss: 0.4112 - val_categorical_accuracy: 0.8203

Epoch 00107: val_loss did not improve from 0.40842
Epoch 108/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2322 - categorical_accuracy: 0.9375
1632/6000 [=======>......................] - ETA: 0s - loss: 0.3922 - categorical_accuracy: 0.8382
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4057 - categorical_accuracy: 0.8284
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4111 - categorical_accuracy: 0.8249
6000/6000 [==============================] - 0s 51us/step - loss: 0.4144 - categorical_accuracy: 0.8222 - val_loss: 0.4138 - val_categorical_accuracy: 0.8128

Epoch 00108: val_loss did not improve from 0.40842
Epoch 109/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2901 - categorical_accuracy: 0.8750
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4158 - categorical_accuracy: 0.8254
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4088 - categorical_accuracy: 0.8275
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4158 - categorical_accuracy: 0.8240
6000/6000 [==============================] - 0s 50us/step - loss: 0.4146 - categorical_accuracy: 0.8240 - val_loss: 0.4105 - val_categorical_accuracy: 0.8212

Epoch 00109: val_loss did not improve from 0.40842
Epoch 110/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5575 - categorical_accuracy: 0.7188
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4051 - categorical_accuracy: 0.8323
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4195 - categorical_accuracy: 0.8234
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8222
6000/6000 [==============================] - 0s 50us/step - loss: 0.4159 - categorical_accuracy: 0.8225 - val_loss: 0.4105 - val_categorical_accuracy: 0.8162

Epoch 00110: val_loss did not improve from 0.40842
Epoch 111/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5902 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4342 - categorical_accuracy: 0.8143
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4178 - categorical_accuracy: 0.8236
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4213 - categorical_accuracy: 0.8172
6000/6000 [==============================] - 0s 50us/step - loss: 0.4167 - categorical_accuracy: 0.8195 - val_loss: 0.4105 - val_categorical_accuracy: 0.8210

Epoch 00111: val_loss did not improve from 0.40842
Epoch 112/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4476 - categorical_accuracy: 0.8438
1408/6000 [======>.......................] - ETA: 0s - loss: 0.4086 - categorical_accuracy: 0.8182
2976/6000 [=============>................] - ETA: 0s - loss: 0.4024 - categorical_accuracy: 0.8317
4576/6000 [=====================>........] - ETA: 0s - loss: 0.4059 - categorical_accuracy: 0.8322
6000/6000 [==============================] - 0s 52us/step - loss: 0.4129 - categorical_accuracy: 0.8297 - val_loss: 0.4109 - val_categorical_accuracy: 0.8208

Epoch 00112: val_loss did not improve from 0.40842
Epoch 113/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4102 - categorical_accuracy: 0.8750
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4062 - categorical_accuracy: 0.8186
3328/6000 [===============>..............] - ETA: 0s - loss: 0.4104 - categorical_accuracy: 0.8212
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4096 - categorical_accuracy: 0.8215
6000/6000 [==============================] - 0s 51us/step - loss: 0.4173 - categorical_accuracy: 0.8190 - val_loss: 0.4128 - val_categorical_accuracy: 0.8185

Epoch 00113: val_loss did not improve from 0.40842
Epoch 114/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3889 - categorical_accuracy: 0.8750
1568/6000 [======>.......................] - ETA: 0s - loss: 0.4047 - categorical_accuracy: 0.8355
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8289
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4168 - categorical_accuracy: 0.8206
6000/6000 [==============================] - 0s 50us/step - loss: 0.4137 - categorical_accuracy: 0.8227 - val_loss: 0.4103 - val_categorical_accuracy: 0.8207

Epoch 00114: val_loss did not improve from 0.40842
Epoch 115/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4890 - categorical_accuracy: 0.8125
1568/6000 [======>.......................] - ETA: 0s - loss: 0.3891 - categorical_accuracy: 0.8374
3072/6000 [==============>...............] - ETA: 0s - loss: 0.4088 - categorical_accuracy: 0.8258
4576/6000 [=====================>........] - ETA: 0s - loss: 0.4069 - categorical_accuracy: 0.8274
6000/6000 [==============================] - 0s 52us/step - loss: 0.4142 - categorical_accuracy: 0.8232 - val_loss: 0.4121 - val_categorical_accuracy: 0.8207

Epoch 00115: val_loss did not improve from 0.40842
Epoch 116/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4012 - categorical_accuracy: 0.8125
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4275 - categorical_accuracy: 0.8173
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4105 - categorical_accuracy: 0.8286
4928/6000 [=======================>......] - ETA: 0s - loss: 0.4112 - categorical_accuracy: 0.8253
6000/6000 [==============================] - 0s 50us/step - loss: 0.4110 - categorical_accuracy: 0.8267 - val_loss: 0.4126 - val_categorical_accuracy: 0.8157

Epoch 00116: val_loss did not improve from 0.40842
Epoch 117/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7812
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4323 - categorical_accuracy: 0.8206
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4131 - categorical_accuracy: 0.8283
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4187 - categorical_accuracy: 0.8222
6000/6000 [==============================] - 0s 50us/step - loss: 0.4194 - categorical_accuracy: 0.8210 - val_loss: 0.4104 - val_categorical_accuracy: 0.8177

Epoch 00117: val_loss did not improve from 0.40842
Epoch 118/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4514 - categorical_accuracy: 0.8125
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4138 - categorical_accuracy: 0.8227
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4224 - categorical_accuracy: 0.8194
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4208 - categorical_accuracy: 0.8201
6000/6000 [==============================] - 0s 52us/step - loss: 0.4124 - categorical_accuracy: 0.8225 - val_loss: 0.4098 - val_categorical_accuracy: 0.8202

Epoch 00118: val_loss did not improve from 0.40842
Epoch 119/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3429 - categorical_accuracy: 0.8750
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4365 - categorical_accuracy: 0.8192
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4268 - categorical_accuracy: 0.8177
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4156 - categorical_accuracy: 0.8234
6000/6000 [==============================] - 0s 50us/step - loss: 0.4184 - categorical_accuracy: 0.8227 - val_loss: 0.4121 - val_categorical_accuracy: 0.8208

Epoch 00119: val_loss did not improve from 0.40842
Epoch 120/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4513 - categorical_accuracy: 0.7500
1568/6000 [======>.......................] - ETA: 0s - loss: 0.3905 - categorical_accuracy: 0.8425
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4038 - categorical_accuracy: 0.8289
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4161 - categorical_accuracy: 0.8235
6000/6000 [==============================] - 0s 50us/step - loss: 0.4102 - categorical_accuracy: 0.8278 - val_loss: 0.4115 - val_categorical_accuracy: 0.8187

Epoch 00120: val_loss did not improve from 0.40842
Epoch 121/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4888 - categorical_accuracy: 0.7812
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4057 - categorical_accuracy: 0.8352
3360/6000 [===============>..............] - ETA: 0s - loss: 0.4119 - categorical_accuracy: 0.8262
4992/6000 [=======================>......] - ETA: 0s - loss: 0.4151 - categorical_accuracy: 0.8247
6000/6000 [==============================] - 0s 50us/step - loss: 0.4144 - categorical_accuracy: 0.8242 - val_loss: 0.4089 - val_categorical_accuracy: 0.8200

Epoch 00121: val_loss did not improve from 0.40842
Epoch 122/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2573 - categorical_accuracy: 0.9375
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4063 - categorical_accuracy: 0.8239
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4063 - categorical_accuracy: 0.8249
4928/6000 [=======================>......] - ETA: 0s - loss: 0.4094 - categorical_accuracy: 0.8220
6000/6000 [==============================] - 0s 49us/step - loss: 0.4127 - categorical_accuracy: 0.8232 - val_loss: 0.4107 - val_categorical_accuracy: 0.8217

Epoch 00122: val_loss did not improve from 0.40842
Epoch 123/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4159 - categorical_accuracy: 0.7188
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8213
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4040 - categorical_accuracy: 0.8232
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4067 - categorical_accuracy: 0.8226
6000/6000 [==============================] - 0s 52us/step - loss: 0.4088 - categorical_accuracy: 0.8233 - val_loss: 0.4095 - val_categorical_accuracy: 0.8195

Epoch 00123: val_loss did not improve from 0.40842
Epoch 124/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5174 - categorical_accuracy: 0.6562
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4094 - categorical_accuracy: 0.8338
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4132 - categorical_accuracy: 0.8270
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8246
6000/6000 [==============================] - 0s 53us/step - loss: 0.4220 - categorical_accuracy: 0.8225 - val_loss: 0.4132 - val_categorical_accuracy: 0.8190

Epoch 00124: val_loss did not improve from 0.40842
Epoch 125/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3790 - categorical_accuracy: 0.8125
1600/6000 [=======>......................] - ETA: 0s - loss: 0.3797 - categorical_accuracy: 0.8494
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4098 - categorical_accuracy: 0.8304
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4131 - categorical_accuracy: 0.8278
6000/6000 [==============================] - 0s 50us/step - loss: 0.4166 - categorical_accuracy: 0.8258 - val_loss: 0.4104 - val_categorical_accuracy: 0.8183

Epoch 00125: val_loss did not improve from 0.40842
Epoch 126/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3304 - categorical_accuracy: 0.9062
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4056 - categorical_accuracy: 0.8413
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4077 - categorical_accuracy: 0.8289
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4191 - categorical_accuracy: 0.8238
6000/6000 [==============================] - 0s 50us/step - loss: 0.4144 - categorical_accuracy: 0.8265 - val_loss: 0.4122 - val_categorical_accuracy: 0.8198

Epoch 00126: val_loss did not improve from 0.40842
Epoch 127/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3591 - categorical_accuracy: 0.8750
1664/6000 [=======>......................] - ETA: 0s - loss: 0.4177 - categorical_accuracy: 0.8257
3328/6000 [===============>..............] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8215
4960/6000 [=======================>......] - ETA: 0s - loss: 0.4197 - categorical_accuracy: 0.8218
6000/6000 [==============================] - 0s 50us/step - loss: 0.4126 - categorical_accuracy: 0.8258 - val_loss: 0.4096 - val_categorical_accuracy: 0.8195

Epoch 00127: val_loss did not improve from 0.40842
Epoch 128/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3377 - categorical_accuracy: 0.9062
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4114 - categorical_accuracy: 0.8313
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4072 - categorical_accuracy: 0.8272
4704/6000 [======================>.......] - ETA: 0s - loss: 0.4125 - categorical_accuracy: 0.8231
6000/6000 [==============================] - 0s 51us/step - loss: 0.4161 - categorical_accuracy: 0.8245 - val_loss: 0.4120 - val_categorical_accuracy: 0.8205

Epoch 00128: val_loss did not improve from 0.40842
Epoch 129/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3576 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.3929 - categorical_accuracy: 0.8356
3296/6000 [===============>..............] - ETA: 0s - loss: 0.4160 - categorical_accuracy: 0.8225
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4115 - categorical_accuracy: 0.8258
6000/6000 [==============================] - 0s 49us/step - loss: 0.4143 - categorical_accuracy: 0.8242 - val_loss: 0.4118 - val_categorical_accuracy: 0.8172

Epoch 00129: val_loss did not improve from 0.40842
Epoch 130/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3371 - categorical_accuracy: 0.8750
1408/6000 [======>.......................] - ETA: 0s - loss: 0.4134 - categorical_accuracy: 0.8260
2976/6000 [=============>................] - ETA: 0s - loss: 0.4098 - categorical_accuracy: 0.8253
4608/6000 [======================>.......] - ETA: 0s - loss: 0.4236 - categorical_accuracy: 0.8179
6000/6000 [==============================] - 0s 51us/step - loss: 0.4150 - categorical_accuracy: 0.8232 - val_loss: 0.4102 - val_categorical_accuracy: 0.8198

Epoch 00130: val_loss did not improve from 0.40842
Epoch 131/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4104 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4137 - categorical_accuracy: 0.8213
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4118 - categorical_accuracy: 0.8249
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4173 - categorical_accuracy: 0.8211
6000/6000 [==============================] - 0s 51us/step - loss: 0.4165 - categorical_accuracy: 0.8210 - val_loss: 0.4098 - val_categorical_accuracy: 0.8172

Epoch 00131: val_loss did not improve from 0.40842
Epoch 132/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3235 - categorical_accuracy: 0.8125
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8294
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4208 - categorical_accuracy: 0.8244
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4231 - categorical_accuracy: 0.8213
6000/6000 [==============================] - 0s 50us/step - loss: 0.4205 - categorical_accuracy: 0.8220 - val_loss: 0.4110 - val_categorical_accuracy: 0.8205

Epoch 00132: val_loss did not improve from 0.40842
Epoch 133/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3323 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.3990 - categorical_accuracy: 0.8338
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4151 - categorical_accuracy: 0.8229
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4174 - categorical_accuracy: 0.8205
6000/6000 [==============================] - 0s 50us/step - loss: 0.4148 - categorical_accuracy: 0.8225 - val_loss: 0.4102 - val_categorical_accuracy: 0.8180

Epoch 00133: val_loss did not improve from 0.40842
Epoch 134/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4481 - categorical_accuracy: 0.7500
1536/6000 [======>.......................] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8294
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4085 - categorical_accuracy: 0.8247
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4137 - categorical_accuracy: 0.8205
6000/6000 [==============================] - 0s 51us/step - loss: 0.4100 - categorical_accuracy: 0.8225 - val_loss: 0.4118 - val_categorical_accuracy: 0.8172

Epoch 00134: val_loss did not improve from 0.40842
Epoch 135/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4049 - categorical_accuracy: 0.8438
1504/6000 [======>.......................] - ETA: 0s - loss: 0.3998 - categorical_accuracy: 0.8338
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4019 - categorical_accuracy: 0.8299
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4060 - categorical_accuracy: 0.8262
6000/6000 [==============================] - 0s 50us/step - loss: 0.4132 - categorical_accuracy: 0.8203 - val_loss: 0.4118 - val_categorical_accuracy: 0.8210

Epoch 00135: val_loss did not improve from 0.40842
Epoch 136/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4085 - categorical_accuracy: 0.7812
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4025 - categorical_accuracy: 0.8319
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4193 - categorical_accuracy: 0.8246
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4163 - categorical_accuracy: 0.8229
6000/6000 [==============================] - 0s 50us/step - loss: 0.4179 - categorical_accuracy: 0.8257 - val_loss: 0.4083 - val_categorical_accuracy: 0.8200

Epoch 00136: val_loss improved from 0.40842 to 0.40832, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 137/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2839 - categorical_accuracy: 0.9375
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4039 - categorical_accuracy: 0.8260
3104/6000 [==============>...............] - ETA: 0s - loss: 0.4085 - categorical_accuracy: 0.8231
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4144 - categorical_accuracy: 0.8209
6000/6000 [==============================] - 0s 51us/step - loss: 0.4164 - categorical_accuracy: 0.8212 - val_loss: 0.4111 - val_categorical_accuracy: 0.8210

Epoch 00137: val_loss did not improve from 0.40832
Epoch 138/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3895 - categorical_accuracy: 0.8438
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4117 - categorical_accuracy: 0.8194
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4203 - categorical_accuracy: 0.8209
4800/6000 [=======================>......] - ETA: 0s - loss: 0.4115 - categorical_accuracy: 0.8254
6000/6000 [==============================] - 0s 51us/step - loss: 0.4137 - categorical_accuracy: 0.8257 - val_loss: 0.4117 - val_categorical_accuracy: 0.8180

Epoch 00138: val_loss did not improve from 0.40832
Epoch 139/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3948 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4086 - categorical_accuracy: 0.8192
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4073 - categorical_accuracy: 0.8252
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4112 - categorical_accuracy: 0.8252
6000/6000 [==============================] - 0s 50us/step - loss: 0.4137 - categorical_accuracy: 0.8237 - val_loss: 0.4108 - val_categorical_accuracy: 0.8212

Epoch 00139: val_loss did not improve from 0.40832
Epoch 140/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3641 - categorical_accuracy: 0.8438
1504/6000 [======>.......................] - ETA: 0s - loss: 0.3915 - categorical_accuracy: 0.8378
3168/6000 [==============>...............] - ETA: 0s - loss: 0.3935 - categorical_accuracy: 0.8343
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4078 - categorical_accuracy: 0.8254
6000/6000 [==============================] - 0s 50us/step - loss: 0.4123 - categorical_accuracy: 0.8215 - val_loss: 0.4120 - val_categorical_accuracy: 0.8218

Epoch 00140: val_loss did not improve from 0.40832
Epoch 141/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5256 - categorical_accuracy: 0.8125
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4056 - categorical_accuracy: 0.8275
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8202
4768/6000 [======================>.......] - ETA: 0s - loss: 0.4082 - categorical_accuracy: 0.8236
6000/6000 [==============================] - 0s 51us/step - loss: 0.4109 - categorical_accuracy: 0.8230 - val_loss: 0.4101 - val_categorical_accuracy: 0.8185

Epoch 00141: val_loss did not improve from 0.40832
Epoch 142/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2778 - categorical_accuracy: 0.9062
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4180 - categorical_accuracy: 0.8100
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4035 - categorical_accuracy: 0.8193
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4111 - categorical_accuracy: 0.8181
6000/6000 [==============================] - 0s 51us/step - loss: 0.4153 - categorical_accuracy: 0.8180 - val_loss: 0.4132 - val_categorical_accuracy: 0.8130

Epoch 00142: val_loss did not improve from 0.40832
Epoch 143/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3621 - categorical_accuracy: 0.8750
1632/6000 [=======>......................] - ETA: 0s - loss: 0.3859 - categorical_accuracy: 0.8401
3200/6000 [===============>..............] - ETA: 0s - loss: 0.3966 - categorical_accuracy: 0.8331
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4122 - categorical_accuracy: 0.8263
6000/6000 [==============================] - 0s 50us/step - loss: 0.4138 - categorical_accuracy: 0.8258 - val_loss: 0.4122 - val_categorical_accuracy: 0.8183

Epoch 00143: val_loss did not improve from 0.40832
Epoch 144/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2810 - categorical_accuracy: 0.9375
1696/6000 [=======>......................] - ETA: 0s - loss: 0.4077 - categorical_accuracy: 0.8278
3264/6000 [===============>..............] - ETA: 0s - loss: 0.4084 - categorical_accuracy: 0.8238
4864/6000 [=======================>......] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.8228
6000/6000 [==============================] - 0s 50us/step - loss: 0.4124 - categorical_accuracy: 0.8203 - val_loss: 0.4111 - val_categorical_accuracy: 0.8183

Epoch 00144: val_loss did not improve from 0.40832
Epoch 145/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2925 - categorical_accuracy: 0.8750
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4028 - categorical_accuracy: 0.8288
3200/6000 [===============>..............] - ETA: 0s - loss: 0.4113 - categorical_accuracy: 0.8219
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4128 - categorical_accuracy: 0.8181
6000/6000 [==============================] - 0s 50us/step - loss: 0.4128 - categorical_accuracy: 0.8220 - val_loss: 0.4116 - val_categorical_accuracy: 0.8178

Epoch 00145: val_loss did not improve from 0.40832
Epoch 146/150

  32/6000 [..............................] - ETA: 0s - loss: 0.5030 - categorical_accuracy: 0.8438
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4116 - categorical_accuracy: 0.8419
3168/6000 [==============>...............] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8327
4736/6000 [======================>.......] - ETA: 0s - loss: 0.4092 - categorical_accuracy: 0.8313
6000/6000 [==============================] - 0s 51us/step - loss: 0.4114 - categorical_accuracy: 0.8270 - val_loss: 0.4106 - val_categorical_accuracy: 0.8178

Epoch 00146: val_loss did not improve from 0.40832
Epoch 147/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4078 - categorical_accuracy: 0.8125
1600/6000 [=======>......................] - ETA: 0s - loss: 0.4162 - categorical_accuracy: 0.8256
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8230
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4217 - categorical_accuracy: 0.8195
6000/6000 [==============================] - 0s 52us/step - loss: 0.4166 - categorical_accuracy: 0.8228 - val_loss: 0.4134 - val_categorical_accuracy: 0.8197

Epoch 00147: val_loss did not improve from 0.40832
Epoch 148/150

  32/6000 [..............................] - ETA: 0s - loss: 0.2624 - categorical_accuracy: 0.9375
1472/6000 [======>.......................] - ETA: 0s - loss: 0.3888 - categorical_accuracy: 0.8505
3072/6000 [==============>...............] - ETA: 0s - loss: 0.3983 - categorical_accuracy: 0.8392
4640/6000 [======================>.......] - ETA: 0s - loss: 0.4090 - categorical_accuracy: 0.8328
6000/6000 [==============================] - 0s 51us/step - loss: 0.4109 - categorical_accuracy: 0.8280 - val_loss: 0.4128 - val_categorical_accuracy: 0.8207

Epoch 00148: val_loss did not improve from 0.40832
Epoch 149/150

  32/6000 [..............................] - ETA: 0s - loss: 0.3972 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.3912 - categorical_accuracy: 0.8388
3264/6000 [===============>..............] - ETA: 0s - loss: 0.3996 - categorical_accuracy: 0.8318
4896/6000 [=======================>......] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8270
6000/6000 [==============================] - 0s 50us/step - loss: 0.4102 - categorical_accuracy: 0.8248 - val_loss: 0.4121 - val_categorical_accuracy: 0.8165

Epoch 00149: val_loss did not improve from 0.40832
Epoch 150/150

  32/6000 [..............................] - ETA: 0s - loss: 0.4821 - categorical_accuracy: 0.7500
1632/6000 [=======>......................] - ETA: 0s - loss: 0.4374 - categorical_accuracy: 0.8070
3232/6000 [===============>..............] - ETA: 0s - loss: 0.4193 - categorical_accuracy: 0.8243
4832/6000 [=======================>......] - ETA: 0s - loss: 0.4213 - categorical_accuracy: 0.8210
6000/6000 [==============================] - 0s 50us/step - loss: 0.4123 - categorical_accuracy: 0.8248 - val_loss: 0.4102 - val_categorical_accuracy: 0.8193

Epoch 00150: val_loss did not improve from 0.40832
                         : Elapsed time for training with 6000 events: [1;31m47.1 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 6000 events: [1;31m0.726 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.272e-01
                         :    2 : mfchi2     : 2.727e-01
                         :    3 : gm2e       : 9.061e-02
                         :    4 : pi0p3cms   : 1.628e-02
                         :    5 : gm2e925    : 1.624e-02
                         :    6 : gmthetacms : 1.556e-02
                         :    7 : gm1e925    : 1.422e-02
                         :    8 : gm1p3cms   : 1.309e-02
                         :    9 : gm2p3cms   : 1.216e-02
                         :   10 : gm1e       : 8.899e-03
                         :   11 : gm1eerror  : 5.546e-03
                         :   12 : ediff      : 4.103e-03
                         :   13 : gm2eerror  : 3.485e-03
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.041573     0.99206   [     -3.1672      5.7307 ]
                         :   pi0p3cms:    0.041400     0.98937   [     -3.0105      5.7307 ]
                         :       gm1e:    0.045740     0.99911   [     -3.0178      5.7307 ]
                         :       gm2e:    0.022127     0.98518   [     -2.9163      5.7307 ]
                         :    gm1e925:     0.78805      2.1990   [     -3.2477      5.7307 ]
                         :    gm2e925:     0.78805      2.1990   [     -3.2477      5.7307 ]
                         :      ediff:    0.047827      1.0084   [     -2.9445      5.7307 ]
                         :  gm1eerror:    0.047899      1.0019   [     -2.7432      5.7307 ]
                         :  gm2eerror:    0.023703     0.98008   [     -2.7384      5.7307 ]
                         :   gm1p3cms:    0.045726     0.99539   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.022698     0.98655   [     -2.8845      5.7307 ]
                         : gmthetacms:   -0.016403     0.98184   [     -4.1351      5.7307 ]
                         :     mfchi2:  -0.0076097     0.98299   [     -2.2075      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.041573     0.99206   [     -3.1672      5.7307 ]
                         :   pi0p3cms:    0.041400     0.98937   [     -3.0105      5.7307 ]
                         :       gm1e:    0.045740     0.99911   [     -3.0178      5.7307 ]
                         :       gm2e:    0.022127     0.98518   [     -2.9163      5.7307 ]
                         :    gm1e925:     0.78805      2.1990   [     -3.2477      5.7307 ]
                         :    gm2e925:     0.78805      2.1990   [     -3.2477      5.7307 ]
                         :      ediff:    0.047827      1.0084   [     -2.9445      5.7307 ]
                         :  gm1eerror:    0.047899      1.0019   [     -2.7432      5.7307 ]
                         :  gm2eerror:    0.023703     0.98008   [     -2.7384      5.7307 ]
                         :   gm1p3cms:    0.045726     0.99539   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.022698     0.98655   [     -2.8845      5.7307 ]
                         : gmthetacms:   -0.016403     0.98184   [     -4.1351      5.7307 ]
                         :     mfchi2:  -0.0076097     0.98299   [     -2.2075      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.51562     0.50608   [   0.0049119      4.2687 ]
                         :   pi0p3cms:     0.65459     0.67438   [    0.011733      6.0224 ]
                         :       gm1e:     0.38983     0.39151   [    0.063063      3.8130 ]
                         :       gm2e:     0.15655     0.14623   [    0.060001      1.8160 ]
                         :    gm1e925:     0.95003    0.063395   [     0.22900      1.0000 ]
                         :    gm2e925:     0.95003    0.063395   [     0.22900      1.0000 ]
                         :      ediff:     0.23327     0.32975   [  1.2249e-05      3.4668 ]
                         :  gm1eerror:  0.00011500  0.00031622   [  2.1524e-06   0.0088087 ]
                         :  gm2eerror:  1.9820e-05  5.5386e-05   [  1.7405e-06   0.0012380 ]
                         :   gm1p3cms:     0.48717     0.52675   [    0.048464      5.0839 ]
                         :   gm2p3cms:     0.19296     0.19455   [    0.043825      2.6831 ]
                         : gmthetacms:     0.81012     0.54467   [    0.044029      3.0902 ]
                         :     mfchi2:      10.359      12.095   [  2.3731e-07      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       PyKeras        : 0.876
                         : dataset       GTB            : 0.870
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              PyKeras        : 0.252 (0.277)       0.658 (0.675)      0.860 (0.869)
                         : dataset              GTB            : 0.255 (0.385)       0.658 (0.688)      0.849 (0.867)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 6000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 6000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
