DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : [1mTrain all methods[0m
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 2000
                         : Signal     -- testing events             : 2000
                         : Signal     -- training and testing events: 4000
                         : Background -- training events            : 2000
                         : Background -- testing events             : 2000
                         : Background -- training and testing events: 4000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.974  +0.956  +0.746  -0.173  -0.173  +0.733    +0.822    +0.633   +0.936   +0.752     -0.682  -0.203
                         :   pi0p3cms:  +0.974   +1.000  +0.934  +0.724  -0.160  -0.160  +0.718    +0.826    +0.631   +0.962   +0.771     -0.669  -0.183
                         :       gm1e:  +0.956   +0.934  +1.000  +0.520  -0.111  -0.111  +0.900    +0.884    +0.438   +0.976   +0.538     -0.615  -0.182
                         :       gm2e:  +0.746   +0.724  +0.520  +1.000  -0.259  -0.259  +0.095    +0.402    +0.862   +0.517   +0.977     -0.558  -0.191
                         :    gm1e925:  -0.173   -0.160  -0.111  -0.259  +1.000  +1.000  +0.004    -0.082    -0.282   -0.104   -0.242     +0.063  -0.026
                         :    gm2e925:  -0.173   -0.160  -0.111  -0.259  +1.000  +1.000  +0.004    -0.082    -0.282   -0.104   -0.242     +0.063  -0.026
                         :      ediff:  +0.733   +0.718  +0.900  +0.095  +0.004  +0.004  +1.000    +0.825    +0.070   +0.873   +0.128     -0.431  -0.115
                         :  gm1eerror:  +0.822   +0.826  +0.884  +0.402  -0.082  -0.082  +0.825    +1.000    +0.372   +0.885   +0.432     -0.408  -0.130
                         :  gm2eerror:  +0.633   +0.631  +0.438  +0.862  -0.282  -0.282  +0.070    +0.372    +1.000   +0.447   +0.863     -0.379  -0.138
                         :   gm1p3cms:  +0.936   +0.962  +0.976  +0.517  -0.104  -0.104  +0.873    +0.885    +0.447   +1.000   +0.568     -0.610  -0.167
                         :   gm2p3cms:  +0.752   +0.771  +0.538  +0.977  -0.242  -0.242  +0.128    +0.432    +0.863   +0.568   +1.000     -0.565  -0.176
                         : gmthetacms:  -0.682   -0.669  -0.615  -0.558  +0.063  +0.063  -0.431    -0.408    -0.379   -0.610   -0.565     +1.000  +0.202
                         :     mfchi2:  -0.203   -0.183  -0.182  -0.191  -0.026  -0.026  -0.115    -0.130    -0.138   -0.167   -0.176     +0.202  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.975  +0.968  +0.623  -0.072  -0.072  +0.864    +0.786    +0.546   +0.951   +0.625     -0.718  -0.149
                         :   pi0p3cms:  +0.975   +1.000  +0.945  +0.610  -0.069  -0.069  +0.842    +0.794    +0.552   +0.971   +0.656     -0.728  -0.136
                         :       gm1e:  +0.968   +0.945  +1.000  +0.426  -0.065  -0.065  +0.960    +0.838    +0.375   +0.978   +0.440     -0.617  -0.139
                         :       gm2e:  +0.623   +0.610  +0.426  +1.000  -0.064  -0.064  +0.154    +0.321    +0.894   +0.429   +0.958     -0.558  -0.151
                         :    gm1e925:  -0.072   -0.069  -0.065  -0.064  +1.000  +1.000  -0.051    -0.035    -0.082   -0.062   -0.059     +0.044  -0.036
                         :    gm2e925:  -0.072   -0.069  -0.065  -0.064  +1.000  +1.000  -0.051    -0.035    -0.082   -0.062   -0.059     +0.044  -0.036
                         :      ediff:  +0.864   +0.842  +0.960  +0.154  -0.051  -0.051  +1.000    +0.815    +0.131   +0.935   +0.182     -0.501  -0.105
                         :  gm1eerror:  +0.786   +0.794  +0.838  +0.321  -0.035  -0.035  +0.815    +1.000    +0.300   +0.841   +0.350     -0.370  -0.110
                         :  gm2eerror:  +0.546   +0.552  +0.375  +0.894  -0.082  -0.082  +0.131    +0.300    +1.000   +0.390   +0.880     -0.416  -0.145
                         :   gm1p3cms:  +0.951   +0.971  +0.978  +0.429  -0.062  -0.062  +0.935    +0.841    +0.390   +1.000   +0.470     -0.634  -0.128
                         :   gm2p3cms:  +0.625   +0.656  +0.440  +0.958  -0.059  -0.059  +0.182    +0.350    +0.880   +0.470   +1.000     -0.600  -0.140
                         : gmthetacms:  -0.718   -0.728  -0.617  -0.558  +0.044  +0.044  -0.501    -0.370    -0.416   -0.634   -0.600     +1.000  +0.099
                         :     mfchi2:  -0.149   -0.136  -0.139  -0.151  -0.036  -0.036  -0.105    -0.110    -0.145   -0.128   -0.140     +0.099  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.014495     0.99997   [     -2.9073      5.7307 ]
                         :   pi0p3cms:    0.013369     0.99473   [     -2.9075      5.7307 ]
                         :       gm1e:    0.014956      1.0006   [     -2.9040      5.7307 ]
                         :       gm2e:    0.014585      1.0005   [     -2.8241      5.7307 ]
                         :    gm1e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :    gm2e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :      ediff:    0.015802      1.0064   [     -2.8487      5.7307 ]
                         :  gm1eerror:    0.015391     0.99881   [     -2.6322      5.7307 ]
                         :  gm2eerror:    0.015433     0.99816   [     -2.6476      5.7307 ]
                         :   gm1p3cms:    0.014257     0.99872   [     -2.9037      5.7307 ]
                         :   gm2p3cms:    0.015246      1.0039   [     -2.8759      5.7307 ]
                         : gmthetacms:    0.014290     0.99812   [     -2.9066      5.7307 ]
                         :     mfchi2:    0.022081      1.0067   [     -2.1005      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 3.024e-01
                         :    2 : gmthetacms : 2.691e-01
                         :    3 : gm1e       : 2.638e-01
                         :    4 : pi0p3cms   : 2.571e-01
                         :    5 : gm2e       : 2.491e-01
                         :    6 : gm1eerror  : 2.433e-01
                         :    7 : mfchi2     : 2.381e-01
                         :    8 : gm2eerror  : 2.322e-01
                         :    9 : gm1p3cms   : 2.306e-01
                         :   10 : gm2p3cms   : 2.091e-01
                         :   11 : ediff      : 1.375e-01
                         :   12 : gm1e925    : 8.971e-02
                         :   13 : gm2e925    : 8.971e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.014495     0.99997   [     -2.9073      5.7307 ]
                         :   pi0p3cms:    0.013369     0.99473   [     -2.9075      5.7307 ]
                         :       gm1e:    0.014956      1.0006   [     -2.9040      5.7307 ]
                         :       gm2e:    0.014585      1.0005   [     -2.8241      5.7307 ]
                         :    gm1e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :    gm2e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :      ediff:    0.015802      1.0064   [     -2.8487      5.7307 ]
                         :  gm1eerror:    0.015391     0.99881   [     -2.6322      5.7307 ]
                         :  gm2eerror:    0.015433     0.99816   [     -2.6476      5.7307 ]
                         :   gm1p3cms:    0.014257     0.99872   [     -2.9037      5.7307 ]
                         :   gm2p3cms:    0.015246      1.0039   [     -2.8759      5.7307 ]
                         : gmthetacms:    0.014290     0.99812   [     -2.9066      5.7307 ]
                         :     mfchi2:    0.022081      1.0067   [     -2.1005      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 4000 samples, validate on 4000 samples
Epoch 1/150

  32/4000 [..............................] - ETA: 23s - loss: 2.0360 - categorical_accuracy: 0.3750
1248/4000 [========>.....................] - ETA: 0s - loss: 0.8413 - categorical_accuracy: 0.5625 
2560/4000 [==================>...........] - ETA: 0s - loss: 0.7616 - categorical_accuracy: 0.6094
3808/4000 [===========================>..] - ETA: 0s - loss: 0.7281 - categorical_accuracy: 0.6284
4000/4000 [==============================] - 0s 119us/step - loss: 0.7226 - categorical_accuracy: 0.6327 - val_loss: 0.5149 - val_categorical_accuracy: 0.7530

Epoch 00001: val_loss improved from inf to 0.51490, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/150

  32/4000 [..............................] - ETA: 0s - loss: 0.8303 - categorical_accuracy: 0.6875
1312/4000 [========>.....................] - ETA: 0s - loss: 0.5952 - categorical_accuracy: 0.7081
2656/4000 [==================>...........] - ETA: 0s - loss: 0.5956 - categorical_accuracy: 0.7052
3968/4000 [============================>.] - ETA: 0s - loss: 0.5867 - categorical_accuracy: 0.7069
4000/4000 [==============================] - 0s 62us/step - loss: 0.5857 - categorical_accuracy: 0.7075 - val_loss: 0.4959 - val_categorical_accuracy: 0.7655

Epoch 00002: val_loss improved from 0.51490 to 0.49593, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6291 - categorical_accuracy: 0.6562
1344/4000 [=========>....................] - ETA: 0s - loss: 0.5631 - categorical_accuracy: 0.7150
2720/4000 [===================>..........] - ETA: 0s - loss: 0.5584 - categorical_accuracy: 0.7272
4000/4000 [==============================] - 0s 60us/step - loss: 0.5463 - categorical_accuracy: 0.7372 - val_loss: 0.4841 - val_categorical_accuracy: 0.7770

Epoch 00003: val_loss improved from 0.49593 to 0.48413, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5538 - categorical_accuracy: 0.7188
1312/4000 [========>.....................] - ETA: 0s - loss: 0.5252 - categorical_accuracy: 0.7416
2688/4000 [===================>..........] - ETA: 0s - loss: 0.5299 - categorical_accuracy: 0.7429
4000/4000 [==============================] - 0s 61us/step - loss: 0.5309 - categorical_accuracy: 0.7473 - val_loss: 0.4767 - val_categorical_accuracy: 0.7818

Epoch 00004: val_loss improved from 0.48413 to 0.47669, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/150

  32/4000 [..............................] - ETA: 0s - loss: 0.7631 - categorical_accuracy: 0.7188
1280/4000 [========>.....................] - ETA: 0s - loss: 0.5004 - categorical_accuracy: 0.7734
2624/4000 [==================>...........] - ETA: 0s - loss: 0.5083 - categorical_accuracy: 0.7649
3936/4000 [============================>.] - ETA: 0s - loss: 0.5141 - categorical_accuracy: 0.7612
4000/4000 [==============================] - 0s 62us/step - loss: 0.5146 - categorical_accuracy: 0.7598 - val_loss: 0.4728 - val_categorical_accuracy: 0.7843

Epoch 00005: val_loss improved from 0.47669 to 0.47277, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5318 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.5072 - categorical_accuracy: 0.7626
2656/4000 [==================>...........] - ETA: 0s - loss: 0.5198 - categorical_accuracy: 0.7602
3840/4000 [===========================>..] - ETA: 0s - loss: 0.5162 - categorical_accuracy: 0.7633
4000/4000 [==============================] - 0s 66us/step - loss: 0.5145 - categorical_accuracy: 0.7650 - val_loss: 0.4696 - val_categorical_accuracy: 0.7847

Epoch 00006: val_loss improved from 0.47277 to 0.46957, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4744 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.5101 - categorical_accuracy: 0.7774
2624/4000 [==================>...........] - ETA: 0s - loss: 0.5072 - categorical_accuracy: 0.7691
3936/4000 [============================>.] - ETA: 0s - loss: 0.5027 - categorical_accuracy: 0.7716
4000/4000 [==============================] - 0s 63us/step - loss: 0.5028 - categorical_accuracy: 0.7715 - val_loss: 0.4659 - val_categorical_accuracy: 0.7853

Epoch 00007: val_loss improved from 0.46957 to 0.46586, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3574 - categorical_accuracy: 0.8750
1216/4000 [========>.....................] - ETA: 0s - loss: 0.4956 - categorical_accuracy: 0.7911
2528/4000 [=================>............] - ETA: 0s - loss: 0.4975 - categorical_accuracy: 0.7864
3872/4000 [============================>.] - ETA: 0s - loss: 0.5073 - categorical_accuracy: 0.7758
4000/4000 [==============================] - 0s 63us/step - loss: 0.5090 - categorical_accuracy: 0.7740 - val_loss: 0.4735 - val_categorical_accuracy: 0.7860

Epoch 00008: val_loss did not improve from 0.46586
Epoch 9/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6336 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4983 - categorical_accuracy: 0.7762
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4973 - categorical_accuracy: 0.7783
4000/4000 [==============================] - 0s 60us/step - loss: 0.5028 - categorical_accuracy: 0.7807 - val_loss: 0.4658 - val_categorical_accuracy: 0.7868

Epoch 00009: val_loss improved from 0.46586 to 0.46579, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 10/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4615 - categorical_accuracy: 0.7500
1280/4000 [========>.....................] - ETA: 0s - loss: 0.5055 - categorical_accuracy: 0.7664
2528/4000 [=================>............] - ETA: 0s - loss: 0.4950 - categorical_accuracy: 0.7729
3776/4000 [===========================>..] - ETA: 0s - loss: 0.4917 - categorical_accuracy: 0.7791
4000/4000 [==============================] - 0s 63us/step - loss: 0.4888 - categorical_accuracy: 0.7795 - val_loss: 0.4618 - val_categorical_accuracy: 0.7883

Epoch 00010: val_loss improved from 0.46579 to 0.46182, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 11/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5003 - categorical_accuracy: 0.7812
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4867 - categorical_accuracy: 0.7889
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.7883
4000/4000 [==============================] - 0s 59us/step - loss: 0.4929 - categorical_accuracy: 0.7830 - val_loss: 0.4612 - val_categorical_accuracy: 0.7878

Epoch 00011: val_loss improved from 0.46182 to 0.46121, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 12/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3562 - categorical_accuracy: 0.9375
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4819 - categorical_accuracy: 0.7828
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4922 - categorical_accuracy: 0.7846
3936/4000 [============================>.] - ETA: 0s - loss: 0.4808 - categorical_accuracy: 0.7871
4000/4000 [==============================] - 0s 62us/step - loss: 0.4823 - categorical_accuracy: 0.7860 - val_loss: 0.4593 - val_categorical_accuracy: 0.7880

Epoch 00012: val_loss improved from 0.46121 to 0.45935, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 13/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5903 - categorical_accuracy: 0.7812
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4907 - categorical_accuracy: 0.7713
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4943 - categorical_accuracy: 0.7744
3904/4000 [============================>.] - ETA: 0s - loss: 0.4881 - categorical_accuracy: 0.7800
4000/4000 [==============================] - 0s 62us/step - loss: 0.4899 - categorical_accuracy: 0.7785 - val_loss: 0.4605 - val_categorical_accuracy: 0.7878

Epoch 00013: val_loss did not improve from 0.45935
Epoch 14/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3359 - categorical_accuracy: 0.9375
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4989 - categorical_accuracy: 0.7893
2560/4000 [==================>...........] - ETA: 0s - loss: 0.4931 - categorical_accuracy: 0.7852
3840/4000 [===========================>..] - ETA: 0s - loss: 0.4889 - categorical_accuracy: 0.7859
4000/4000 [==============================] - 0s 62us/step - loss: 0.4873 - categorical_accuracy: 0.7850 - val_loss: 0.4606 - val_categorical_accuracy: 0.7890

Epoch 00014: val_loss did not improve from 0.45935
Epoch 15/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5549 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.5050 - categorical_accuracy: 0.7805
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4915 - categorical_accuracy: 0.7839
3968/4000 [============================>.] - ETA: 0s - loss: 0.4917 - categorical_accuracy: 0.7815
4000/4000 [==============================] - 0s 62us/step - loss: 0.4907 - categorical_accuracy: 0.7815 - val_loss: 0.4587 - val_categorical_accuracy: 0.7900

Epoch 00015: val_loss improved from 0.45935 to 0.45872, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 16/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4445 - categorical_accuracy: 0.7812
1024/4000 [======>.......................] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7979
2048/4000 [==============>...............] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.7866
3104/4000 [======================>.......] - ETA: 0s - loss: 0.4877 - categorical_accuracy: 0.7832
4000/4000 [==============================] - 0s 72us/step - loss: 0.4843 - categorical_accuracy: 0.7843 - val_loss: 0.4571 - val_categorical_accuracy: 0.7890

Epoch 00016: val_loss improved from 0.45872 to 0.45707, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 17/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4561 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.5090 - categorical_accuracy: 0.7881
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4996 - categorical_accuracy: 0.7756
3936/4000 [============================>.] - ETA: 0s - loss: 0.4875 - categorical_accuracy: 0.7840
4000/4000 [==============================] - 0s 63us/step - loss: 0.4866 - categorical_accuracy: 0.7843 - val_loss: 0.4560 - val_categorical_accuracy: 0.7905

Epoch 00017: val_loss improved from 0.45707 to 0.45602, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 18/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3788 - categorical_accuracy: 0.8750
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4886 - categorical_accuracy: 0.7812
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.7892
3968/4000 [============================>.] - ETA: 0s - loss: 0.4790 - categorical_accuracy: 0.7828
4000/4000 [==============================] - 0s 62us/step - loss: 0.4796 - categorical_accuracy: 0.7825 - val_loss: 0.4557 - val_categorical_accuracy: 0.7893

Epoch 00018: val_loss improved from 0.45602 to 0.45567, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 19/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5505 - categorical_accuracy: 0.6562
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4778 - categorical_accuracy: 0.7872
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7835
4000/4000 [==============================] - 0s 60us/step - loss: 0.4842 - categorical_accuracy: 0.7837 - val_loss: 0.4594 - val_categorical_accuracy: 0.7928

Epoch 00019: val_loss did not improve from 0.45567
Epoch 20/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3535 - categorical_accuracy: 0.9375
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.7946
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4857 - categorical_accuracy: 0.7820
4000/4000 [==============================] - 0s 60us/step - loss: 0.4803 - categorical_accuracy: 0.7872 - val_loss: 0.4557 - val_categorical_accuracy: 0.7895

Epoch 00020: val_loss did not improve from 0.45567
Epoch 21/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3987 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4662 - categorical_accuracy: 0.7834
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4816 - categorical_accuracy: 0.7768
3968/4000 [============================>.] - ETA: 0s - loss: 0.4791 - categorical_accuracy: 0.7835
4000/4000 [==============================] - 0s 61us/step - loss: 0.4789 - categorical_accuracy: 0.7832 - val_loss: 0.4559 - val_categorical_accuracy: 0.7905

Epoch 00021: val_loss did not improve from 0.45567
Epoch 22/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5767 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.8006
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4754 - categorical_accuracy: 0.7902
4000/4000 [==============================] - 0s 59us/step - loss: 0.4844 - categorical_accuracy: 0.7850 - val_loss: 0.4562 - val_categorical_accuracy: 0.7897

Epoch 00022: val_loss did not improve from 0.45567
Epoch 23/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4264 - categorical_accuracy: 0.8438
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.7997
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.7892
4000/4000 [==============================] - 0s 59us/step - loss: 0.4748 - categorical_accuracy: 0.7905 - val_loss: 0.4511 - val_categorical_accuracy: 0.7895

Epoch 00023: val_loss improved from 0.45567 to 0.45109, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 24/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3973 - categorical_accuracy: 0.8750
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4902 - categorical_accuracy: 0.7812
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4836 - categorical_accuracy: 0.7846
3936/4000 [============================>.] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7901
4000/4000 [==============================] - 0s 61us/step - loss: 0.4777 - categorical_accuracy: 0.7895 - val_loss: 0.4510 - val_categorical_accuracy: 0.7910

Epoch 00024: val_loss improved from 0.45109 to 0.45100, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 25/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4296 - categorical_accuracy: 0.8125
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4721 - categorical_accuracy: 0.7961
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4582 - categorical_accuracy: 0.7986
3808/4000 [===========================>..] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7897
4000/4000 [==============================] - 0s 63us/step - loss: 0.4743 - categorical_accuracy: 0.7890 - val_loss: 0.4542 - val_categorical_accuracy: 0.7922

Epoch 00025: val_loss did not improve from 0.45100
Epoch 26/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3699 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4629 - categorical_accuracy: 0.8009
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.7923
4000/4000 [==============================] - 0s 63us/step - loss: 0.4767 - categorical_accuracy: 0.7887 - val_loss: 0.4521 - val_categorical_accuracy: 0.7903

Epoch 00026: val_loss did not improve from 0.45100
Epoch 27/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4155 - categorical_accuracy: 0.8438
1024/4000 [======>.......................] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.7832
2112/4000 [==============>...............] - ETA: 0s - loss: 0.4788 - categorical_accuracy: 0.7817
3424/4000 [========================>.....] - ETA: 0s - loss: 0.4745 - categorical_accuracy: 0.7859
4000/4000 [==============================] - 0s 66us/step - loss: 0.4773 - categorical_accuracy: 0.7840 - val_loss: 0.4528 - val_categorical_accuracy: 0.7915

Epoch 00027: val_loss did not improve from 0.45100
Epoch 28/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5903 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4677 - categorical_accuracy: 0.7827
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4640 - categorical_accuracy: 0.7878
4000/4000 [==============================] - 0s 60us/step - loss: 0.4670 - categorical_accuracy: 0.7883 - val_loss: 0.4499 - val_categorical_accuracy: 0.7920

Epoch 00028: val_loss improved from 0.45100 to 0.44994, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 29/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6042 - categorical_accuracy: 0.6875
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4563 - categorical_accuracy: 0.7984
2528/4000 [=================>............] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.7872
3840/4000 [===========================>..] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7875
4000/4000 [==============================] - 0s 63us/step - loss: 0.4737 - categorical_accuracy: 0.7878 - val_loss: 0.4510 - val_categorical_accuracy: 0.7930

Epoch 00029: val_loss did not improve from 0.44994
Epoch 30/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4757 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7798
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4788 - categorical_accuracy: 0.7798
4000/4000 [==============================] - 0s 61us/step - loss: 0.4741 - categorical_accuracy: 0.7837 - val_loss: 0.4488 - val_categorical_accuracy: 0.7893

Epoch 00030: val_loss improved from 0.44994 to 0.44875, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 31/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4318 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4681 - categorical_accuracy: 0.7902
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7934
4000/4000 [==============================] - 0s 61us/step - loss: 0.4731 - categorical_accuracy: 0.7893 - val_loss: 0.4491 - val_categorical_accuracy: 0.7893

Epoch 00031: val_loss did not improve from 0.44875
Epoch 32/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4822 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7943
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4587 - categorical_accuracy: 0.7940
4000/4000 [==============================] - 0s 59us/step - loss: 0.4691 - categorical_accuracy: 0.7878 - val_loss: 0.4512 - val_categorical_accuracy: 0.7922

Epoch 00032: val_loss did not improve from 0.44875
Epoch 33/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3996 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4882 - categorical_accuracy: 0.7842
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.7944
4000/4000 [==============================] - 0s 61us/step - loss: 0.4670 - categorical_accuracy: 0.7925 - val_loss: 0.4477 - val_categorical_accuracy: 0.7900

Epoch 00033: val_loss improved from 0.44875 to 0.44769, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 34/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3368 - categorical_accuracy: 0.8750
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4602 - categorical_accuracy: 0.7981
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4730 - categorical_accuracy: 0.7881
3936/4000 [============================>.] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7891
4000/4000 [==============================] - 0s 62us/step - loss: 0.4713 - categorical_accuracy: 0.7910 - val_loss: 0.4496 - val_categorical_accuracy: 0.7937

Epoch 00034: val_loss did not improve from 0.44769
Epoch 35/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3850 - categorical_accuracy: 0.8125
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4557 - categorical_accuracy: 0.7902
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.7835
4000/4000 [==============================] - 0s 60us/step - loss: 0.4701 - categorical_accuracy: 0.7887 - val_loss: 0.4490 - val_categorical_accuracy: 0.7903

Epoch 00035: val_loss did not improve from 0.44769
Epoch 36/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5302 - categorical_accuracy: 0.7188
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.7973
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4735 - categorical_accuracy: 0.7835
4000/4000 [==============================] - 0s 60us/step - loss: 0.4709 - categorical_accuracy: 0.7843 - val_loss: 0.4465 - val_categorical_accuracy: 0.7895

Epoch 00036: val_loss improved from 0.44769 to 0.44648, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 37/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4726 - categorical_accuracy: 0.8125
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.7991
2528/4000 [=================>............] - ETA: 0s - loss: 0.4601 - categorical_accuracy: 0.7939
3872/4000 [============================>.] - ETA: 0s - loss: 0.4687 - categorical_accuracy: 0.7931
4000/4000 [==============================] - 0s 63us/step - loss: 0.4692 - categorical_accuracy: 0.7930 - val_loss: 0.4473 - val_categorical_accuracy: 0.7912

Epoch 00037: val_loss did not improve from 0.44648
Epoch 38/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4189 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4632 - categorical_accuracy: 0.7965
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4761 - categorical_accuracy: 0.7831
4000/4000 [==============================] - 0s 60us/step - loss: 0.4733 - categorical_accuracy: 0.7870 - val_loss: 0.4471 - val_categorical_accuracy: 0.7903

Epoch 00038: val_loss did not improve from 0.44648
Epoch 39/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4639 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4537 - categorical_accuracy: 0.7972
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4613 - categorical_accuracy: 0.7935
4000/4000 [==============================] - 0s 59us/step - loss: 0.4662 - categorical_accuracy: 0.7895 - val_loss: 0.4482 - val_categorical_accuracy: 0.7947

Epoch 00039: val_loss did not improve from 0.44648
Epoch 40/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5311 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4822 - categorical_accuracy: 0.7718
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4684 - categorical_accuracy: 0.7835
4000/4000 [==============================] - 0s 60us/step - loss: 0.4697 - categorical_accuracy: 0.7872 - val_loss: 0.4464 - val_categorical_accuracy: 0.7908

Epoch 00040: val_loss improved from 0.44648 to 0.44639, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 41/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5338 - categorical_accuracy: 0.7500
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4668 - categorical_accuracy: 0.7820
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4632 - categorical_accuracy: 0.7944
3904/4000 [============================>.] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.7923
4000/4000 [==============================] - 0s 62us/step - loss: 0.4719 - categorical_accuracy: 0.7910 - val_loss: 0.4499 - val_categorical_accuracy: 0.7930

Epoch 00041: val_loss did not improve from 0.44639
Epoch 42/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.8750
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4465 - categorical_accuracy: 0.8021
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4494 - categorical_accuracy: 0.7945
4000/4000 [==============================] - 0s 60us/step - loss: 0.4654 - categorical_accuracy: 0.7893 - val_loss: 0.4535 - val_categorical_accuracy: 0.7928

Epoch 00042: val_loss did not improve from 0.44639
Epoch 43/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4409 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4693 - categorical_accuracy: 0.7894
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4664 - categorical_accuracy: 0.7933
3968/4000 [============================>.] - ETA: 0s - loss: 0.4684 - categorical_accuracy: 0.7921
4000/4000 [==============================] - 0s 62us/step - loss: 0.4680 - categorical_accuracy: 0.7928 - val_loss: 0.4486 - val_categorical_accuracy: 0.7935

Epoch 00043: val_loss did not improve from 0.44639
Epoch 44/150

  32/4000 [..............................] - ETA: 0s - loss: 0.2973 - categorical_accuracy: 0.9375
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4570 - categorical_accuracy: 0.7894
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7871
4000/4000 [==============================] - 0s 61us/step - loss: 0.4690 - categorical_accuracy: 0.7860 - val_loss: 0.4462 - val_categorical_accuracy: 0.7880

Epoch 00044: val_loss improved from 0.44639 to 0.44621, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 45/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4033 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4581 - categorical_accuracy: 0.7873
2560/4000 [==================>...........] - ETA: 0s - loss: 0.4567 - categorical_accuracy: 0.7965
3936/4000 [============================>.] - ETA: 0s - loss: 0.4630 - categorical_accuracy: 0.7914
4000/4000 [==============================] - 0s 62us/step - loss: 0.4628 - categorical_accuracy: 0.7908 - val_loss: 0.4465 - val_categorical_accuracy: 0.7930

Epoch 00045: val_loss did not improve from 0.44621
Epoch 46/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3788 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4670 - categorical_accuracy: 0.7820
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7762
4000/4000 [==============================] - 0s 60us/step - loss: 0.4693 - categorical_accuracy: 0.7828 - val_loss: 0.4459 - val_categorical_accuracy: 0.7947

Epoch 00046: val_loss improved from 0.44621 to 0.44589, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 47/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3417 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7950
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.7895
3968/4000 [============================>.] - ETA: 0s - loss: 0.4698 - categorical_accuracy: 0.7931
4000/4000 [==============================] - 0s 62us/step - loss: 0.4690 - categorical_accuracy: 0.7933 - val_loss: 0.4466 - val_categorical_accuracy: 0.7947

Epoch 00047: val_loss did not improve from 0.44589
Epoch 48/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3895 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4615 - categorical_accuracy: 0.7961
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4687 - categorical_accuracy: 0.7917
3968/4000 [============================>.] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.7896
4000/4000 [==============================] - 0s 62us/step - loss: 0.4712 - categorical_accuracy: 0.7895 - val_loss: 0.4475 - val_categorical_accuracy: 0.7952

Epoch 00048: val_loss did not improve from 0.44589
Epoch 49/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4604 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4555 - categorical_accuracy: 0.8038
2560/4000 [==================>...........] - ETA: 0s - loss: 0.4577 - categorical_accuracy: 0.7992
3872/4000 [============================>.] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7955
4000/4000 [==============================] - 0s 63us/step - loss: 0.4681 - categorical_accuracy: 0.7937 - val_loss: 0.4469 - val_categorical_accuracy: 0.7918

Epoch 00049: val_loss did not improve from 0.44589
Epoch 50/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4271 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.7775
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4681 - categorical_accuracy: 0.7873
3936/4000 [============================>.] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7879
4000/4000 [==============================] - 0s 62us/step - loss: 0.4740 - categorical_accuracy: 0.7887 - val_loss: 0.4474 - val_categorical_accuracy: 0.7952

Epoch 00050: val_loss did not improve from 0.44589
Epoch 51/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4859 - categorical_accuracy: 0.7500
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4456 - categorical_accuracy: 0.8088
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4578 - categorical_accuracy: 0.7993
3968/4000 [============================>.] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7926
4000/4000 [==============================] - 0s 62us/step - loss: 0.4697 - categorical_accuracy: 0.7925 - val_loss: 0.4474 - val_categorical_accuracy: 0.7925

Epoch 00051: val_loss did not improve from 0.44589
Epoch 52/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3926 - categorical_accuracy: 0.8438
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7898
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4788 - categorical_accuracy: 0.7866
4000/4000 [==============================] - 0s 60us/step - loss: 0.4691 - categorical_accuracy: 0.7897 - val_loss: 0.4463 - val_categorical_accuracy: 0.7935

Epoch 00052: val_loss did not improve from 0.44589
Epoch 53/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3682 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.7946
2176/4000 [===============>..............] - ETA: 0s - loss: 0.4582 - categorical_accuracy: 0.7918
3072/4000 [======================>.......] - ETA: 0s - loss: 0.4667 - categorical_accuracy: 0.7842
4000/4000 [==============================] - 0s 71us/step - loss: 0.4637 - categorical_accuracy: 0.7893 - val_loss: 0.4451 - val_categorical_accuracy: 0.7937

Epoch 00053: val_loss improved from 0.44589 to 0.44508, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 54/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4788 - categorical_accuracy: 0.8125
 960/4000 [======>.......................] - ETA: 0s - loss: 0.4542 - categorical_accuracy: 0.7865
1920/4000 [=============>................] - ETA: 0s - loss: 0.4442 - categorical_accuracy: 0.8000
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4511 - categorical_accuracy: 0.7999
3616/4000 [==========================>...] - ETA: 0s - loss: 0.4659 - categorical_accuracy: 0.7912
4000/4000 [==============================] - 0s 89us/step - loss: 0.4641 - categorical_accuracy: 0.7905 - val_loss: 0.4488 - val_categorical_accuracy: 0.7937

Epoch 00054: val_loss did not improve from 0.44508
Epoch 55/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5970 - categorical_accuracy: 0.7500
 992/4000 [======>.......................] - ETA: 0s - loss: 0.4436 - categorical_accuracy: 0.8065
1952/4000 [=============>................] - ETA: 0s - loss: 0.4595 - categorical_accuracy: 0.7941
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.7956
3232/4000 [=======================>......] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7905
3904/4000 [============================>.] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7889
4000/4000 [==============================] - 0s 113us/step - loss: 0.4654 - categorical_accuracy: 0.7905 - val_loss: 0.4467 - val_categorical_accuracy: 0.7915

Epoch 00055: val_loss did not improve from 0.44508
Epoch 56/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3339 - categorical_accuracy: 0.8125
1120/4000 [=======>......................] - ETA: 0s - loss: 0.4699 - categorical_accuracy: 0.7884
2336/4000 [================>.............] - ETA: 0s - loss: 0.4639 - categorical_accuracy: 0.7911
3520/4000 [=========================>....] - ETA: 0s - loss: 0.4618 - categorical_accuracy: 0.7915
4000/4000 [==============================] - 0s 66us/step - loss: 0.4645 - categorical_accuracy: 0.7893 - val_loss: 0.4459 - val_categorical_accuracy: 0.7925

Epoch 00056: val_loss did not improve from 0.44508
Epoch 57/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3261 - categorical_accuracy: 0.9062
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4522 - categorical_accuracy: 0.7912
2368/4000 [================>.............] - ETA: 0s - loss: 0.4525 - categorical_accuracy: 0.7998
3200/4000 [=======================>......] - ETA: 0s - loss: 0.4591 - categorical_accuracy: 0.7978
4000/4000 [==============================] - 0s 71us/step - loss: 0.4636 - categorical_accuracy: 0.7943 - val_loss: 0.4468 - val_categorical_accuracy: 0.7918

Epoch 00057: val_loss did not improve from 0.44508
Epoch 58/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4097 - categorical_accuracy: 0.8750
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7951
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4673 - categorical_accuracy: 0.7909
3968/4000 [============================>.] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7863
4000/4000 [==============================] - 0s 62us/step - loss: 0.4703 - categorical_accuracy: 0.7865 - val_loss: 0.4459 - val_categorical_accuracy: 0.7943

Epoch 00058: val_loss did not improve from 0.44508
Epoch 59/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4129 - categorical_accuracy: 0.7500
1440/4000 [=========>....................] - ETA: 0s - loss: 0.4581 - categorical_accuracy: 0.7979
2848/4000 [====================>.........] - ETA: 0s - loss: 0.4645 - categorical_accuracy: 0.7949
4000/4000 [==============================] - 0s 68us/step - loss: 0.4644 - categorical_accuracy: 0.7935 - val_loss: 0.4467 - val_categorical_accuracy: 0.7990

Epoch 00059: val_loss did not improve from 0.44508
Epoch 60/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4012 - categorical_accuracy: 0.8125
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4635 - categorical_accuracy: 0.7939
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7958
4000/4000 [==============================] - 0s 60us/step - loss: 0.4689 - categorical_accuracy: 0.7930 - val_loss: 0.4452 - val_categorical_accuracy: 0.7972

Epoch 00060: val_loss did not improve from 0.44508
Epoch 61/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3763 - categorical_accuracy: 0.8125
1440/4000 [=========>....................] - ETA: 0s - loss: 0.4685 - categorical_accuracy: 0.7944
2848/4000 [====================>.........] - ETA: 0s - loss: 0.4649 - categorical_accuracy: 0.7942
4000/4000 [==============================] - 0s 58us/step - loss: 0.4665 - categorical_accuracy: 0.7903 - val_loss: 0.4462 - val_categorical_accuracy: 0.7952

Epoch 00061: val_loss did not improve from 0.44508
Epoch 62/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3391 - categorical_accuracy: 0.7812
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4543 - categorical_accuracy: 0.7976
2816/4000 [====================>.........] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7880
4000/4000 [==============================] - 0s 58us/step - loss: 0.4668 - categorical_accuracy: 0.7862 - val_loss: 0.4452 - val_categorical_accuracy: 0.7945

Epoch 00062: val_loss did not improve from 0.44508
Epoch 63/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4908 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4823 - categorical_accuracy: 0.7762
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4691 - categorical_accuracy: 0.7911
4000/4000 [==============================] - 0s 61us/step - loss: 0.4639 - categorical_accuracy: 0.7950 - val_loss: 0.4451 - val_categorical_accuracy: 0.7962

Epoch 00063: val_loss did not improve from 0.44508
Epoch 64/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5094 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4646 - categorical_accuracy: 0.7969
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7961
4000/4000 [==============================] - 0s 59us/step - loss: 0.4709 - categorical_accuracy: 0.7925 - val_loss: 0.4454 - val_categorical_accuracy: 0.7962

Epoch 00064: val_loss did not improve from 0.44508
Epoch 65/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4136 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4700 - categorical_accuracy: 0.7812
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4758 - categorical_accuracy: 0.7820
4000/4000 [==============================] - 0s 60us/step - loss: 0.4672 - categorical_accuracy: 0.7870 - val_loss: 0.4456 - val_categorical_accuracy: 0.7955

Epoch 00065: val_loss did not improve from 0.44508
Epoch 66/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5720 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7917
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4691 - categorical_accuracy: 0.7857
4000/4000 [==============================] - 0s 60us/step - loss: 0.4605 - categorical_accuracy: 0.7900 - val_loss: 0.4467 - val_categorical_accuracy: 0.7940

Epoch 00066: val_loss did not improve from 0.44508
Epoch 67/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3601 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.8001
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4672 - categorical_accuracy: 0.7922
4000/4000 [==============================] - 0s 60us/step - loss: 0.4666 - categorical_accuracy: 0.7885 - val_loss: 0.4462 - val_categorical_accuracy: 0.7972

Epoch 00067: val_loss did not improve from 0.44508
Epoch 68/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5608 - categorical_accuracy: 0.8125
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4856 - categorical_accuracy: 0.7805
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4608 - categorical_accuracy: 0.7986
3968/4000 [============================>.] - ETA: 0s - loss: 0.4659 - categorical_accuracy: 0.7896
4000/4000 [==============================] - 0s 61us/step - loss: 0.4661 - categorical_accuracy: 0.7897 - val_loss: 0.4467 - val_categorical_accuracy: 0.7962

Epoch 00068: val_loss did not improve from 0.44508
Epoch 69/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4724 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4620 - categorical_accuracy: 0.7965
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4667 - categorical_accuracy: 0.7913
4000/4000 [==============================] - 0s 61us/step - loss: 0.4617 - categorical_accuracy: 0.7943 - val_loss: 0.4455 - val_categorical_accuracy: 0.7975

Epoch 00069: val_loss did not improve from 0.44508
Epoch 70/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5977 - categorical_accuracy: 0.7188
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4545 - categorical_accuracy: 0.8004
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4616 - categorical_accuracy: 0.7930
4000/4000 [==============================] - 0s 59us/step - loss: 0.4603 - categorical_accuracy: 0.7947 - val_loss: 0.4459 - val_categorical_accuracy: 0.7965

Epoch 00070: val_loss did not improve from 0.44508
Epoch 71/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3702 - categorical_accuracy: 0.8125
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4648 - categorical_accuracy: 0.7887
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7809
4000/4000 [==============================] - 0s 62us/step - loss: 0.4666 - categorical_accuracy: 0.7883 - val_loss: 0.4467 - val_categorical_accuracy: 0.7947

Epoch 00071: val_loss did not improve from 0.44508
Epoch 72/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5948 - categorical_accuracy: 0.7188
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7837
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7854
3968/4000 [============================>.] - ETA: 0s - loss: 0.4582 - categorical_accuracy: 0.7888
4000/4000 [==============================] - 0s 61us/step - loss: 0.4575 - categorical_accuracy: 0.7893 - val_loss: 0.4449 - val_categorical_accuracy: 0.7965

Epoch 00072: val_loss improved from 0.44508 to 0.44494, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 73/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6405 - categorical_accuracy: 0.5938
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4562 - categorical_accuracy: 0.7941
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4717 - categorical_accuracy: 0.7870
3936/4000 [============================>.] - ETA: 0s - loss: 0.4658 - categorical_accuracy: 0.7912
4000/4000 [==============================] - 0s 61us/step - loss: 0.4656 - categorical_accuracy: 0.7912 - val_loss: 0.4459 - val_categorical_accuracy: 0.7930

Epoch 00073: val_loss did not improve from 0.44494
Epoch 74/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3933 - categorical_accuracy: 0.8750
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4429 - categorical_accuracy: 0.8162
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4617 - categorical_accuracy: 0.7983
4000/4000 [==============================] - 0s 58us/step - loss: 0.4649 - categorical_accuracy: 0.7935 - val_loss: 0.4459 - val_categorical_accuracy: 0.7960

Epoch 00074: val_loss did not improve from 0.44494
Epoch 75/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4110 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.7812
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4712 - categorical_accuracy: 0.7838
4000/4000 [==============================] - 0s 59us/step - loss: 0.4619 - categorical_accuracy: 0.7905 - val_loss: 0.4464 - val_categorical_accuracy: 0.7945

Epoch 00075: val_loss did not improve from 0.44494
Epoch 76/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4304 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4471 - categorical_accuracy: 0.8096
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4581 - categorical_accuracy: 0.7969
4000/4000 [==============================] - 0s 59us/step - loss: 0.4587 - categorical_accuracy: 0.7952 - val_loss: 0.4445 - val_categorical_accuracy: 0.7975

Epoch 00076: val_loss improved from 0.44494 to 0.44446, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 77/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4541 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.8034
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4777 - categorical_accuracy: 0.7945
4000/4000 [==============================] - 0s 59us/step - loss: 0.4681 - categorical_accuracy: 0.7960 - val_loss: 0.4450 - val_categorical_accuracy: 0.7965

Epoch 00077: val_loss did not improve from 0.44446
Epoch 78/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5929 - categorical_accuracy: 0.7188
1440/4000 [=========>....................] - ETA: 0s - loss: 0.4540 - categorical_accuracy: 0.8056
2880/4000 [====================>.........] - ETA: 0s - loss: 0.4586 - categorical_accuracy: 0.7972
4000/4000 [==============================] - 0s 58us/step - loss: 0.4644 - categorical_accuracy: 0.7933 - val_loss: 0.4463 - val_categorical_accuracy: 0.7940

Epoch 00078: val_loss did not improve from 0.44446
Epoch 79/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4616 - categorical_accuracy: 0.7961
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4570 - categorical_accuracy: 0.7972
4000/4000 [==============================] - 0s 61us/step - loss: 0.4598 - categorical_accuracy: 0.7945 - val_loss: 0.4482 - val_categorical_accuracy: 0.7950

Epoch 00079: val_loss did not improve from 0.44446
Epoch 80/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3733 - categorical_accuracy: 0.8125
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.7965
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4521 - categorical_accuracy: 0.7985
4000/4000 [==============================] - 0s 60us/step - loss: 0.4619 - categorical_accuracy: 0.7910 - val_loss: 0.4453 - val_categorical_accuracy: 0.7980

Epoch 00080: val_loss did not improve from 0.44446
Epoch 81/150

  32/4000 [..............................] - ETA: 0s - loss: 0.2799 - categorical_accuracy: 0.8750
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4700 - categorical_accuracy: 0.7917
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4622 - categorical_accuracy: 0.7965
4000/4000 [==============================] - 0s 60us/step - loss: 0.4593 - categorical_accuracy: 0.7940 - val_loss: 0.4454 - val_categorical_accuracy: 0.7987

Epoch 00081: val_loss did not improve from 0.44446
Epoch 82/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4016 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4406 - categorical_accuracy: 0.8060
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4607 - categorical_accuracy: 0.7983
4000/4000 [==============================] - 0s 59us/step - loss: 0.4587 - categorical_accuracy: 0.7947 - val_loss: 0.4460 - val_categorical_accuracy: 0.7972

Epoch 00082: val_loss did not improve from 0.44446
Epoch 83/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5468 - categorical_accuracy: 0.7188
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4501 - categorical_accuracy: 0.7943
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4620 - categorical_accuracy: 0.7953
4000/4000 [==============================] - 0s 59us/step - loss: 0.4617 - categorical_accuracy: 0.7960 - val_loss: 0.4471 - val_categorical_accuracy: 0.7970

Epoch 00083: val_loss did not improve from 0.44446
Epoch 84/150

  32/4000 [..............................] - ETA: 0s - loss: 0.2648 - categorical_accuracy: 0.9062
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4522 - categorical_accuracy: 0.7856
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4528 - categorical_accuracy: 0.7898
4000/4000 [==============================] - 0s 59us/step - loss: 0.4559 - categorical_accuracy: 0.7897 - val_loss: 0.4460 - val_categorical_accuracy: 0.7960

Epoch 00084: val_loss did not improve from 0.44446
Epoch 85/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4397 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7936
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4570 - categorical_accuracy: 0.7929
4000/4000 [==============================] - 0s 60us/step - loss: 0.4567 - categorical_accuracy: 0.7937 - val_loss: 0.4455 - val_categorical_accuracy: 0.7983

Epoch 00085: val_loss did not improve from 0.44446
Epoch 86/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3662 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4483 - categorical_accuracy: 0.8009
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4588 - categorical_accuracy: 0.7946
3968/4000 [============================>.] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.7946
4000/4000 [==============================] - 0s 60us/step - loss: 0.4554 - categorical_accuracy: 0.7950 - val_loss: 0.4456 - val_categorical_accuracy: 0.7955

Epoch 00086: val_loss did not improve from 0.44446
Epoch 87/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4979 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4370 - categorical_accuracy: 0.8001
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4604 - categorical_accuracy: 0.7899
4000/4000 [==============================] - 0s 60us/step - loss: 0.4625 - categorical_accuracy: 0.7905 - val_loss: 0.4455 - val_categorical_accuracy: 0.7972

Epoch 00087: val_loss did not improve from 0.44446
Epoch 88/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4719 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4440 - categorical_accuracy: 0.8067
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4512 - categorical_accuracy: 0.8035
4000/4000 [==============================] - 0s 59us/step - loss: 0.4578 - categorical_accuracy: 0.7935 - val_loss: 0.4459 - val_categorical_accuracy: 0.7972

Epoch 00088: val_loss did not improve from 0.44446
Epoch 89/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3935 - categorical_accuracy: 0.8125
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4457 - categorical_accuracy: 0.8110
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4625 - categorical_accuracy: 0.7924
4000/4000 [==============================] - 0s 59us/step - loss: 0.4613 - categorical_accuracy: 0.7880 - val_loss: 0.4464 - val_categorical_accuracy: 0.7970

Epoch 00089: val_loss did not improve from 0.44446
Epoch 90/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5121 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4794 - categorical_accuracy: 0.7842
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.7926
4000/4000 [==============================] - 0s 59us/step - loss: 0.4676 - categorical_accuracy: 0.7915 - val_loss: 0.4471 - val_categorical_accuracy: 0.7960

Epoch 00090: val_loss did not improve from 0.44446
Epoch 91/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3447 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7907
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.7857
4000/4000 [==============================] - 0s 59us/step - loss: 0.4641 - categorical_accuracy: 0.7920 - val_loss: 0.4458 - val_categorical_accuracy: 0.7955

Epoch 00091: val_loss did not improve from 0.44446
Epoch 92/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5455 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.7907
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4626 - categorical_accuracy: 0.7831
3776/4000 [===========================>..] - ETA: 0s - loss: 0.4577 - categorical_accuracy: 0.7913
4000/4000 [==============================] - 0s 63us/step - loss: 0.4573 - categorical_accuracy: 0.7925 - val_loss: 0.4461 - val_categorical_accuracy: 0.7975

Epoch 00092: val_loss did not improve from 0.44446
Epoch 93/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3998 - categorical_accuracy: 0.8125
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4268 - categorical_accuracy: 0.8069
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4463 - categorical_accuracy: 0.7982
3968/4000 [============================>.] - ETA: 0s - loss: 0.4586 - categorical_accuracy: 0.7928
4000/4000 [==============================] - 0s 62us/step - loss: 0.4585 - categorical_accuracy: 0.7925 - val_loss: 0.4472 - val_categorical_accuracy: 0.7965

Epoch 00093: val_loss did not improve from 0.44446
Epoch 94/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5567 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4669 - categorical_accuracy: 0.7850
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4459 - categorical_accuracy: 0.8043
4000/4000 [==============================] - 0s 59us/step - loss: 0.4529 - categorical_accuracy: 0.7962 - val_loss: 0.4460 - val_categorical_accuracy: 0.7970

Epoch 00094: val_loss did not improve from 0.44446
Epoch 95/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6092 - categorical_accuracy: 0.6562
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4536 - categorical_accuracy: 0.7945
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4657 - categorical_accuracy: 0.7907
3968/4000 [============================>.] - ETA: 0s - loss: 0.4599 - categorical_accuracy: 0.7918
4000/4000 [==============================] - 0s 61us/step - loss: 0.4596 - categorical_accuracy: 0.7915 - val_loss: 0.4464 - val_categorical_accuracy: 0.7983

Epoch 00095: val_loss did not improve from 0.44446
Epoch 96/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4769 - categorical_accuracy: 0.8750
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4613 - categorical_accuracy: 0.7873
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4542 - categorical_accuracy: 0.7937
3904/4000 [============================>.] - ETA: 0s - loss: 0.4548 - categorical_accuracy: 0.7971
4000/4000 [==============================] - 0s 66us/step - loss: 0.4553 - categorical_accuracy: 0.7972 - val_loss: 0.4458 - val_categorical_accuracy: 0.7993

Epoch 00096: val_loss did not improve from 0.44446
Epoch 97/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5484 - categorical_accuracy: 0.7500
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7879
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7909
4000/4000 [==============================] - 0s 61us/step - loss: 0.4628 - categorical_accuracy: 0.7920 - val_loss: 0.4450 - val_categorical_accuracy: 0.7990

Epoch 00097: val_loss did not improve from 0.44446
Epoch 98/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6158 - categorical_accuracy: 0.5938
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4525 - categorical_accuracy: 0.7850
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4637 - categorical_accuracy: 0.7812
4000/4000 [==============================] - 0s 60us/step - loss: 0.4585 - categorical_accuracy: 0.7883 - val_loss: 0.4456 - val_categorical_accuracy: 0.7987

Epoch 00098: val_loss did not improve from 0.44446
Epoch 99/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4632 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4619 - categorical_accuracy: 0.7936
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4505 - categorical_accuracy: 0.8020
4000/4000 [==============================] - 0s 59us/step - loss: 0.4531 - categorical_accuracy: 0.7962 - val_loss: 0.4460 - val_categorical_accuracy: 0.7985

Epoch 00099: val_loss did not improve from 0.44446
Epoch 100/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5639 - categorical_accuracy: 0.7500
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4445 - categorical_accuracy: 0.7995
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4540 - categorical_accuracy: 0.7965
4000/4000 [==============================] - 0s 61us/step - loss: 0.4573 - categorical_accuracy: 0.7962 - val_loss: 0.4475 - val_categorical_accuracy: 0.7945

Epoch 00100: val_loss did not improve from 0.44446
Epoch 101/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6717 - categorical_accuracy: 0.6250
1120/4000 [=======>......................] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.7902
2528/4000 [=================>............] - ETA: 0s - loss: 0.4536 - categorical_accuracy: 0.7967
3808/4000 [===========================>..] - ETA: 0s - loss: 0.4633 - categorical_accuracy: 0.7923
4000/4000 [==============================] - 0s 62us/step - loss: 0.4618 - categorical_accuracy: 0.7933 - val_loss: 0.4464 - val_categorical_accuracy: 0.7975

Epoch 00101: val_loss did not improve from 0.44446
Epoch 102/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4345 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.7940
2816/4000 [====================>.........] - ETA: 0s - loss: 0.4587 - categorical_accuracy: 0.7937
4000/4000 [==============================] - 0s 59us/step - loss: 0.4635 - categorical_accuracy: 0.7918 - val_loss: 0.4478 - val_categorical_accuracy: 0.7960

Epoch 00102: val_loss did not improve from 0.44446
Epoch 103/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3302 - categorical_accuracy: 0.8750
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4542 - categorical_accuracy: 0.7940
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4617 - categorical_accuracy: 0.7892
4000/4000 [==============================] - 0s 58us/step - loss: 0.4616 - categorical_accuracy: 0.7928 - val_loss: 0.4464 - val_categorical_accuracy: 0.7962

Epoch 00103: val_loss did not improve from 0.44446
Epoch 104/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5824 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4646 - categorical_accuracy: 0.7940
2816/4000 [====================>.........] - ETA: 0s - loss: 0.4597 - categorical_accuracy: 0.7965
4000/4000 [==============================] - 0s 59us/step - loss: 0.4604 - categorical_accuracy: 0.7947 - val_loss: 0.4485 - val_categorical_accuracy: 0.7940

Epoch 00104: val_loss did not improve from 0.44446
Epoch 105/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5654 - categorical_accuracy: 0.7188
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4597 - categorical_accuracy: 0.7929
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4517 - categorical_accuracy: 0.8017
4000/4000 [==============================] - 0s 60us/step - loss: 0.4576 - categorical_accuracy: 0.7958 - val_loss: 0.4473 - val_categorical_accuracy: 0.7980

Epoch 00105: val_loss did not improve from 0.44446
Epoch 106/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3213 - categorical_accuracy: 0.8750
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4627 - categorical_accuracy: 0.7798
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7910
4000/4000 [==============================] - 0s 60us/step - loss: 0.4553 - categorical_accuracy: 0.7997 - val_loss: 0.4457 - val_categorical_accuracy: 0.7972

Epoch 00106: val_loss did not improve from 0.44446
Epoch 107/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.8067
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4624 - categorical_accuracy: 0.7982
4000/4000 [==============================] - 0s 60us/step - loss: 0.4614 - categorical_accuracy: 0.7977 - val_loss: 0.4468 - val_categorical_accuracy: 0.7972

Epoch 00107: val_loss did not improve from 0.44446
Epoch 108/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3767 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4560 - categorical_accuracy: 0.7958
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4636 - categorical_accuracy: 0.7835
4000/4000 [==============================] - 0s 59us/step - loss: 0.4596 - categorical_accuracy: 0.7872 - val_loss: 0.4461 - val_categorical_accuracy: 0.7965

Epoch 00108: val_loss did not improve from 0.44446
Epoch 109/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3067 - categorical_accuracy: 0.9062
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4405 - categorical_accuracy: 0.7957
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4436 - categorical_accuracy: 0.7948
4000/4000 [==============================] - 0s 59us/step - loss: 0.4578 - categorical_accuracy: 0.7925 - val_loss: 0.4460 - val_categorical_accuracy: 0.7980

Epoch 00109: val_loss did not improve from 0.44446
Epoch 110/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3364 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4494 - categorical_accuracy: 0.8038
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.7985
4000/4000 [==============================] - 0s 60us/step - loss: 0.4599 - categorical_accuracy: 0.7930 - val_loss: 0.4469 - val_categorical_accuracy: 0.7962

Epoch 00110: val_loss did not improve from 0.44446
Epoch 111/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.8438
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4516 - categorical_accuracy: 0.7862
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4486 - categorical_accuracy: 0.7960
4000/4000 [==============================] - 0s 59us/step - loss: 0.4522 - categorical_accuracy: 0.7908 - val_loss: 0.4489 - val_categorical_accuracy: 0.7930

Epoch 00111: val_loss did not improve from 0.44446
Epoch 112/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4616 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4646 - categorical_accuracy: 0.7909
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4533 - categorical_accuracy: 0.8005
4000/4000 [==============================] - 0s 61us/step - loss: 0.4549 - categorical_accuracy: 0.7990 - val_loss: 0.4466 - val_categorical_accuracy: 0.7968

Epoch 00112: val_loss did not improve from 0.44446
Epoch 113/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3864 - categorical_accuracy: 0.8125
1184/4000 [=======>......................] - ETA: 0s - loss: 0.4492 - categorical_accuracy: 0.7914
2560/4000 [==================>...........] - ETA: 0s - loss: 0.4601 - categorical_accuracy: 0.7941
3936/4000 [============================>.] - ETA: 0s - loss: 0.4622 - categorical_accuracy: 0.7929
4000/4000 [==============================] - 0s 61us/step - loss: 0.4629 - categorical_accuracy: 0.7925 - val_loss: 0.4473 - val_categorical_accuracy: 0.7945

Epoch 00113: val_loss did not improve from 0.44446
Epoch 114/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3724 - categorical_accuracy: 0.8125
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4829 - categorical_accuracy: 0.7752
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4595 - categorical_accuracy: 0.7882
4000/4000 [==============================] - 0s 60us/step - loss: 0.4579 - categorical_accuracy: 0.7910 - val_loss: 0.4460 - val_categorical_accuracy: 0.7947

Epoch 00114: val_loss did not improve from 0.44446
Epoch 115/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5355 - categorical_accuracy: 0.7188
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4529 - categorical_accuracy: 0.7912
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4596 - categorical_accuracy: 0.7934
3968/4000 [============================>.] - ETA: 0s - loss: 0.4592 - categorical_accuracy: 0.7941
4000/4000 [==============================] - 0s 60us/step - loss: 0.4585 - categorical_accuracy: 0.7947 - val_loss: 0.4470 - val_categorical_accuracy: 0.7952

Epoch 00115: val_loss did not improve from 0.44446
Epoch 116/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4151 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4626 - categorical_accuracy: 0.7887
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4494 - categorical_accuracy: 0.7956
4000/4000 [==============================] - 0s 59us/step - loss: 0.4565 - categorical_accuracy: 0.7945 - val_loss: 0.4475 - val_categorical_accuracy: 0.7965

Epoch 00116: val_loss did not improve from 0.44446
Epoch 117/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6145 - categorical_accuracy: 0.7188
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4984 - categorical_accuracy: 0.7648
2496/4000 [=================>............] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7821
3840/4000 [===========================>..] - ETA: 0s - loss: 0.4670 - categorical_accuracy: 0.7854
4000/4000 [==============================] - 0s 62us/step - loss: 0.4645 - categorical_accuracy: 0.7865 - val_loss: 0.4461 - val_categorical_accuracy: 0.7965

Epoch 00117: val_loss did not improve from 0.44446
Epoch 118/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5119 - categorical_accuracy: 0.6875
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4732 - categorical_accuracy: 0.7843
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.7950
4000/4000 [==============================] - 0s 59us/step - loss: 0.4567 - categorical_accuracy: 0.7975 - val_loss: 0.4452 - val_categorical_accuracy: 0.7972

Epoch 00118: val_loss did not improve from 0.44446
Epoch 119/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4214 - categorical_accuracy: 0.7812
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4604 - categorical_accuracy: 0.7896
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4573 - categorical_accuracy: 0.7941
4000/4000 [==============================] - 0s 59us/step - loss: 0.4558 - categorical_accuracy: 0.7922 - val_loss: 0.4455 - val_categorical_accuracy: 0.7958

Epoch 00119: val_loss did not improve from 0.44446
Epoch 120/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3361 - categorical_accuracy: 0.9062
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4949 - categorical_accuracy: 0.7768
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4644 - categorical_accuracy: 0.7950
4000/4000 [==============================] - 0s 60us/step - loss: 0.4570 - categorical_accuracy: 0.7972 - val_loss: 0.4461 - val_categorical_accuracy: 0.7945

Epoch 00120: val_loss did not improve from 0.44446
Epoch 121/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4888 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4481 - categorical_accuracy: 0.8054
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4508 - categorical_accuracy: 0.8026
3616/4000 [==========================>...] - ETA: 0s - loss: 0.4551 - categorical_accuracy: 0.7987
4000/4000 [==============================] - 0s 64us/step - loss: 0.4528 - categorical_accuracy: 0.7983 - val_loss: 0.4460 - val_categorical_accuracy: 0.7958

Epoch 00121: val_loss did not improve from 0.44446
Epoch 122/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.7871
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4546 - categorical_accuracy: 0.7920
4000/4000 [==============================] - 0s 61us/step - loss: 0.4574 - categorical_accuracy: 0.7943 - val_loss: 0.4472 - val_categorical_accuracy: 0.7955

Epoch 00122: val_loss did not improve from 0.44446
Epoch 123/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4659 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7907
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.7908
4000/4000 [==============================] - 0s 59us/step - loss: 0.4568 - categorical_accuracy: 0.7920 - val_loss: 0.4478 - val_categorical_accuracy: 0.7937

Epoch 00123: val_loss did not improve from 0.44446
Epoch 124/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4188 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4325 - categorical_accuracy: 0.8038
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4541 - categorical_accuracy: 0.7945
4000/4000 [==============================] - 0s 59us/step - loss: 0.4571 - categorical_accuracy: 0.7950 - val_loss: 0.4497 - val_categorical_accuracy: 0.7937

Epoch 00124: val_loss did not improve from 0.44446
Epoch 125/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4673 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4568 - categorical_accuracy: 0.7972
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4524 - categorical_accuracy: 0.7952
4000/4000 [==============================] - 0s 60us/step - loss: 0.4509 - categorical_accuracy: 0.7952 - val_loss: 0.4469 - val_categorical_accuracy: 0.7947

Epoch 00125: val_loss did not improve from 0.44446
Epoch 126/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3730 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4597 - categorical_accuracy: 0.7842
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.7894
4000/4000 [==============================] - 0s 59us/step - loss: 0.4620 - categorical_accuracy: 0.7925 - val_loss: 0.4470 - val_categorical_accuracy: 0.7955

Epoch 00126: val_loss did not improve from 0.44446
Epoch 127/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5124 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4451 - categorical_accuracy: 0.8118
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4522 - categorical_accuracy: 0.7972
4000/4000 [==============================] - 0s 59us/step - loss: 0.4549 - categorical_accuracy: 0.7905 - val_loss: 0.4478 - val_categorical_accuracy: 0.7952

Epoch 00127: val_loss did not improve from 0.44446
Epoch 128/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4942 - categorical_accuracy: 0.8125
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4447 - categorical_accuracy: 0.8087
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4476 - categorical_accuracy: 0.7984
4000/4000 [==============================] - 0s 61us/step - loss: 0.4545 - categorical_accuracy: 0.7937 - val_loss: 0.4471 - val_categorical_accuracy: 0.7940

Epoch 00128: val_loss did not improve from 0.44446
Epoch 129/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4053 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4437 - categorical_accuracy: 0.8095
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4500 - categorical_accuracy: 0.7996
4000/4000 [==============================] - 0s 68us/step - loss: 0.4597 - categorical_accuracy: 0.7950 - val_loss: 0.4468 - val_categorical_accuracy: 0.7962

Epoch 00129: val_loss did not improve from 0.44446
Epoch 130/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4736 - categorical_accuracy: 0.7812
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4604 - categorical_accuracy: 0.7924
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4501 - categorical_accuracy: 0.8010
4000/4000 [==============================] - 0s 60us/step - loss: 0.4517 - categorical_accuracy: 0.7935 - val_loss: 0.4464 - val_categorical_accuracy: 0.7977

Epoch 00130: val_loss did not improve from 0.44446
Epoch 131/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4339 - categorical_accuracy: 0.8125
 928/4000 [=====>........................] - ETA: 0s - loss: 0.4507 - categorical_accuracy: 0.8028
2176/4000 [===============>..............] - ETA: 0s - loss: 0.4628 - categorical_accuracy: 0.7960
3488/4000 [=========================>....] - ETA: 0s - loss: 0.4629 - categorical_accuracy: 0.7944
4000/4000 [==============================] - 0s 66us/step - loss: 0.4632 - categorical_accuracy: 0.7955 - val_loss: 0.4466 - val_categorical_accuracy: 0.7977

Epoch 00131: val_loss did not improve from 0.44446
Epoch 132/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4608 - categorical_accuracy: 0.8023
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4623 - categorical_accuracy: 0.7908
4000/4000 [==============================] - 0s 60us/step - loss: 0.4566 - categorical_accuracy: 0.7915 - val_loss: 0.4460 - val_categorical_accuracy: 0.7947

Epoch 00132: val_loss did not improve from 0.44446
Epoch 133/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3082 - categorical_accuracy: 0.9062
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4484 - categorical_accuracy: 0.8073
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4556 - categorical_accuracy: 0.7991
3936/4000 [============================>.] - ETA: 0s - loss: 0.4603 - categorical_accuracy: 0.7965
4000/4000 [==============================] - 0s 61us/step - loss: 0.4594 - categorical_accuracy: 0.7972 - val_loss: 0.4481 - val_categorical_accuracy: 0.7962

Epoch 00133: val_loss did not improve from 0.44446
Epoch 134/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6771 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4593 - categorical_accuracy: 0.7738
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.7857
4000/4000 [==============================] - 0s 58us/step - loss: 0.4531 - categorical_accuracy: 0.7900 - val_loss: 0.4464 - val_categorical_accuracy: 0.7945

Epoch 00134: val_loss did not improve from 0.44446
Epoch 135/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4439 - categorical_accuracy: 0.8750
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4606 - categorical_accuracy: 0.8006
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.7998
4000/4000 [==============================] - 0s 61us/step - loss: 0.4586 - categorical_accuracy: 0.7997 - val_loss: 0.4459 - val_categorical_accuracy: 0.7972

Epoch 00135: val_loss did not improve from 0.44446
Epoch 136/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3942 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4428 - categorical_accuracy: 0.8118
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4567 - categorical_accuracy: 0.7972
4000/4000 [==============================] - 0s 59us/step - loss: 0.4547 - categorical_accuracy: 0.7958 - val_loss: 0.4478 - val_categorical_accuracy: 0.7983

Epoch 00136: val_loss did not improve from 0.44446
Epoch 137/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3156 - categorical_accuracy: 0.8750
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4438 - categorical_accuracy: 0.8118
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4547 - categorical_accuracy: 0.8006
3936/4000 [============================>.] - ETA: 0s - loss: 0.4544 - categorical_accuracy: 0.7978
4000/4000 [==============================] - 0s 63us/step - loss: 0.4538 - categorical_accuracy: 0.7985 - val_loss: 0.4462 - val_categorical_accuracy: 0.7983

Epoch 00137: val_loss did not improve from 0.44446
Epoch 138/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4390 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4574 - categorical_accuracy: 0.7951
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4500 - categorical_accuracy: 0.7996
4000/4000 [==============================] - 0s 61us/step - loss: 0.4543 - categorical_accuracy: 0.7947 - val_loss: 0.4466 - val_categorical_accuracy: 0.7943

Epoch 00138: val_loss did not improve from 0.44446
Epoch 139/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6181 - categorical_accuracy: 0.6875
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4540 - categorical_accuracy: 0.8169
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4551 - categorical_accuracy: 0.8012
4000/4000 [==============================] - 0s 59us/step - loss: 0.4584 - categorical_accuracy: 0.7980 - val_loss: 0.4470 - val_categorical_accuracy: 0.7950

Epoch 00139: val_loss did not improve from 0.44446
Epoch 140/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5035 - categorical_accuracy: 0.6875
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4573 - categorical_accuracy: 0.8006
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4591 - categorical_accuracy: 0.7903
4000/4000 [==============================] - 0s 59us/step - loss: 0.4485 - categorical_accuracy: 0.7980 - val_loss: 0.4462 - val_categorical_accuracy: 0.7972

Epoch 00140: val_loss did not improve from 0.44446
Epoch 141/150

  32/4000 [..............................] - ETA: 0s - loss: 0.2986 - categorical_accuracy: 0.9062
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4555 - categorical_accuracy: 0.7902
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4483 - categorical_accuracy: 0.7984
4000/4000 [==============================] - 0s 65us/step - loss: 0.4521 - categorical_accuracy: 0.7940 - val_loss: 0.4470 - val_categorical_accuracy: 0.7958

Epoch 00141: val_loss did not improve from 0.44446
Epoch 142/150

  32/4000 [..............................] - ETA: 0s - loss: 0.2860 - categorical_accuracy: 0.8750
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4549 - categorical_accuracy: 0.8003
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4518 - categorical_accuracy: 0.8030
3968/4000 [============================>.] - ETA: 0s - loss: 0.4547 - categorical_accuracy: 0.7984
4000/4000 [==============================] - 0s 62us/step - loss: 0.4549 - categorical_accuracy: 0.7983 - val_loss: 0.4468 - val_categorical_accuracy: 0.7965

Epoch 00142: val_loss did not improve from 0.44446
Epoch 143/150

  32/4000 [..............................] - ETA: 0s - loss: 0.2779 - categorical_accuracy: 0.9688
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4425 - categorical_accuracy: 0.8097
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4630 - categorical_accuracy: 0.7929
4000/4000 [==============================] - 0s 59us/step - loss: 0.4613 - categorical_accuracy: 0.7935 - val_loss: 0.4462 - val_categorical_accuracy: 0.7965

Epoch 00143: val_loss did not improve from 0.44446
Epoch 144/150

  32/4000 [..............................] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4530 - categorical_accuracy: 0.7972
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4487 - categorical_accuracy: 0.7993
4000/4000 [==============================] - 0s 59us/step - loss: 0.4571 - categorical_accuracy: 0.7920 - val_loss: 0.4469 - val_categorical_accuracy: 0.7970

Epoch 00144: val_loss did not improve from 0.44446
Epoch 145/150

  32/4000 [..............................] - ETA: 0s - loss: 0.5407 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4533 - categorical_accuracy: 0.7976
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4518 - categorical_accuracy: 0.7994
4000/4000 [==============================] - 0s 61us/step - loss: 0.4518 - categorical_accuracy: 0.7958 - val_loss: 0.4469 - val_categorical_accuracy: 0.7977

Epoch 00145: val_loss did not improve from 0.44446
Epoch 146/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3051 - categorical_accuracy: 0.9062
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4421 - categorical_accuracy: 0.8001
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4485 - categorical_accuracy: 0.7998
4000/4000 [==============================] - 0s 58us/step - loss: 0.4576 - categorical_accuracy: 0.7950 - val_loss: 0.4473 - val_categorical_accuracy: 0.7970

Epoch 00146: val_loss did not improve from 0.44446
Epoch 147/150

  32/4000 [..............................] - ETA: 0s - loss: 0.6504 - categorical_accuracy: 0.6875
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4567 - categorical_accuracy: 0.8110
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4552 - categorical_accuracy: 0.7961
4000/4000 [==============================] - 0s 59us/step - loss: 0.4582 - categorical_accuracy: 0.7912 - val_loss: 0.4466 - val_categorical_accuracy: 0.7975

Epoch 00147: val_loss did not improve from 0.44446
Epoch 148/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3269 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4657 - categorical_accuracy: 0.7850
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4563 - categorical_accuracy: 0.7906
4000/4000 [==============================] - 0s 59us/step - loss: 0.4543 - categorical_accuracy: 0.7952 - val_loss: 0.4457 - val_categorical_accuracy: 0.7980

Epoch 00148: val_loss did not improve from 0.44446
Epoch 149/150

  32/4000 [..............................] - ETA: 0s - loss: 0.7275 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4726 - categorical_accuracy: 0.7827
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4552 - categorical_accuracy: 0.7900
4000/4000 [==============================] - 0s 60us/step - loss: 0.4504 - categorical_accuracy: 0.7977 - val_loss: 0.4464 - val_categorical_accuracy: 0.7972

Epoch 00149: val_loss did not improve from 0.44446
Epoch 150/150

  32/4000 [..............................] - ETA: 0s - loss: 0.3646 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4400 - categorical_accuracy: 0.7994
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4580 - categorical_accuracy: 0.7954
4000/4000 [==============================] - 0s 59us/step - loss: 0.4534 - categorical_accuracy: 0.7987 - val_loss: 0.4471 - val_categorical_accuracy: 0.7968

Epoch 00150: val_loss did not improve from 0.44446
                         : Elapsed time for training with 4000 events: [1;31m38.6 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 4000 events: [1;31m0.572 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.123e-01
                         :    2 : mfchi2     : 2.558e-01
                         :    3 : gm2e       : 9.346e-02
                         :    4 : gm2p3cms   : 2.402e-02
                         :    5 : gmthetacms : 2.165e-02
                         :    6 : gm1e925    : 1.817e-02
                         :    7 : gm2e925    : 1.648e-02
                         :    8 : gm1p3cms   : 1.432e-02
                         :    9 : pi0p3cms   : 1.260e-02
                         :   10 : gm1eerror  : 8.618e-03
                         :   11 : gm1e       : 8.606e-03
                         :   12 : gm2eerror  : 8.575e-03
                         :   13 : ediff      : 5.406e-03
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.035344      1.0035   [     -2.9955      5.7307 ]
                         :   pi0p3cms:    0.036963      1.0008   [     -3.1514      5.7307 ]
                         :       gm1e:    0.038187      1.0153   [     -2.8532      5.7307 ]
                         :       gm2e:    0.013699     0.99659   [     -2.8713      5.7307 ]
                         :    gm1e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :    gm2e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :      ediff:    0.042492      1.0203   [     -2.9312      5.7307 ]
                         :  gm1eerror:    0.044368      1.0230   [     -2.6163      5.7307 ]
                         :  gm2eerror:    0.017235     0.98759   [     -2.6397      5.7307 ]
                         :   gm1p3cms:    0.041202      1.0084   [     -2.9885      5.7307 ]
                         :   gm2p3cms:    0.017214     0.99841   [     -3.4791      5.7307 ]
                         : gmthetacms:  -0.0033392     0.98707   [     -4.0412      5.7307 ]
                         :     mfchi2:    0.014607     0.99591   [     -2.1007      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.035344      1.0035   [     -2.9955      5.7307 ]
                         :   pi0p3cms:    0.036963      1.0008   [     -3.1514      5.7307 ]
                         :       gm1e:    0.038187      1.0153   [     -2.8532      5.7307 ]
                         :       gm2e:    0.013699     0.99659   [     -2.8713      5.7307 ]
                         :    gm1e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :    gm2e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :      ediff:    0.042492      1.0203   [     -2.9312      5.7307 ]
                         :  gm1eerror:    0.044368      1.0230   [     -2.6163      5.7307 ]
                         :  gm2eerror:    0.017235     0.98759   [     -2.6397      5.7307 ]
                         :   gm1p3cms:    0.041202      1.0084   [     -2.9885      5.7307 ]
                         :   gm2p3cms:    0.017214     0.99841   [     -3.4791      5.7307 ]
                         : gmthetacms:  -0.0033392     0.98707   [     -4.0412      5.7307 ]
                         :     mfchi2:    0.014607     0.99591   [     -2.1007      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.60427     0.56727   [   0.0049119      4.2687 ]
                         :   pi0p3cms:     0.76377     0.75986   [    0.011733      6.0224 ]
                         :       gm1e:     0.45180     0.43868   [    0.063518      3.8130 ]
                         :       gm2e:     0.17939     0.16833   [    0.060015      1.8160 ]
                         :    gm1e925:     0.95262    0.061574   [     0.26583      1.0000 ]
                         :    gm2e925:     0.95262    0.061574   [     0.26583      1.0000 ]
                         :      ediff:     0.27242     0.36967   [  3.9078e-05      3.4668 ]
                         :  gm1eerror:  0.00014844  0.00037581   [  2.2654e-06   0.0088087 ]
                         :  gm2eerror:  2.5471e-05  6.3633e-05   [  1.7405e-06   0.0012202 ]
                         :   gm1p3cms:     0.56471     0.59250   [    0.049929      5.0839 ]
                         :   gm2p3cms:     0.22127     0.22389   [    0.043825      2.6831 ]
                         : gmthetacms:     0.73038     0.52572   [    0.044029      3.0194 ]
                         :     mfchi2:      8.7567      11.451   [  2.3731e-07      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       PyKeras        : 0.875
                         : dataset       GTB            : 0.868
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              PyKeras        : 0.245 (0.281)       0.680 (0.666)      0.857 (0.858)
                         : dataset              GTB            : 0.190 (0.402)       0.652 (0.703)      0.854 (0.872)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 4000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 4000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
