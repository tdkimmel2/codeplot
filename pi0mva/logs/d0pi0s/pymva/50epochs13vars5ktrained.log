DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : [1mTrain all methods[0m
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 5000
                         : Signal     -- testing events             : 5000
                         : Signal     -- training and testing events: 10000
                         : Background -- training events            : 5000
                         : Background -- testing events             : 5000
                         : Background -- training and testing events: 10000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.974  +0.955  +0.751  -0.185  -0.185  +0.724    +0.755    +0.642   +0.937   +0.754     -0.687  -0.213
                         :   pi0p3cms:  +0.974   +1.000  +0.931  +0.734  -0.170  -0.170  +0.704    +0.759    +0.647   +0.960   +0.777     -0.672  -0.190
                         :       gm1e:  +0.955   +0.931  +1.000  +0.524  -0.128  -0.128  +0.895    +0.820    +0.448   +0.976   +0.538     -0.619  -0.192
                         :       gm2e:  +0.751   +0.734  +0.524  +1.000  -0.253  -0.253  +0.089    +0.355    +0.862   +0.526   +0.978     -0.563  -0.199
                         :    gm1e925:  -0.185   -0.170  -0.128  -0.253  +1.000  +1.000  -0.017    -0.079    -0.248   -0.118   -0.234     +0.081  -0.031
                         :    gm2e925:  -0.185   -0.170  -0.128  -0.253  +1.000  +1.000  -0.017    -0.079    -0.248   -0.118   -0.234     +0.081  -0.031
                         :      ediff:  +0.724   +0.704  +0.895  +0.089  -0.017  -0.017  +1.000    +0.773    +0.071   +0.866   +0.116     -0.428  -0.120
                         :  gm1eerror:  +0.755   +0.759  +0.820  +0.355  -0.079  -0.079  +0.773    +1.000    +0.339   +0.823   +0.380     -0.370  -0.111
                         :  gm2eerror:  +0.642   +0.647  +0.448  +0.862  -0.248  -0.248  +0.071    +0.339    +1.000   +0.463   +0.868     -0.377  -0.137
                         :   gm1p3cms:  +0.937   +0.960  +0.976  +0.526  -0.118  -0.118  +0.866    +0.823    +0.463   +1.000   +0.571     -0.614  -0.172
                         :   gm2p3cms:  +0.754   +0.777  +0.538  +0.978  -0.234  -0.234  +0.116    +0.380    +0.868   +0.571   +1.000     -0.565  -0.182
                         : gmthetacms:  -0.687   -0.672  -0.619  -0.563  +0.081  +0.081  -0.428    -0.370    -0.377   -0.614   -0.565     +1.000  +0.226
                         :     mfchi2:  -0.213   -0.190  -0.192  -0.199  -0.031  -0.031  -0.120    -0.111    -0.137   -0.172   -0.182     +0.226  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.975  +0.967  +0.635  -0.072  -0.072  +0.850    +0.786    +0.504   +0.949   +0.633     -0.716  -0.140
                         :   pi0p3cms:  +0.975   +1.000  +0.942  +0.627  -0.068  -0.068  +0.825    +0.779    +0.513   +0.969   +0.667     -0.727  -0.130
                         :       gm1e:  +0.967   +0.942  +1.000  +0.432  -0.063  -0.063  +0.954    +0.843    +0.342   +0.978   +0.441     -0.620  -0.137
                         :       gm2e:  +0.635   +0.627  +0.432  +1.000  -0.069  -0.069  +0.141    +0.301    +0.829   +0.437   +0.963     -0.547  -0.122
                         :    gm1e925:  -0.072   -0.068  -0.063  -0.069  +1.000  +1.000  -0.047    -0.034    -0.056   -0.062   -0.064     +0.047  -0.001
                         :    gm2e925:  -0.072   -0.068  -0.063  -0.069  +1.000  +1.000  -0.047    -0.034    -0.056   -0.062   -0.064     +0.047  -0.001
                         :      ediff:  +0.850   +0.825  +0.954  +0.141  -0.047  -0.047  +1.000    +0.825    +0.100   +0.928   +0.164     -0.498  -0.109
                         :  gm1eerror:  +0.786   +0.779  +0.843  +0.301  -0.034  -0.034  +0.825    +1.000    +0.253   +0.833   +0.319     -0.384  -0.120
                         :  gm2eerror:  +0.504   +0.513  +0.342  +0.829  -0.056  -0.056  +0.100    +0.253    +1.000   +0.355   +0.821     -0.347  -0.105
                         :   gm1p3cms:  +0.949   +0.969  +0.978  +0.437  -0.062  -0.062  +0.928    +0.833    +0.355   +1.000   +0.473     -0.637  -0.127
                         :   gm2p3cms:  +0.633   +0.667  +0.441  +0.963  -0.064  -0.064  +0.164    +0.319    +0.821   +0.473   +1.000     -0.586  -0.113
                         : gmthetacms:  -0.716   -0.727  -0.620  -0.547  +0.047  +0.047  -0.498    -0.384    -0.347   -0.637   -0.586     +1.000  +0.081
                         :     mfchi2:  -0.140   -0.130  -0.137  -0.122  -0.001  -0.001  -0.109    -0.120    -0.105   -0.127   -0.113     +0.081  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0060582     0.99822   [     -3.1814      5.7307 ]
                         :   pi0p3cms:   0.0060451     0.99834   [     -3.1823      5.7307 ]
                         :       gm1e:   0.0072977      1.0039   [     -3.1781      5.7307 ]
                         :       gm2e:   0.0057390     0.99688   [     -3.0048      5.7307 ]
                         :    gm1e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :    gm2e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :      ediff:   0.0071855      1.0039   [     -3.0813      5.7307 ]
                         :  gm1eerror:   0.0087212     0.98917   [     -2.9440      5.7307 ]
                         :  gm2eerror:   0.0072976     0.99978   [     -2.8631      5.7307 ]
                         :   gm1p3cms:   0.0064692      1.0006   [     -3.1755      5.7307 ]
                         :   gm2p3cms:   0.0056364     0.99686   [     -3.1597      5.7307 ]
                         : gmthetacms:   0.0059472     0.99744   [     -3.1827      5.7307 ]
                         :     mfchi2:    0.010585     0.99134   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 2.907e-01
                         :    2 : gmthetacms : 2.573e-01
                         :    3 : gm1e       : 2.565e-01
                         :    4 : pi0p3cms   : 2.465e-01
                         :    5 : gm1eerror  : 2.402e-01
                         :    6 : mfchi2     : 2.393e-01
                         :    7 : gm2e       : 2.383e-01
                         :    8 : gm1p3cms   : 2.217e-01
                         :    9 : gm2eerror  : 2.201e-01
                         :   10 : gm2p3cms   : 2.024e-01
                         :   11 : ediff      : 1.325e-01
                         :   12 : gm1e925    : 7.736e-02
                         :   13 : gm2e925    : 7.736e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0060582     0.99822   [     -3.1814      5.7307 ]
                         :   pi0p3cms:   0.0060451     0.99834   [     -3.1823      5.7307 ]
                         :       gm1e:   0.0072977      1.0039   [     -3.1781      5.7307 ]
                         :       gm2e:   0.0057390     0.99688   [     -3.0048      5.7307 ]
                         :    gm1e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :    gm2e925:     0.73319      2.1218   [     -3.1451      5.7307 ]
                         :      ediff:   0.0071855      1.0039   [     -3.0813      5.7307 ]
                         :  gm1eerror:   0.0087212     0.98917   [     -2.9440      5.7307 ]
                         :  gm2eerror:   0.0072976     0.99978   [     -2.8631      5.7307 ]
                         :   gm1p3cms:   0.0064692      1.0006   [     -3.1755      5.7307 ]
                         :   gm2p3cms:   0.0056364     0.99686   [     -3.1597      5.7307 ]
                         : gmthetacms:   0.0059472     0.99744   [     -3.1827      5.7307 ]
                         :     mfchi2:    0.010585     0.99134   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 10000 samples, validate on 10000 samples
Epoch 1/50

   32/10000 [..............................] - ETA: 49s - loss: 1.1404 - categorical_accuracy: 0.3750
 1536/10000 [===>..........................] - ETA: 1s - loss: 0.7486 - categorical_accuracy: 0.5924 
 2944/10000 [=======>......................] - ETA: 0s - loss: 0.6963 - categorical_accuracy: 0.6315
 4000/10000 [===========>..................] - ETA: 0s - loss: 0.6688 - categorical_accuracy: 0.6522
 5664/10000 [===============>..............] - ETA: 0s - loss: 0.6520 - categorical_accuracy: 0.6707
 7264/10000 [====================>.........] - ETA: 0s - loss: 0.6300 - categorical_accuracy: 0.6830
 8928/10000 [=========================>....] - ETA: 0s - loss: 0.6170 - categorical_accuracy: 0.6939
10000/10000 [==============================] - 1s 72us/step - loss: 0.6082 - categorical_accuracy: 0.6983 - val_loss: 0.4877 - val_categorical_accuracy: 0.7733

Epoch 00001: val_loss improved from inf to 0.48773, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5583 - categorical_accuracy: 0.7812
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.5408 - categorical_accuracy: 0.7468
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.5443 - categorical_accuracy: 0.7456
 4768/10000 [=============>................] - ETA: 0s - loss: 0.5330 - categorical_accuracy: 0.7502
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.5306 - categorical_accuracy: 0.7517
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.5250 - categorical_accuracy: 0.7560
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.5214 - categorical_accuracy: 0.7586
10000/10000 [==============================] - 1s 51us/step - loss: 0.5199 - categorical_accuracy: 0.7597 - val_loss: 0.4786 - val_categorical_accuracy: 0.7803

Epoch 00002: val_loss improved from 0.48773 to 0.47857, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3956 - categorical_accuracy: 0.7500
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.5186 - categorical_accuracy: 0.7606
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.5221 - categorical_accuracy: 0.7603
 4832/10000 [=============>................] - ETA: 0s - loss: 0.5157 - categorical_accuracy: 0.7645
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.5119 - categorical_accuracy: 0.7691
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.5084 - categorical_accuracy: 0.7694
 9632/10000 [===========================>..] - ETA: 0s - loss: 0.5120 - categorical_accuracy: 0.7672
10000/10000 [==============================] - 1s 50us/step - loss: 0.5126 - categorical_accuracy: 0.7670 - val_loss: 0.4785 - val_categorical_accuracy: 0.7833

Epoch 00003: val_loss improved from 0.47857 to 0.47847, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6610 - categorical_accuracy: 0.6875
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4900 - categorical_accuracy: 0.7763
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4900 - categorical_accuracy: 0.7794
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4971 - categorical_accuracy: 0.7762
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.5007 - categorical_accuracy: 0.7716
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.5035 - categorical_accuracy: 0.7701
 9632/10000 [===========================>..] - ETA: 0s - loss: 0.5046 - categorical_accuracy: 0.7702
10000/10000 [==============================] - 1s 51us/step - loss: 0.5045 - categorical_accuracy: 0.7714 - val_loss: 0.4833 - val_categorical_accuracy: 0.7862

Epoch 00004: val_loss did not improve from 0.47847
Epoch 5/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3480 - categorical_accuracy: 0.8438
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.5035 - categorical_accuracy: 0.7679
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.5064 - categorical_accuracy: 0.7723
 4800/10000 [=============>................] - ETA: 0s - loss: 0.5084 - categorical_accuracy: 0.7692
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.5093 - categorical_accuracy: 0.7690
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.5059 - categorical_accuracy: 0.7724
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.5028 - categorical_accuracy: 0.7736
10000/10000 [==============================] - 1s 50us/step - loss: 0.5017 - categorical_accuracy: 0.7749 - val_loss: 0.4689 - val_categorical_accuracy: 0.7852

Epoch 00005: val_loss improved from 0.47847 to 0.46894, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4657 - categorical_accuracy: 0.7188
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4922 - categorical_accuracy: 0.7725
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4891 - categorical_accuracy: 0.7787
 4768/10000 [=============>................] - ETA: 0s - loss: 0.5020 - categorical_accuracy: 0.7747
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.5009 - categorical_accuracy: 0.7759
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4986 - categorical_accuracy: 0.7753
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.4963 - categorical_accuracy: 0.7760
10000/10000 [==============================] - 1s 52us/step - loss: 0.4962 - categorical_accuracy: 0.7763 - val_loss: 0.4682 - val_categorical_accuracy: 0.7878

Epoch 00006: val_loss improved from 0.46894 to 0.46817, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5800 - categorical_accuracy: 0.7500
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4850 - categorical_accuracy: 0.7881
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4799 - categorical_accuracy: 0.7912
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4898 - categorical_accuracy: 0.7829
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4867 - categorical_accuracy: 0.7854
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.4915 - categorical_accuracy: 0.7822
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4904 - categorical_accuracy: 0.7818
10000/10000 [==============================] - 1s 50us/step - loss: 0.4913 - categorical_accuracy: 0.7813 - val_loss: 0.4643 - val_categorical_accuracy: 0.7882

Epoch 00007: val_loss improved from 0.46817 to 0.46428, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4543 - categorical_accuracy: 0.8125
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4851 - categorical_accuracy: 0.7757
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.7834
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4894 - categorical_accuracy: 0.7806
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4944 - categorical_accuracy: 0.7758
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4886 - categorical_accuracy: 0.7800
 9472/10000 [===========================>..] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.7801
10000/10000 [==============================] - 1s 51us/step - loss: 0.4884 - categorical_accuracy: 0.7816 - val_loss: 0.4602 - val_categorical_accuracy: 0.7893

Epoch 00008: val_loss improved from 0.46428 to 0.46018, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 9/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3474 - categorical_accuracy: 0.8438
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.5066 - categorical_accuracy: 0.7806
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.7859
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4898 - categorical_accuracy: 0.7884
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4889 - categorical_accuracy: 0.7864
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.4862 - categorical_accuracy: 0.7854
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.4886 - categorical_accuracy: 0.7830
10000/10000 [==============================] - 0s 50us/step - loss: 0.4885 - categorical_accuracy: 0.7828 - val_loss: 0.4645 - val_categorical_accuracy: 0.7890

Epoch 00009: val_loss did not improve from 0.46018
Epoch 10/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3781 - categorical_accuracy: 0.7812
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4946 - categorical_accuracy: 0.7788
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4947 - categorical_accuracy: 0.7822
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4963 - categorical_accuracy: 0.7810
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4893 - categorical_accuracy: 0.7870
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.7852
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.4841 - categorical_accuracy: 0.7857
10000/10000 [==============================] - 1s 51us/step - loss: 0.4836 - categorical_accuracy: 0.7863 - val_loss: 0.4571 - val_categorical_accuracy: 0.7894

Epoch 00010: val_loss improved from 0.46018 to 0.45705, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 11/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6883 - categorical_accuracy: 0.6562
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.5123 - categorical_accuracy: 0.7716
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.5086 - categorical_accuracy: 0.7742
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4983 - categorical_accuracy: 0.7812
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4884 - categorical_accuracy: 0.7809
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.4870 - categorical_accuracy: 0.7824
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4863 - categorical_accuracy: 0.7839
10000/10000 [==============================] - 1s 50us/step - loss: 0.4853 - categorical_accuracy: 0.7838 - val_loss: 0.4579 - val_categorical_accuracy: 0.7913

Epoch 00011: val_loss did not improve from 0.45705
Epoch 12/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5648 - categorical_accuracy: 0.7188
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4956 - categorical_accuracy: 0.7696
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4821 - categorical_accuracy: 0.7803
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4846 - categorical_accuracy: 0.7800
 6272/10000 [=================>............] - ETA: 0s - loss: 0.4841 - categorical_accuracy: 0.7859
 7712/10000 [======================>.......] - ETA: 0s - loss: 0.4846 - categorical_accuracy: 0.7859
 9248/10000 [==========================>...] - ETA: 0s - loss: 0.4835 - categorical_accuracy: 0.7859
10000/10000 [==============================] - 1s 52us/step - loss: 0.4835 - categorical_accuracy: 0.7858 - val_loss: 0.4581 - val_categorical_accuracy: 0.7921

Epoch 00012: val_loss did not improve from 0.45705
Epoch 13/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3538 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.7819
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.7889
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4769 - categorical_accuracy: 0.7856
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4813 - categorical_accuracy: 0.7857
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.7855
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.7849
10000/10000 [==============================] - 1s 51us/step - loss: 0.4803 - categorical_accuracy: 0.7856 - val_loss: 0.4575 - val_categorical_accuracy: 0.7915

Epoch 00013: val_loss did not improve from 0.45705
Epoch 14/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4395 - categorical_accuracy: 0.7812
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.7831
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4774 - categorical_accuracy: 0.7763
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.7817
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7842
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4767 - categorical_accuracy: 0.7833
 9472/10000 [===========================>..] - ETA: 0s - loss: 0.4791 - categorical_accuracy: 0.7835
10000/10000 [==============================] - 1s 51us/step - loss: 0.4793 - categorical_accuracy: 0.7848 - val_loss: 0.4578 - val_categorical_accuracy: 0.7924

Epoch 00014: val_loss did not improve from 0.45705
Epoch 15/50

   32/10000 [..............................] - ETA: 0s - loss: 0.2759 - categorical_accuracy: 0.9688
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4669 - categorical_accuracy: 0.7966
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4677 - categorical_accuracy: 0.7956
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.7930
 6336/10000 [==================>...........] - ETA: 0s - loss: 0.4719 - categorical_accuracy: 0.7918
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4723 - categorical_accuracy: 0.7912
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.7865
10000/10000 [==============================] - 1s 50us/step - loss: 0.4757 - categorical_accuracy: 0.7879 - val_loss: 0.4565 - val_categorical_accuracy: 0.7921

Epoch 00015: val_loss improved from 0.45705 to 0.45646, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 16/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5317 - categorical_accuracy: 0.7500
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4798 - categorical_accuracy: 0.7751
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.7884
 4800/10000 [=============>................] - ETA: 0s - loss: 0.4768 - categorical_accuracy: 0.7885
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.7889
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.4740 - categorical_accuracy: 0.7891
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7854
10000/10000 [==============================] - 1s 50us/step - loss: 0.4774 - categorical_accuracy: 0.7869 - val_loss: 0.4576 - val_categorical_accuracy: 0.7917

Epoch 00016: val_loss did not improve from 0.45646
Epoch 17/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4777 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4922 - categorical_accuracy: 0.7719
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4820 - categorical_accuracy: 0.7746
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.7846
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4739 - categorical_accuracy: 0.7839
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4723 - categorical_accuracy: 0.7851
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.7860
10000/10000 [==============================] - 1s 51us/step - loss: 0.4740 - categorical_accuracy: 0.7860 - val_loss: 0.4564 - val_categorical_accuracy: 0.7929

Epoch 00017: val_loss improved from 0.45646 to 0.45640, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 18/50

   32/10000 [..............................] - ETA: 1s - loss: 0.4039 - categorical_accuracy: 0.8438
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4574 - categorical_accuracy: 0.8002
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4757 - categorical_accuracy: 0.7812
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4746 - categorical_accuracy: 0.7815
 6336/10000 [==================>...........] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.7863
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4765 - categorical_accuracy: 0.7849
 9536/10000 [===========================>..] - ETA: 0s - loss: 0.4776 - categorical_accuracy: 0.7833
10000/10000 [==============================] - 1s 51us/step - loss: 0.4755 - categorical_accuracy: 0.7849 - val_loss: 0.4503 - val_categorical_accuracy: 0.7945

Epoch 00018: val_loss improved from 0.45640 to 0.45029, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 19/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5718 - categorical_accuracy: 0.6875
 1504/10000 [===>..........................] - ETA: 0s - loss: 0.4827 - categorical_accuracy: 0.7839
 2784/10000 [=======>......................] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7816
 3936/10000 [==========>...................] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.7901
 5344/10000 [===============>..............] - ETA: 0s - loss: 0.4766 - categorical_accuracy: 0.7869
 6976/10000 [===================>..........] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7887
 8512/10000 [========================>.....] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7876
10000/10000 [==============================] - 1s 54us/step - loss: 0.4736 - categorical_accuracy: 0.7891 - val_loss: 0.4500 - val_categorical_accuracy: 0.7937

Epoch 00019: val_loss improved from 0.45029 to 0.45000, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 20/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6655 - categorical_accuracy: 0.7188
 1472/10000 [===>..........................] - ETA: 0s - loss: 0.4902 - categorical_accuracy: 0.7731
 2912/10000 [=======>......................] - ETA: 0s - loss: 0.4828 - categorical_accuracy: 0.7867
 4320/10000 [===========>..................] - ETA: 0s - loss: 0.4778 - categorical_accuracy: 0.7882
 5792/10000 [================>.............] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.7847
 7264/10000 [====================>.........] - ETA: 0s - loss: 0.4738 - categorical_accuracy: 0.7865
 8736/10000 [=========================>....] - ETA: 0s - loss: 0.4740 - categorical_accuracy: 0.7869
10000/10000 [==============================] - 1s 54us/step - loss: 0.4736 - categorical_accuracy: 0.7866 - val_loss: 0.4527 - val_categorical_accuracy: 0.7937

Epoch 00020: val_loss did not improve from 0.45000
Epoch 21/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3966 - categorical_accuracy: 0.8750
 1536/10000 [===>..........................] - ETA: 0s - loss: 0.4911 - categorical_accuracy: 0.7819
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4809 - categorical_accuracy: 0.7812
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4798 - categorical_accuracy: 0.7844
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7895
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.4791 - categorical_accuracy: 0.7880
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4768 - categorical_accuracy: 0.7867
10000/10000 [==============================] - 1s 50us/step - loss: 0.4750 - categorical_accuracy: 0.7877 - val_loss: 0.4505 - val_categorical_accuracy: 0.7931

Epoch 00021: val_loss did not improve from 0.45000
Epoch 22/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5427 - categorical_accuracy: 0.7500
 1440/10000 [===>..........................] - ETA: 0s - loss: 0.4496 - categorical_accuracy: 0.8111
 3008/10000 [========>.....................] - ETA: 0s - loss: 0.4609 - categorical_accuracy: 0.7982
 4576/10000 [============>.................] - ETA: 0s - loss: 0.4643 - categorical_accuracy: 0.7961
 6208/10000 [=================>............] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.7925
 7744/10000 [======================>.......] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7904
 9408/10000 [===========================>..] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7923
10000/10000 [==============================] - 1s 51us/step - loss: 0.4703 - categorical_accuracy: 0.7907 - val_loss: 0.4503 - val_categorical_accuracy: 0.7936

Epoch 00022: val_loss did not improve from 0.45000
Epoch 23/50

   32/10000 [..............................] - ETA: 1s - loss: 0.5874 - categorical_accuracy: 0.7500
 1472/10000 [===>..........................] - ETA: 0s - loss: 0.4833 - categorical_accuracy: 0.7751
 3040/10000 [========>.....................] - ETA: 0s - loss: 0.4770 - categorical_accuracy: 0.7816
 4640/10000 [============>.................] - ETA: 0s - loss: 0.4750 - categorical_accuracy: 0.7873
 6208/10000 [=================>............] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7879
 7872/10000 [======================>.......] - ETA: 0s - loss: 0.4747 - categorical_accuracy: 0.7900
 9472/10000 [===========================>..] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7895
10000/10000 [==============================] - 1s 51us/step - loss: 0.4738 - categorical_accuracy: 0.7894 - val_loss: 0.4510 - val_categorical_accuracy: 0.7944

Epoch 00023: val_loss did not improve from 0.45000
Epoch 24/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3981 - categorical_accuracy: 0.8125
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4810 - categorical_accuracy: 0.7898
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.7861
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4777 - categorical_accuracy: 0.7854
 6528/10000 [==================>...........] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7884
 8064/10000 [=======================>......] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7886
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4740 - categorical_accuracy: 0.7894
10000/10000 [==============================] - 1s 50us/step - loss: 0.4727 - categorical_accuracy: 0.7901 - val_loss: 0.4503 - val_categorical_accuracy: 0.7936

Epoch 00024: val_loss did not improve from 0.45000
Epoch 25/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4860 - categorical_accuracy: 0.7763
 2912/10000 [=======>......................] - ETA: 0s - loss: 0.4725 - categorical_accuracy: 0.7878
 4544/10000 [============>.................] - ETA: 0s - loss: 0.4656 - categorical_accuracy: 0.7923
 6144/10000 [=================>............] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7922
 7776/10000 [======================>.......] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.7914
 9408/10000 [===========================>..] - ETA: 0s - loss: 0.4681 - categorical_accuracy: 0.7916
10000/10000 [==============================] - 1s 52us/step - loss: 0.4698 - categorical_accuracy: 0.7896 - val_loss: 0.4526 - val_categorical_accuracy: 0.7934

Epoch 00025: val_loss did not improve from 0.45000
Epoch 26/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3538 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7944
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4630 - categorical_accuracy: 0.7981
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7895
 6496/10000 [==================>...........] - ETA: 0s - loss: 0.4718 - categorical_accuracy: 0.7880
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7861
 9632/10000 [===========================>..] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7876
10000/10000 [==============================] - 1s 51us/step - loss: 0.4713 - categorical_accuracy: 0.7881 - val_loss: 0.4496 - val_categorical_accuracy: 0.7932

Epoch 00026: val_loss improved from 0.45000 to 0.44963, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 27/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3579 - categorical_accuracy: 0.9062
 1536/10000 [===>..........................] - ETA: 0s - loss: 0.4771 - categorical_accuracy: 0.8034
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4826 - categorical_accuracy: 0.7879
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4741 - categorical_accuracy: 0.7893
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4738 - categorical_accuracy: 0.7894
 7904/10000 [======================>.......] - ETA: 0s - loss: 0.4720 - categorical_accuracy: 0.7907
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7905
10000/10000 [==============================] - 1s 52us/step - loss: 0.4725 - categorical_accuracy: 0.7895 - val_loss: 0.4522 - val_categorical_accuracy: 0.7924

Epoch 00027: val_loss did not improve from 0.44963
Epoch 28/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4307 - categorical_accuracy: 0.8125
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4757 - categorical_accuracy: 0.7831
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4769 - categorical_accuracy: 0.7874
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7889
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.7891
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.7879
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4725 - categorical_accuracy: 0.7877
10000/10000 [==============================] - 1s 51us/step - loss: 0.4716 - categorical_accuracy: 0.7875 - val_loss: 0.4507 - val_categorical_accuracy: 0.7936

Epoch 00028: val_loss did not improve from 0.44963
Epoch 29/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6135 - categorical_accuracy: 0.6562
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4773 - categorical_accuracy: 0.7875
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4793 - categorical_accuracy: 0.7859
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4765 - categorical_accuracy: 0.7827
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4731 - categorical_accuracy: 0.7858
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.7884
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7892
10000/10000 [==============================] - 1s 51us/step - loss: 0.4694 - categorical_accuracy: 0.7895 - val_loss: 0.4497 - val_categorical_accuracy: 0.7943

Epoch 00029: val_loss did not improve from 0.44963
Epoch 30/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5098 - categorical_accuracy: 0.7812
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7874
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4529 - categorical_accuracy: 0.7994
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4562 - categorical_accuracy: 0.7975
 5888/10000 [================>.............] - ETA: 0s - loss: 0.4598 - categorical_accuracy: 0.7947
 7488/10000 [=====================>........] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7906
 9056/10000 [==========================>...] - ETA: 0s - loss: 0.4690 - categorical_accuracy: 0.7880
10000/10000 [==============================] - 1s 53us/step - loss: 0.4676 - categorical_accuracy: 0.7887 - val_loss: 0.4500 - val_categorical_accuracy: 0.7931

Epoch 00030: val_loss did not improve from 0.44963
Epoch 31/50

   32/10000 [..............................] - ETA: 0s - loss: 0.2544 - categorical_accuracy: 0.9688
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.7793
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4673 - categorical_accuracy: 0.7892
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4650 - categorical_accuracy: 0.7899
 6336/10000 [==================>...........] - ETA: 0s - loss: 0.4633 - categorical_accuracy: 0.7893
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4656 - categorical_accuracy: 0.7887
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4651 - categorical_accuracy: 0.7909
10000/10000 [==============================] - 1s 51us/step - loss: 0.4660 - categorical_accuracy: 0.7895 - val_loss: 0.4492 - val_categorical_accuracy: 0.7929

Epoch 00031: val_loss improved from 0.44963 to 0.44917, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 32/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4843 - categorical_accuracy: 0.7500
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4550 - categorical_accuracy: 0.7978
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4571 - categorical_accuracy: 0.8019
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4638 - categorical_accuracy: 0.8001
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4711 - categorical_accuracy: 0.7914
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4744 - categorical_accuracy: 0.7869
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4740 - categorical_accuracy: 0.7879
10000/10000 [==============================] - 1s 50us/step - loss: 0.4727 - categorical_accuracy: 0.7890 - val_loss: 0.4509 - val_categorical_accuracy: 0.7930

Epoch 00032: val_loss did not improve from 0.44917
Epoch 33/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5374 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4625 - categorical_accuracy: 0.7763
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4686 - categorical_accuracy: 0.7907
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4638 - categorical_accuracy: 0.7935
 6208/10000 [=================>............] - ETA: 0s - loss: 0.4700 - categorical_accuracy: 0.7890
 7840/10000 [======================>.......] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7911
 9408/10000 [===========================>..] - ETA: 0s - loss: 0.4702 - categorical_accuracy: 0.7889
10000/10000 [==============================] - 1s 51us/step - loss: 0.4715 - categorical_accuracy: 0.7873 - val_loss: 0.4527 - val_categorical_accuracy: 0.7935

Epoch 00033: val_loss did not improve from 0.44917
Epoch 34/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5794 - categorical_accuracy: 0.7500
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.7994
 3136/10000 [========>.....................] - ETA: 0s - loss: 0.4587 - categorical_accuracy: 0.7985
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.7986
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4640 - categorical_accuracy: 0.7944
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.7920
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.7925
10000/10000 [==============================] - 1s 50us/step - loss: 0.4690 - categorical_accuracy: 0.7915 - val_loss: 0.4513 - val_categorical_accuracy: 0.7942

Epoch 00034: val_loss did not improve from 0.44917
Epoch 35/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.8125
 1504/10000 [===>..........................] - ETA: 0s - loss: 0.4684 - categorical_accuracy: 0.7872
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4702 - categorical_accuracy: 0.7923
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7973
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4656 - categorical_accuracy: 0.7945
 7872/10000 [======================>.......] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.7910
 9408/10000 [===========================>..] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7882
10000/10000 [==============================] - 1s 51us/step - loss: 0.4688 - categorical_accuracy: 0.7884 - val_loss: 0.4482 - val_categorical_accuracy: 0.7937

Epoch 00035: val_loss improved from 0.44917 to 0.44819, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 36/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5753 - categorical_accuracy: 0.6562
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4465 - categorical_accuracy: 0.8062
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4549 - categorical_accuracy: 0.7942
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4639 - categorical_accuracy: 0.7889
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4654 - categorical_accuracy: 0.7891
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.4647 - categorical_accuracy: 0.7883
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7885
10000/10000 [==============================] - 1s 51us/step - loss: 0.4682 - categorical_accuracy: 0.7881 - val_loss: 0.4483 - val_categorical_accuracy: 0.7936

Epoch 00036: val_loss did not improve from 0.44819
Epoch 37/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4224 - categorical_accuracy: 0.8125
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4723 - categorical_accuracy: 0.7800
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4738 - categorical_accuracy: 0.7822
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7875
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7914
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4708 - categorical_accuracy: 0.7875
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4693 - categorical_accuracy: 0.7894
10000/10000 [==============================] - 1s 51us/step - loss: 0.4687 - categorical_accuracy: 0.7896 - val_loss: 0.4480 - val_categorical_accuracy: 0.7938

Epoch 00037: val_loss improved from 0.44819 to 0.44802, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 38/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4221 - categorical_accuracy: 0.8125
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4786 - categorical_accuracy: 0.7800
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4823 - categorical_accuracy: 0.7819
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4780 - categorical_accuracy: 0.7844
 6304/10000 [=================>............] - ETA: 0s - loss: 0.4769 - categorical_accuracy: 0.7857
 7904/10000 [======================>.......] - ETA: 0s - loss: 0.4719 - categorical_accuracy: 0.7896
 9504/10000 [===========================>..] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.7887
10000/10000 [==============================] - 1s 51us/step - loss: 0.4689 - categorical_accuracy: 0.7889 - val_loss: 0.4479 - val_categorical_accuracy: 0.7950

Epoch 00038: val_loss improved from 0.44802 to 0.44788, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 39/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5355 - categorical_accuracy: 0.7500
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4889 - categorical_accuracy: 0.7793
 3168/10000 [========>.....................] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7835
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4692 - categorical_accuracy: 0.7907
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7938
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.7929
 9440/10000 [===========================>..] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.7889
10000/10000 [==============================] - 1s 51us/step - loss: 0.4672 - categorical_accuracy: 0.7884 - val_loss: 0.4532 - val_categorical_accuracy: 0.7923

Epoch 00039: val_loss did not improve from 0.44788
Epoch 40/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3742 - categorical_accuracy: 0.8438
 1600/10000 [===>..........................] - ETA: 0s - loss: 0.4484 - categorical_accuracy: 0.7956
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.7869
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4637 - categorical_accuracy: 0.7910
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4660 - categorical_accuracy: 0.7900
 8000/10000 [=======================>......] - ETA: 0s - loss: 0.4676 - categorical_accuracy: 0.7903
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7889
10000/10000 [==============================] - 1s 51us/step - loss: 0.4690 - categorical_accuracy: 0.7872 - val_loss: 0.4482 - val_categorical_accuracy: 0.7941

Epoch 00040: val_loss did not improve from 0.44788
Epoch 41/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4836 - categorical_accuracy: 0.7500
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7873
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4740 - categorical_accuracy: 0.7791
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4691 - categorical_accuracy: 0.7859
 6240/10000 [=================>............] - ETA: 0s - loss: 0.4668 - categorical_accuracy: 0.7857
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7873
 9568/10000 [===========================>..] - ETA: 0s - loss: 0.4656 - categorical_accuracy: 0.7889
10000/10000 [==============================] - 1s 50us/step - loss: 0.4660 - categorical_accuracy: 0.7887 - val_loss: 0.4488 - val_categorical_accuracy: 0.7935

Epoch 00041: val_loss did not improve from 0.44788
Epoch 42/50

   32/10000 [..............................] - ETA: 0s - loss: 0.6787 - categorical_accuracy: 0.6875
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4607 - categorical_accuracy: 0.7984
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7890
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4644 - categorical_accuracy: 0.7928
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.7879
 8064/10000 [=======================>......] - ETA: 0s - loss: 0.4614 - categorical_accuracy: 0.7906
 9728/10000 [============================>.] - ETA: 0s - loss: 0.4659 - categorical_accuracy: 0.7888
10000/10000 [==============================] - 1s 51us/step - loss: 0.4652 - categorical_accuracy: 0.7888 - val_loss: 0.4500 - val_categorical_accuracy: 0.7951

Epoch 00042: val_loss did not improve from 0.44788
Epoch 43/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3846 - categorical_accuracy: 0.8750
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4572 - categorical_accuracy: 0.8021
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4655 - categorical_accuracy: 0.7941
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4633 - categorical_accuracy: 0.7938
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4624 - categorical_accuracy: 0.7945
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4655 - categorical_accuracy: 0.7908
 9632/10000 [===========================>..] - ETA: 0s - loss: 0.4656 - categorical_accuracy: 0.7908
10000/10000 [==============================] - 1s 51us/step - loss: 0.4665 - categorical_accuracy: 0.7910 - val_loss: 0.4487 - val_categorical_accuracy: 0.7944

Epoch 00043: val_loss did not improve from 0.44788
Epoch 44/50

   32/10000 [..............................] - ETA: 1s - loss: 0.4045 - categorical_accuracy: 0.7500
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.7921
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4599 - categorical_accuracy: 0.7896
 4832/10000 [=============>................] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7893
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4613 - categorical_accuracy: 0.7918
 8128/10000 [=======================>......] - ETA: 0s - loss: 0.4630 - categorical_accuracy: 0.7900
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.4643 - categorical_accuracy: 0.7893
10000/10000 [==============================] - 1s 51us/step - loss: 0.4641 - categorical_accuracy: 0.7894 - val_loss: 0.4501 - val_categorical_accuracy: 0.7945

Epoch 00044: val_loss did not improve from 0.44788
Epoch 45/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5700 - categorical_accuracy: 0.7500
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.7800
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4659 - categorical_accuracy: 0.7908
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4632 - categorical_accuracy: 0.7909
 6464/10000 [==================>...........] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7929
 7968/10000 [======================>.......] - ETA: 0s - loss: 0.4657 - categorical_accuracy: 0.7910
 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7920
10000/10000 [==============================] - 1s 50us/step - loss: 0.4643 - categorical_accuracy: 0.7913 - val_loss: 0.4488 - val_categorical_accuracy: 0.7946

Epoch 00045: val_loss did not improve from 0.44788
Epoch 46/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7188
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4900 - categorical_accuracy: 0.7794
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.7843
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4755 - categorical_accuracy: 0.7880
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4667 - categorical_accuracy: 0.7903
 8096/10000 [=======================>......] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.7904
 9664/10000 [===========================>..] - ETA: 0s - loss: 0.4668 - categorical_accuracy: 0.7887
10000/10000 [==============================] - 1s 50us/step - loss: 0.4657 - categorical_accuracy: 0.7895 - val_loss: 0.4504 - val_categorical_accuracy: 0.7949

Epoch 00046: val_loss did not improve from 0.44788
Epoch 47/50

   32/10000 [..............................] - ETA: 0s - loss: 0.5168 - categorical_accuracy: 0.6875
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4580 - categorical_accuracy: 0.7957
 3264/10000 [========>.....................] - ETA: 0s - loss: 0.4699 - categorical_accuracy: 0.7904
 4864/10000 [=============>................] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.7915
 6368/10000 [==================>...........] - ETA: 0s - loss: 0.4670 - categorical_accuracy: 0.7919
 7936/10000 [======================>.......] - ETA: 0s - loss: 0.4686 - categorical_accuracy: 0.7903
 9536/10000 [===========================>..] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7908
10000/10000 [==============================] - 1s 51us/step - loss: 0.4655 - categorical_accuracy: 0.7903 - val_loss: 0.4488 - val_categorical_accuracy: 0.7935

Epoch 00047: val_loss did not improve from 0.44788
Epoch 48/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4309 - categorical_accuracy: 0.8438
 1632/10000 [===>..........................] - ETA: 0s - loss: 0.4764 - categorical_accuracy: 0.7831
 3296/10000 [========>.....................] - ETA: 0s - loss: 0.4755 - categorical_accuracy: 0.7864
 4768/10000 [=============>................] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.7901
 6432/10000 [==================>...........] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7886
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.7906
 9632/10000 [===========================>..] - ETA: 0s - loss: 0.4690 - categorical_accuracy: 0.7901
10000/10000 [==============================] - 1s 50us/step - loss: 0.4696 - categorical_accuracy: 0.7901 - val_loss: 0.4508 - val_categorical_accuracy: 0.7942

Epoch 00048: val_loss did not improve from 0.44788
Epoch 49/50

   32/10000 [..............................] - ETA: 0s - loss: 0.4970 - categorical_accuracy: 0.7500
 1568/10000 [===>..........................] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.7921
 3200/10000 [========>.....................] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.7878
 4736/10000 [=============>................] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.7889
 6400/10000 [==================>...........] - ETA: 0s - loss: 0.4630 - categorical_accuracy: 0.7942
 8032/10000 [=======================>......] - ETA: 0s - loss: 0.4669 - categorical_accuracy: 0.7927
 9696/10000 [============================>.] - ETA: 0s - loss: 0.4687 - categorical_accuracy: 0.7907
10000/10000 [==============================] - 1s 51us/step - loss: 0.4673 - categorical_accuracy: 0.7920 - val_loss: 0.4509 - val_categorical_accuracy: 0.7933

Epoch 00049: val_loss did not improve from 0.44788
Epoch 50/50

   32/10000 [..............................] - ETA: 0s - loss: 0.3402 - categorical_accuracy: 0.9062
 1664/10000 [===>..........................] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.7806
 3232/10000 [========>.....................] - ETA: 0s - loss: 0.4738 - categorical_accuracy: 0.7837
 4896/10000 [=============>................] - ETA: 0s - loss: 0.4673 - categorical_accuracy: 0.7896
 6560/10000 [==================>...........] - ETA: 0s - loss: 0.4715 - categorical_accuracy: 0.7870
 8160/10000 [=======================>......] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.7880
 9824/10000 [============================>.] - ETA: 0s - loss: 0.4670 - categorical_accuracy: 0.7900
10000/10000 [==============================] - 1s 50us/step - loss: 0.4674 - categorical_accuracy: 0.7895 - val_loss: 0.4496 - val_categorical_accuracy: 0.7946

Epoch 00050: val_loss did not improve from 0.44788
                         : Elapsed time for training with 10000 events: [1;31m26.7 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 10000 events: [1;31m1.29 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.428e-01
                         :    2 : mfchi2     : 2.816e-01
                         :    3 : gm2e       : 8.728e-02
                         :    4 : gm2p3cms   : 1.688e-02
                         :    5 : gm1e925    : 1.478e-02
                         :    6 : gmthetacms : 1.297e-02
                         :    7 : gm2e925    : 1.264e-02
                         :    8 : pi0p3cms   : 1.001e-02
                         :    9 : gm1p3cms   : 7.372e-03
                         :   10 : gm1e       : 4.175e-03
                         :   11 : gm1eerror  : 3.741e-03
                         :   12 : ediff      : 3.244e-03
                         :   13 : gm2eerror  : 2.585e-03
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.032698     0.98528   [     -3.3185      5.7307 ]
                         :   pi0p3cms:    0.031525     0.98939   [     -3.1739      5.7307 ]
                         :       gm1e:    0.037156     0.99648   [     -3.1688      5.7307 ]
                         :       gm2e:    0.019090     0.98641   [     -3.0473      5.7307 ]
                         :    gm1e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :    gm2e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :      ediff:    0.037446      1.0010   [     -3.2146      5.7307 ]
                         :  gm1eerror:    0.037890     0.97969   [     -2.9310      5.7307 ]
                         :  gm2eerror:    0.016566     0.98404   [     -2.8571      5.7307 ]
                         :   gm1p3cms:    0.035527     0.99481   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.017945     0.99035   [     -3.0355      5.7307 ]
                         : gmthetacms:   -0.015994     0.98551   [     -2.9852      5.7307 ]
                         :     mfchi2:  -0.0031458     0.98859   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.032698     0.98528   [     -3.3185      5.7307 ]
                         :   pi0p3cms:    0.031525     0.98939   [     -3.1739      5.7307 ]
                         :       gm1e:    0.037156     0.99648   [     -3.1688      5.7307 ]
                         :       gm2e:    0.019090     0.98641   [     -3.0473      5.7307 ]
                         :    gm1e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :    gm2e925:     0.69382      2.1086   [     -3.4056      5.7307 ]
                         :      ediff:    0.037446      1.0010   [     -3.2146      5.7307 ]
                         :  gm1eerror:    0.037890     0.97969   [     -2.9310      5.7307 ]
                         :  gm2eerror:    0.016566     0.98404   [     -2.8571      5.7307 ]
                         :   gm1p3cms:    0.035527     0.99481   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.017945     0.99035   [     -3.0355      5.7307 ]
                         : gmthetacms:   -0.015994     0.98551   [     -2.9852      5.7307 ]
                         :     mfchi2:  -0.0031458     0.98859   [     -2.1938      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59786     0.55669   [   0.0049119      4.9404 ]
                         :   pi0p3cms:     0.75579     0.74589   [    0.011479      6.9727 ]
                         :       gm1e:     0.44434     0.42427   [    0.063063      4.8358 ]
                         :       gm2e:     0.18021     0.17182   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95208    0.062272   [     0.22900      1.0000 ]
                         :    gm2e925:     0.95208    0.062272   [     0.22900      1.0000 ]
                         :      ediff:     0.26413     0.35410   [  1.2249e-05      4.7205 ]
                         :  gm1eerror:  0.00013800  0.00032775   [  2.1524e-06   0.0088087 ]
                         :  gm2eerror:  2.5697e-05  6.6469e-05   [  1.7209e-06   0.0013470 ]
                         :   gm1p3cms:     0.55537     0.57310   [    0.048464      6.8307 ]
                         :   gm2p3cms:     0.22241     0.22897   [    0.043817      2.6974 ]
                         : gmthetacms:     0.72740     0.52235   [    0.044029      3.0902 ]
                         :     mfchi2:      8.7758      11.427   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       PyKeras        : 0.873
                         : dataset       GTB            : 0.871
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              PyKeras        : 0.245 (0.263)       0.659 (0.666)      0.861 (0.866)
                         : dataset              GTB            : 0.227 (0.337)       0.656 (0.686)      0.855 (0.867)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 10000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 10000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
