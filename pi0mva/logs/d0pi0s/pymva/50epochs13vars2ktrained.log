DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : [1mTrain all methods[0m
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 2000
                         : Signal     -- testing events             : 2000
                         : Signal     -- training and testing events: 4000
                         : Background -- training events            : 2000
                         : Background -- testing events             : 2000
                         : Background -- training and testing events: 4000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.974  +0.956  +0.746  -0.173  -0.173  +0.733    +0.822    +0.633   +0.936   +0.752     -0.682  -0.203
                         :   pi0p3cms:  +0.974   +1.000  +0.934  +0.724  -0.160  -0.160  +0.718    +0.826    +0.631   +0.962   +0.771     -0.669  -0.183
                         :       gm1e:  +0.956   +0.934  +1.000  +0.520  -0.111  -0.111  +0.900    +0.884    +0.438   +0.976   +0.538     -0.615  -0.182
                         :       gm2e:  +0.746   +0.724  +0.520  +1.000  -0.259  -0.259  +0.095    +0.402    +0.862   +0.517   +0.977     -0.558  -0.191
                         :    gm1e925:  -0.173   -0.160  -0.111  -0.259  +1.000  +1.000  +0.004    -0.082    -0.282   -0.104   -0.242     +0.063  -0.026
                         :    gm2e925:  -0.173   -0.160  -0.111  -0.259  +1.000  +1.000  +0.004    -0.082    -0.282   -0.104   -0.242     +0.063  -0.026
                         :      ediff:  +0.733   +0.718  +0.900  +0.095  +0.004  +0.004  +1.000    +0.825    +0.070   +0.873   +0.128     -0.431  -0.115
                         :  gm1eerror:  +0.822   +0.826  +0.884  +0.402  -0.082  -0.082  +0.825    +1.000    +0.372   +0.885   +0.432     -0.408  -0.130
                         :  gm2eerror:  +0.633   +0.631  +0.438  +0.862  -0.282  -0.282  +0.070    +0.372    +1.000   +0.447   +0.863     -0.379  -0.138
                         :   gm1p3cms:  +0.936   +0.962  +0.976  +0.517  -0.104  -0.104  +0.873    +0.885    +0.447   +1.000   +0.568     -0.610  -0.167
                         :   gm2p3cms:  +0.752   +0.771  +0.538  +0.977  -0.242  -0.242  +0.128    +0.432    +0.863   +0.568   +1.000     -0.565  -0.176
                         : gmthetacms:  -0.682   -0.669  -0.615  -0.558  +0.063  +0.063  -0.431    -0.408    -0.379   -0.610   -0.565     +1.000  +0.202
                         :     mfchi2:  -0.203   -0.183  -0.182  -0.191  -0.026  -0.026  -0.115    -0.130    -0.138   -0.167   -0.176     +0.202  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.975  +0.968  +0.623  -0.072  -0.072  +0.864    +0.786    +0.546   +0.951   +0.625     -0.718  -0.149
                         :   pi0p3cms:  +0.975   +1.000  +0.945  +0.610  -0.069  -0.069  +0.842    +0.794    +0.552   +0.971   +0.656     -0.728  -0.136
                         :       gm1e:  +0.968   +0.945  +1.000  +0.426  -0.065  -0.065  +0.960    +0.838    +0.375   +0.978   +0.440     -0.617  -0.139
                         :       gm2e:  +0.623   +0.610  +0.426  +1.000  -0.064  -0.064  +0.154    +0.321    +0.894   +0.429   +0.958     -0.558  -0.151
                         :    gm1e925:  -0.072   -0.069  -0.065  -0.064  +1.000  +1.000  -0.051    -0.035    -0.082   -0.062   -0.059     +0.044  -0.036
                         :    gm2e925:  -0.072   -0.069  -0.065  -0.064  +1.000  +1.000  -0.051    -0.035    -0.082   -0.062   -0.059     +0.044  -0.036
                         :      ediff:  +0.864   +0.842  +0.960  +0.154  -0.051  -0.051  +1.000    +0.815    +0.131   +0.935   +0.182     -0.501  -0.105
                         :  gm1eerror:  +0.786   +0.794  +0.838  +0.321  -0.035  -0.035  +0.815    +1.000    +0.300   +0.841   +0.350     -0.370  -0.110
                         :  gm2eerror:  +0.546   +0.552  +0.375  +0.894  -0.082  -0.082  +0.131    +0.300    +1.000   +0.390   +0.880     -0.416  -0.145
                         :   gm1p3cms:  +0.951   +0.971  +0.978  +0.429  -0.062  -0.062  +0.935    +0.841    +0.390   +1.000   +0.470     -0.634  -0.128
                         :   gm2p3cms:  +0.625   +0.656  +0.440  +0.958  -0.059  -0.059  +0.182    +0.350    +0.880   +0.470   +1.000     -0.600  -0.140
                         : gmthetacms:  -0.718   -0.728  -0.617  -0.558  +0.044  +0.044  -0.501    -0.370    -0.416   -0.634   -0.600     +1.000  +0.099
                         :     mfchi2:  -0.149   -0.136  -0.139  -0.151  -0.036  -0.036  -0.105    -0.110    -0.145   -0.128   -0.140     +0.099  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.014495     0.99997   [     -2.9073      5.7307 ]
                         :   pi0p3cms:    0.013369     0.99473   [     -2.9075      5.7307 ]
                         :       gm1e:    0.014956      1.0006   [     -2.9040      5.7307 ]
                         :       gm2e:    0.014585      1.0005   [     -2.8241      5.7307 ]
                         :    gm1e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :    gm2e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :      ediff:    0.015802      1.0064   [     -2.8487      5.7307 ]
                         :  gm1eerror:    0.015391     0.99881   [     -2.6322      5.7307 ]
                         :  gm2eerror:    0.015433     0.99816   [     -2.6476      5.7307 ]
                         :   gm1p3cms:    0.014257     0.99872   [     -2.9037      5.7307 ]
                         :   gm2p3cms:    0.015246      1.0039   [     -2.8759      5.7307 ]
                         : gmthetacms:    0.014290     0.99812   [     -2.9066      5.7307 ]
                         :     mfchi2:    0.022081      1.0067   [     -2.1005      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 3.024e-01
                         :    2 : gmthetacms : 2.691e-01
                         :    3 : gm1e       : 2.638e-01
                         :    4 : pi0p3cms   : 2.571e-01
                         :    5 : gm2e       : 2.491e-01
                         :    6 : gm1eerror  : 2.433e-01
                         :    7 : mfchi2     : 2.381e-01
                         :    8 : gm2eerror  : 2.322e-01
                         :    9 : gm1p3cms   : 2.306e-01
                         :   10 : gm2p3cms   : 2.091e-01
                         :   11 : ediff      : 1.375e-01
                         :   12 : gm1e925    : 8.971e-02
                         :   13 : gm2e925    : 8.971e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.014495     0.99997   [     -2.9073      5.7307 ]
                         :   pi0p3cms:    0.013369     0.99473   [     -2.9075      5.7307 ]
                         :       gm1e:    0.014956      1.0006   [     -2.9040      5.7307 ]
                         :       gm2e:    0.014585      1.0005   [     -2.8241      5.7307 ]
                         :    gm1e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :    gm2e925:     0.68292      2.0066   [     -2.8680      5.4200 ]
                         :      ediff:    0.015802      1.0064   [     -2.8487      5.7307 ]
                         :  gm1eerror:    0.015391     0.99881   [     -2.6322      5.7307 ]
                         :  gm2eerror:    0.015433     0.99816   [     -2.6476      5.7307 ]
                         :   gm1p3cms:    0.014257     0.99872   [     -2.9037      5.7307 ]
                         :   gm2p3cms:    0.015246      1.0039   [     -2.8759      5.7307 ]
                         : gmthetacms:    0.014290     0.99812   [     -2.9066      5.7307 ]
                         :     mfchi2:    0.022081      1.0067   [     -2.1005      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 4000 samples, validate on 4000 samples
Epoch 1/50

  32/4000 [..............................] - ETA: 22s - loss: 1.3793 - categorical_accuracy: 0.4062
1344/4000 [=========>....................] - ETA: 0s - loss: 0.8143 - categorical_accuracy: 0.5551 
2784/4000 [===================>..........] - ETA: 0s - loss: 0.7260 - categorical_accuracy: 0.6106
4000/4000 [==============================] - 0s 117us/step - loss: 0.6855 - categorical_accuracy: 0.6370 - val_loss: 0.5047 - val_categorical_accuracy: 0.7582

Epoch 00001: val_loss improved from inf to 0.50471, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5822 - categorical_accuracy: 0.6250
1440/4000 [=========>....................] - ETA: 0s - loss: 0.5505 - categorical_accuracy: 0.7361
2816/4000 [====================>.........] - ETA: 0s - loss: 0.5500 - categorical_accuracy: 0.7372
4000/4000 [==============================] - 0s 59us/step - loss: 0.5516 - categorical_accuracy: 0.7308 - val_loss: 0.4897 - val_categorical_accuracy: 0.7742

Epoch 00002: val_loss improved from 0.50471 to 0.48970, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5300 - categorical_accuracy: 0.7188
1344/4000 [=========>....................] - ETA: 0s - loss: 0.5345 - categorical_accuracy: 0.7522
2592/4000 [==================>...........] - ETA: 0s - loss: 0.5264 - categorical_accuracy: 0.7446
3744/4000 [===========================>..] - ETA: 0s - loss: 0.5295 - categorical_accuracy: 0.7457
4000/4000 [==============================] - 0s 64us/step - loss: 0.5293 - categorical_accuracy: 0.7452 - val_loss: 0.4821 - val_categorical_accuracy: 0.7755

Epoch 00003: val_loss improved from 0.48970 to 0.48211, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5361 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.5340 - categorical_accuracy: 0.7631
2656/4000 [==================>...........] - ETA: 0s - loss: 0.5175 - categorical_accuracy: 0.7684
3872/4000 [============================>.] - ETA: 0s - loss: 0.5173 - categorical_accuracy: 0.7696
4000/4000 [==============================] - 0s 64us/step - loss: 0.5173 - categorical_accuracy: 0.7673 - val_loss: 0.4767 - val_categorical_accuracy: 0.7788

Epoch 00004: val_loss improved from 0.48211 to 0.47667, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4562 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.5156 - categorical_accuracy: 0.7565
2688/4000 [===================>..........] - ETA: 0s - loss: 0.5147 - categorical_accuracy: 0.7560
3808/4000 [===========================>..] - ETA: 0s - loss: 0.5082 - categorical_accuracy: 0.7647
4000/4000 [==============================] - 0s 62us/step - loss: 0.5078 - categorical_accuracy: 0.7645 - val_loss: 0.4729 - val_categorical_accuracy: 0.7795

Epoch 00005: val_loss improved from 0.47667 to 0.47290, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 6/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3951 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.5228 - categorical_accuracy: 0.7616
2592/4000 [==================>...........] - ETA: 0s - loss: 0.5158 - categorical_accuracy: 0.7701
3648/4000 [==========================>...] - ETA: 0s - loss: 0.5148 - categorical_accuracy: 0.7686
4000/4000 [==============================] - 0s 64us/step - loss: 0.5125 - categorical_accuracy: 0.7685 - val_loss: 0.4716 - val_categorical_accuracy: 0.7825

Epoch 00006: val_loss improved from 0.47290 to 0.47162, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5195 - categorical_accuracy: 0.6875
1440/4000 [=========>....................] - ETA: 0s - loss: 0.4935 - categorical_accuracy: 0.7722
2816/4000 [====================>.........] - ETA: 0s - loss: 0.4924 - categorical_accuracy: 0.7695
3936/4000 [============================>.] - ETA: 0s - loss: 0.4990 - categorical_accuracy: 0.7734
4000/4000 [==============================] - 0s 62us/step - loss: 0.5006 - categorical_accuracy: 0.7730 - val_loss: 0.4684 - val_categorical_accuracy: 0.7857

Epoch 00007: val_loss improved from 0.47162 to 0.46837, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5076 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.5131 - categorical_accuracy: 0.7621
2720/4000 [===================>..........] - ETA: 0s - loss: 0.5039 - categorical_accuracy: 0.7801
3936/4000 [============================>.] - ETA: 0s - loss: 0.4966 - categorical_accuracy: 0.7800
4000/4000 [==============================] - 0s 60us/step - loss: 0.4990 - categorical_accuracy: 0.7785 - val_loss: 0.4653 - val_categorical_accuracy: 0.7860

Epoch 00008: val_loss improved from 0.46837 to 0.46528, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 9/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5350 - categorical_accuracy: 0.7812
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.7827
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4845 - categorical_accuracy: 0.7848
4000/4000 [==============================] - 0s 59us/step - loss: 0.4942 - categorical_accuracy: 0.7768 - val_loss: 0.4663 - val_categorical_accuracy: 0.7875

Epoch 00009: val_loss did not improve from 0.46528
Epoch 10/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3830 - categorical_accuracy: 0.8438
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7943
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4977 - categorical_accuracy: 0.7841
4000/4000 [==============================] - 0s 63us/step - loss: 0.4958 - categorical_accuracy: 0.7825 - val_loss: 0.4662 - val_categorical_accuracy: 0.7847

Epoch 00010: val_loss did not improve from 0.46528
Epoch 11/50

  32/4000 [..............................] - ETA: 0s - loss: 0.2846 - categorical_accuracy: 0.9062
1216/4000 [========>.....................] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7903
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4784 - categorical_accuracy: 0.7899
3968/4000 [============================>.] - ETA: 0s - loss: 0.4857 - categorical_accuracy: 0.7820
4000/4000 [==============================] - 0s 63us/step - loss: 0.4863 - categorical_accuracy: 0.7820 - val_loss: 0.4661 - val_categorical_accuracy: 0.7847

Epoch 00011: val_loss did not improve from 0.46528
Epoch 12/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4278 - categorical_accuracy: 0.8438
1120/4000 [=======>......................] - ETA: 0s - loss: 0.4863 - categorical_accuracy: 0.7705
2496/4000 [=================>............] - ETA: 0s - loss: 0.4907 - categorical_accuracy: 0.7696
3712/4000 [==========================>...] - ETA: 0s - loss: 0.4909 - categorical_accuracy: 0.7742
4000/4000 [==============================] - 0s 64us/step - loss: 0.4881 - categorical_accuracy: 0.7747 - val_loss: 0.4625 - val_categorical_accuracy: 0.7865

Epoch 00012: val_loss improved from 0.46528 to 0.46250, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 13/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4101 - categorical_accuracy: 0.7812
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4820 - categorical_accuracy: 0.7871
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4902 - categorical_accuracy: 0.7801
4000/4000 [==============================] - 0s 62us/step - loss: 0.4906 - categorical_accuracy: 0.7778 - val_loss: 0.4601 - val_categorical_accuracy: 0.7870

Epoch 00013: val_loss improved from 0.46250 to 0.46005, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 14/50

  32/4000 [..............................] - ETA: 0s - loss: 0.6137 - categorical_accuracy: 0.7188
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4967 - categorical_accuracy: 0.7718
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4950 - categorical_accuracy: 0.7732
4000/4000 [==============================] - 0s 66us/step - loss: 0.4928 - categorical_accuracy: 0.7778 - val_loss: 0.4643 - val_categorical_accuracy: 0.7855

Epoch 00014: val_loss did not improve from 0.46005
Epoch 15/50

  32/4000 [..............................] - ETA: 0s - loss: 0.7998 - categorical_accuracy: 0.5625
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4955 - categorical_accuracy: 0.7884
2848/4000 [====================>.........] - ETA: 0s - loss: 0.4862 - categorical_accuracy: 0.7890
4000/4000 [==============================] - 0s 62us/step - loss: 0.4861 - categorical_accuracy: 0.7840 - val_loss: 0.4629 - val_categorical_accuracy: 0.7857

Epoch 00015: val_loss did not improve from 0.46005
Epoch 16/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5501 - categorical_accuracy: 0.7500
1440/4000 [=========>....................] - ETA: 0s - loss: 0.5052 - categorical_accuracy: 0.7674
2848/4000 [====================>.........] - ETA: 0s - loss: 0.4982 - categorical_accuracy: 0.7749
4000/4000 [==============================] - 0s 69us/step - loss: 0.4889 - categorical_accuracy: 0.7803 - val_loss: 0.4580 - val_categorical_accuracy: 0.7875

Epoch 00016: val_loss improved from 0.46005 to 0.45802, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 17/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5496 - categorical_accuracy: 0.8438
1440/4000 [=========>....................] - ETA: 0s - loss: 0.4695 - categorical_accuracy: 0.7799
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4769 - categorical_accuracy: 0.7795
4000/4000 [==============================] - 0s 62us/step - loss: 0.4783 - categorical_accuracy: 0.7765 - val_loss: 0.4579 - val_categorical_accuracy: 0.7887

Epoch 00017: val_loss improved from 0.45802 to 0.45789, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 18/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4060 - categorical_accuracy: 0.8438
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4999 - categorical_accuracy: 0.7790
2528/4000 [=================>............] - ETA: 0s - loss: 0.4967 - categorical_accuracy: 0.7793
3840/4000 [===========================>..] - ETA: 0s - loss: 0.4924 - categorical_accuracy: 0.7831
4000/4000 [==============================] - 0s 66us/step - loss: 0.4895 - categorical_accuracy: 0.7820 - val_loss: 0.4579 - val_categorical_accuracy: 0.7880

Epoch 00018: val_loss did not improve from 0.45789
Epoch 19/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3695 - categorical_accuracy: 0.8750
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4596 - categorical_accuracy: 0.8011
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4716 - categorical_accuracy: 0.7903
4000/4000 [==============================] - 0s 66us/step - loss: 0.4835 - categorical_accuracy: 0.7803 - val_loss: 0.4617 - val_categorical_accuracy: 0.7853

Epoch 00019: val_loss did not improve from 0.45789
Epoch 20/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5698 - categorical_accuracy: 0.6875
 800/4000 [=====>........................] - ETA: 0s - loss: 0.4628 - categorical_accuracy: 0.8100
1824/4000 [============>.................] - ETA: 0s - loss: 0.4824 - categorical_accuracy: 0.7867
3008/4000 [=====================>........] - ETA: 0s - loss: 0.4855 - categorical_accuracy: 0.7839
4000/4000 [==============================] - 0s 76us/step - loss: 0.4823 - categorical_accuracy: 0.7885 - val_loss: 0.4596 - val_categorical_accuracy: 0.7875

Epoch 00020: val_loss did not improve from 0.45789
Epoch 21/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4185 - categorical_accuracy: 0.7812
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4835 - categorical_accuracy: 0.7917
2496/4000 [=================>............] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7917
3712/4000 [==========================>...] - ETA: 0s - loss: 0.4750 - categorical_accuracy: 0.7874
4000/4000 [==============================] - 0s 67us/step - loss: 0.4778 - categorical_accuracy: 0.7870 - val_loss: 0.4589 - val_categorical_accuracy: 0.7868

Epoch 00021: val_loss did not improve from 0.45789
Epoch 22/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5166 - categorical_accuracy: 0.8438
1088/4000 [=======>......................] - ETA: 0s - loss: 0.4906 - categorical_accuracy: 0.7877
2464/4000 [=================>............] - ETA: 0s - loss: 0.4894 - categorical_accuracy: 0.7739
3872/4000 [============================>.] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7831
4000/4000 [==============================] - 0s 64us/step - loss: 0.4785 - categorical_accuracy: 0.7840 - val_loss: 0.4557 - val_categorical_accuracy: 0.7903

Epoch 00022: val_loss improved from 0.45789 to 0.45569, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 23/50

  32/4000 [..............................] - ETA: 0s - loss: 0.6406 - categorical_accuracy: 0.6875
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4806 - categorical_accuracy: 0.7945
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7884
3904/4000 [============================>.] - ETA: 0s - loss: 0.4784 - categorical_accuracy: 0.7887
4000/4000 [==============================] - 0s 62us/step - loss: 0.4783 - categorical_accuracy: 0.7885 - val_loss: 0.4552 - val_categorical_accuracy: 0.7915

Epoch 00023: val_loss improved from 0.45569 to 0.45516, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 24/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4400 - categorical_accuracy: 0.7500
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4810 - categorical_accuracy: 0.7756
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.7766
3904/4000 [============================>.] - ETA: 0s - loss: 0.4736 - categorical_accuracy: 0.7838
4000/4000 [==============================] - 0s 61us/step - loss: 0.4733 - categorical_accuracy: 0.7837 - val_loss: 0.4561 - val_categorical_accuracy: 0.7885

Epoch 00024: val_loss did not improve from 0.45516
Epoch 25/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4730 - categorical_accuracy: 0.8438
1312/4000 [========>.....................] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.7858
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4780 - categorical_accuracy: 0.7904
3904/4000 [============================>.] - ETA: 0s - loss: 0.4785 - categorical_accuracy: 0.7879
4000/4000 [==============================] - 0s 66us/step - loss: 0.4791 - categorical_accuracy: 0.7878 - val_loss: 0.4583 - val_categorical_accuracy: 0.7870

Epoch 00025: val_loss did not improve from 0.45516
Epoch 26/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4482 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4890 - categorical_accuracy: 0.7682
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4822 - categorical_accuracy: 0.7751
4000/4000 [==============================] - 0s 63us/step - loss: 0.4779 - categorical_accuracy: 0.7800 - val_loss: 0.4530 - val_categorical_accuracy: 0.7890

Epoch 00026: val_loss improved from 0.45516 to 0.45302, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 27/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5014 - categorical_accuracy: 0.7500
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.7812
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4683 - categorical_accuracy: 0.7863
4000/4000 [==============================] - 0s 62us/step - loss: 0.4693 - categorical_accuracy: 0.7843 - val_loss: 0.4554 - val_categorical_accuracy: 0.7893

Epoch 00027: val_loss did not improve from 0.45302
Epoch 28/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5343 - categorical_accuracy: 0.7500
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.7869
2816/4000 [====================>.........] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.7852
4000/4000 [==============================] - 0s 62us/step - loss: 0.4796 - categorical_accuracy: 0.7830 - val_loss: 0.4559 - val_categorical_accuracy: 0.7900

Epoch 00028: val_loss did not improve from 0.45302
Epoch 29/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5294 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.7834
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4794 - categorical_accuracy: 0.7860
4000/4000 [==============================] - 0s 62us/step - loss: 0.4745 - categorical_accuracy: 0.7905 - val_loss: 0.4531 - val_categorical_accuracy: 0.7908

Epoch 00029: val_loss did not improve from 0.45302
Epoch 30/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3575 - categorical_accuracy: 0.9375
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4678 - categorical_accuracy: 0.7906
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4664 - categorical_accuracy: 0.7963
3872/4000 [============================>.] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.7955
4000/4000 [==============================] - 0s 65us/step - loss: 0.4667 - categorical_accuracy: 0.7958 - val_loss: 0.4511 - val_categorical_accuracy: 0.7908

Epoch 00030: val_loss improved from 0.45302 to 0.45111, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 31/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4358 - categorical_accuracy: 0.8125
1440/4000 [=========>....................] - ETA: 0s - loss: 0.4429 - categorical_accuracy: 0.8194
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4564 - categorical_accuracy: 0.8027
4000/4000 [==============================] - 0s 63us/step - loss: 0.4741 - categorical_accuracy: 0.7875 - val_loss: 0.4564 - val_categorical_accuracy: 0.7928

Epoch 00031: val_loss did not improve from 0.45111
Epoch 32/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4586 - categorical_accuracy: 0.7500
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4755 - categorical_accuracy: 0.7856
2688/4000 [===================>..........] - ETA: 0s - loss: 0.4815 - categorical_accuracy: 0.7853
4000/4000 [==============================] - 0s 63us/step - loss: 0.4758 - categorical_accuracy: 0.7890 - val_loss: 0.4506 - val_categorical_accuracy: 0.7930

Epoch 00032: val_loss improved from 0.45111 to 0.45061, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 33/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3783 - categorical_accuracy: 0.8125
1472/4000 [==========>...................] - ETA: 0s - loss: 0.4871 - categorical_accuracy: 0.7833
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4783 - categorical_accuracy: 0.7830
4000/4000 [==============================] - 0s 62us/step - loss: 0.4737 - categorical_accuracy: 0.7845 - val_loss: 0.4551 - val_categorical_accuracy: 0.7910

Epoch 00033: val_loss did not improve from 0.45061
Epoch 34/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4232 - categorical_accuracy: 0.7812
 896/4000 [=====>........................] - ETA: 0s - loss: 0.4879 - categorical_accuracy: 0.7690
1824/4000 [============>.................] - ETA: 0s - loss: 0.4762 - categorical_accuracy: 0.7851
2880/4000 [====================>.........] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7861
4000/4000 [==============================] - 0s 76us/step - loss: 0.4735 - categorical_accuracy: 0.7905 - val_loss: 0.4516 - val_categorical_accuracy: 0.7918

Epoch 00034: val_loss did not improve from 0.45061
Epoch 35/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5722 - categorical_accuracy: 0.7500
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7853
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.7832
3936/4000 [============================>.] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.7840
4000/4000 [==============================] - 0s 63us/step - loss: 0.4789 - categorical_accuracy: 0.7855 - val_loss: 0.4536 - val_categorical_accuracy: 0.7897

Epoch 00035: val_loss did not improve from 0.45061
Epoch 36/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4556 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4686 - categorical_accuracy: 0.7834
2752/4000 [===================>..........] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.7892
4000/4000 [==============================] - 0s 60us/step - loss: 0.4736 - categorical_accuracy: 0.7872 - val_loss: 0.4533 - val_categorical_accuracy: 0.7895

Epoch 00036: val_loss did not improve from 0.45061
Epoch 37/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.8438
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4510 - categorical_accuracy: 0.7947
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4655 - categorical_accuracy: 0.7901
4000/4000 [==============================] - 0s 63us/step - loss: 0.4664 - categorical_accuracy: 0.7908 - val_loss: 0.4515 - val_categorical_accuracy: 0.7930

Epoch 00037: val_loss did not improve from 0.45061
Epoch 38/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4604 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4537 - categorical_accuracy: 0.7980
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.7845
4000/4000 [==============================] - 0s 61us/step - loss: 0.4697 - categorical_accuracy: 0.7885 - val_loss: 0.4486 - val_categorical_accuracy: 0.7912

Epoch 00038: val_loss improved from 0.45061 to 0.44855, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 39/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5899 - categorical_accuracy: 0.5938
1344/4000 [=========>....................] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.7738
2784/4000 [===================>..........] - ETA: 0s - loss: 0.4650 - categorical_accuracy: 0.7848
4000/4000 [==============================] - 0s 60us/step - loss: 0.4733 - categorical_accuracy: 0.7828 - val_loss: 0.4528 - val_categorical_accuracy: 0.7933

Epoch 00039: val_loss did not improve from 0.44855
Epoch 40/50

  32/4000 [..............................] - ETA: 0s - loss: 0.7886 - categorical_accuracy: 0.6562
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.7724
2624/4000 [==================>...........] - ETA: 0s - loss: 0.4766 - categorical_accuracy: 0.7832
3936/4000 [============================>.] - ETA: 0s - loss: 0.4733 - categorical_accuracy: 0.7861
4000/4000 [==============================] - 0s 62us/step - loss: 0.4726 - categorical_accuracy: 0.7862 - val_loss: 0.4507 - val_categorical_accuracy: 0.7937

Epoch 00040: val_loss did not improve from 0.44855
Epoch 41/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3704 - categorical_accuracy: 0.8750
 960/4000 [======>.......................] - ETA: 0s - loss: 0.4657 - categorical_accuracy: 0.7771
2272/4000 [================>.............] - ETA: 0s - loss: 0.4654 - categorical_accuracy: 0.7931
3616/4000 [==========================>...] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7904
4000/4000 [==============================] - 0s 67us/step - loss: 0.4683 - categorical_accuracy: 0.7890 - val_loss: 0.4490 - val_categorical_accuracy: 0.7947

Epoch 00041: val_loss did not improve from 0.44855
Epoch 42/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3113 - categorical_accuracy: 0.8750
 960/4000 [======>.......................] - ETA: 0s - loss: 0.4513 - categorical_accuracy: 0.7948
2368/4000 [================>.............] - ETA: 0s - loss: 0.4709 - categorical_accuracy: 0.7851
3808/4000 [===========================>..] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.7849
4000/4000 [==============================] - 0s 63us/step - loss: 0.4743 - categorical_accuracy: 0.7843 - val_loss: 0.4512 - val_categorical_accuracy: 0.7937

Epoch 00042: val_loss did not improve from 0.44855
Epoch 43/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4778 - categorical_accuracy: 0.8125
1024/4000 [======>.......................] - ETA: 0s - loss: 0.4617 - categorical_accuracy: 0.8008
2368/4000 [================>.............] - ETA: 0s - loss: 0.4626 - categorical_accuracy: 0.7931
3712/4000 [==========================>...] - ETA: 0s - loss: 0.4687 - categorical_accuracy: 0.7896
4000/4000 [==============================] - 0s 65us/step - loss: 0.4727 - categorical_accuracy: 0.7880 - val_loss: 0.4533 - val_categorical_accuracy: 0.7903

Epoch 00043: val_loss did not improve from 0.44855
Epoch 44/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5419 - categorical_accuracy: 0.7188
 928/4000 [=====>........................] - ETA: 0s - loss: 0.4931 - categorical_accuracy: 0.7834
2112/4000 [==============>...............] - ETA: 0s - loss: 0.4797 - categorical_accuracy: 0.7884
3328/4000 [=======================>......] - ETA: 0s - loss: 0.4725 - categorical_accuracy: 0.7924
4000/4000 [==============================] - 0s 72us/step - loss: 0.4721 - categorical_accuracy: 0.7922 - val_loss: 0.4483 - val_categorical_accuracy: 0.7928

Epoch 00044: val_loss improved from 0.44855 to 0.44829, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 45/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4871 - categorical_accuracy: 0.8125
1408/4000 [=========>....................] - ETA: 0s - loss: 0.4607 - categorical_accuracy: 0.7969
2848/4000 [====================>.........] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.7911
4000/4000 [==============================] - 0s 60us/step - loss: 0.4677 - categorical_accuracy: 0.7880 - val_loss: 0.4506 - val_categorical_accuracy: 0.7897

Epoch 00045: val_loss did not improve from 0.44829
Epoch 46/50

  32/4000 [..............................] - ETA: 0s - loss: 0.3223 - categorical_accuracy: 0.8750
1248/4000 [========>.....................] - ETA: 0s - loss: 0.4758 - categorical_accuracy: 0.7973
2656/4000 [==================>...........] - ETA: 0s - loss: 0.4582 - categorical_accuracy: 0.7978
3968/4000 [============================>.] - ETA: 0s - loss: 0.4666 - categorical_accuracy: 0.7921
4000/4000 [==============================] - 0s 62us/step - loss: 0.4663 - categorical_accuracy: 0.7920 - val_loss: 0.4516 - val_categorical_accuracy: 0.7912

Epoch 00046: val_loss did not improve from 0.44829
Epoch 47/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4322 - categorical_accuracy: 0.8125
1152/4000 [=======>......................] - ETA: 0s - loss: 0.4460 - categorical_accuracy: 0.7899
2592/4000 [==================>...........] - ETA: 0s - loss: 0.4642 - categorical_accuracy: 0.7870
3968/4000 [============================>.] - ETA: 0s - loss: 0.4668 - categorical_accuracy: 0.7865
4000/4000 [==============================] - 0s 62us/step - loss: 0.4680 - categorical_accuracy: 0.7862 - val_loss: 0.4495 - val_categorical_accuracy: 0.7922

Epoch 00047: val_loss did not improve from 0.44829
Epoch 48/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4459 - categorical_accuracy: 0.7812
1280/4000 [========>.....................] - ETA: 0s - loss: 0.4771 - categorical_accuracy: 0.7781
2432/4000 [=================>............] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.7808
3488/4000 [=========================>....] - ETA: 0s - loss: 0.4701 - categorical_accuracy: 0.7838
4000/4000 [==============================] - 0s 70us/step - loss: 0.4715 - categorical_accuracy: 0.7847 - val_loss: 0.4493 - val_categorical_accuracy: 0.7918

Epoch 00048: val_loss did not improve from 0.44829
Epoch 49/50

  32/4000 [..............................] - ETA: 0s - loss: 0.5190 - categorical_accuracy: 0.7812
1216/4000 [========>.....................] - ETA: 0s - loss: 0.4554 - categorical_accuracy: 0.8010
2432/4000 [=================>............] - ETA: 0s - loss: 0.4632 - categorical_accuracy: 0.7977
3520/4000 [=========================>....] - ETA: 0s - loss: 0.4750 - categorical_accuracy: 0.7852
4000/4000 [==============================] - 0s 67us/step - loss: 0.4708 - categorical_accuracy: 0.7895 - val_loss: 0.4501 - val_categorical_accuracy: 0.7933

Epoch 00049: val_loss did not improve from 0.44829
Epoch 50/50

  32/4000 [..............................] - ETA: 0s - loss: 0.4993 - categorical_accuracy: 0.8125
1376/4000 [=========>....................] - ETA: 0s - loss: 0.4581 - categorical_accuracy: 0.7863
2720/4000 [===================>..........] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.7801
4000/4000 [==============================] - 0s 59us/step - loss: 0.4638 - categorical_accuracy: 0.7865 - val_loss: 0.4475 - val_categorical_accuracy: 0.7915

Epoch 00050: val_loss improved from 0.44829 to 0.44750, saving model to dataset/weights/TrainedModel_PyKeras.h5
                         : Elapsed time for training with 4000 events: [1;31m14.3 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 4000 events: [1;31m0.597 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.128e-01
                         :    2 : mfchi2     : 2.556e-01
                         :    3 : gm2e       : 9.343e-02
                         :    4 : gm2p3cms   : 2.409e-02
                         :    5 : gmthetacms : 2.224e-02
                         :    6 : gm1e925    : 2.023e-02
                         :    7 : gm1p3cms   : 1.430e-02
                         :    8 : gm2e925    : 1.405e-02
                         :    9 : pi0p3cms   : 1.271e-02
                         :   10 : gm1e       : 9.041e-03
                         :   11 : gm1eerror  : 8.423e-03
                         :   12 : gm2eerror  : 8.245e-03
                         :   13 : ediff      : 4.854e-03
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.035344      1.0035   [     -2.9955      5.7307 ]
                         :   pi0p3cms:    0.036963      1.0008   [     -3.1514      5.7307 ]
                         :       gm1e:    0.038187      1.0153   [     -2.8532      5.7307 ]
                         :       gm2e:    0.013699     0.99659   [     -2.8713      5.7307 ]
                         :    gm1e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :    gm2e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :      ediff:    0.042492      1.0203   [     -2.9312      5.7307 ]
                         :  gm1eerror:    0.044368      1.0230   [     -2.6163      5.7307 ]
                         :  gm2eerror:    0.017235     0.98759   [     -2.6397      5.7307 ]
                         :   gm1p3cms:    0.041202      1.0084   [     -2.9885      5.7307 ]
                         :   gm2p3cms:    0.017214     0.99841   [     -3.4791      5.7307 ]
                         : gmthetacms:  -0.0033392     0.98707   [     -4.0412      5.7307 ]
                         :     mfchi2:    0.014607     0.99591   [     -2.1007      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.035344      1.0035   [     -2.9955      5.7307 ]
                         :   pi0p3cms:    0.036963      1.0008   [     -3.1514      5.7307 ]
                         :       gm1e:    0.038187      1.0153   [     -2.8532      5.7307 ]
                         :       gm2e:    0.013699     0.99659   [     -2.8713      5.7307 ]
                         :    gm1e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :    gm2e925:     0.65932      1.9985   [     -2.9356      5.4200 ]
                         :      ediff:    0.042492      1.0203   [     -2.9312      5.7307 ]
                         :  gm1eerror:    0.044368      1.0230   [     -2.6163      5.7307 ]
                         :  gm2eerror:    0.017235     0.98759   [     -2.6397      5.7307 ]
                         :   gm1p3cms:    0.041202      1.0084   [     -2.9885      5.7307 ]
                         :   gm2p3cms:    0.017214     0.99841   [     -3.4791      5.7307 ]
                         : gmthetacms:  -0.0033392     0.98707   [     -4.0412      5.7307 ]
                         :     mfchi2:    0.014607     0.99591   [     -2.1007      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.60427     0.56727   [   0.0049119      4.2687 ]
                         :   pi0p3cms:     0.76377     0.75986   [    0.011733      6.0224 ]
                         :       gm1e:     0.45180     0.43868   [    0.063518      3.8130 ]
                         :       gm2e:     0.17939     0.16833   [    0.060015      1.8160 ]
                         :    gm1e925:     0.95262    0.061574   [     0.26583      1.0000 ]
                         :    gm2e925:     0.95262    0.061574   [     0.26583      1.0000 ]
                         :      ediff:     0.27242     0.36967   [  3.9078e-05      3.4668 ]
                         :  gm1eerror:  0.00014844  0.00037581   [  2.2654e-06   0.0088087 ]
                         :  gm2eerror:  2.5471e-05  6.3633e-05   [  1.7405e-06   0.0012202 ]
                         :   gm1p3cms:     0.56471     0.59250   [    0.049929      5.0839 ]
                         :   gm2p3cms:     0.22127     0.22389   [    0.043825      2.6831 ]
                         : gmthetacms:     0.73038     0.52572   [    0.044029      3.0194 ]
                         :     mfchi2:      8.7567      11.451   [  2.3731e-07      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       PyKeras        : 0.874
                         : dataset       GTB            : 0.868
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              PyKeras        : 0.235 (0.275)       0.672 (0.664)      0.858 (0.859)
                         : dataset              GTB            : 0.185 (0.401)       0.652 (0.703)      0.853 (0.872)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 4000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 4000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
