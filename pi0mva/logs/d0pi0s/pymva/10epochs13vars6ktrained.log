DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree pi0tree of type Signal with 174683 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree pi0tree of type Background with 4933019 events
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                448       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 66        
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Load model from file: model.h5
Factory                  : Booking method: [1mGTB[0m
                         : 
Factory                  : [1mTrain all methods[0m
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 6000
                         : Signal     -- testing events             : 6000
                         : Signal     -- training and testing events: 12000
                         : Background -- training events            : 6000
                         : Background -- testing events             : 6000
                         : Background -- training and testing events: 12000
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.975  +0.955  +0.758  -0.203  -0.203  +0.718    +0.765    +0.644   +0.938   +0.760     -0.685  -0.210
                         :   pi0p3cms:  +0.975   +1.000  +0.930  +0.743  -0.190  -0.190  +0.697    +0.767    +0.651   +0.960   +0.783     -0.671  -0.187
                         :       gm1e:  +0.955   +0.930  +1.000  +0.532  -0.138  -0.138  +0.892    +0.827    +0.449   +0.976   +0.544     -0.620  -0.189
                         :       gm2e:  +0.758   +0.743  +0.532  +1.000  -0.282  -0.282  +0.091    +0.376    +0.862   +0.535   +0.979     -0.560  -0.198
                         :    gm1e925:  -0.203   -0.190  -0.138  -0.282  +1.000  +1.000  -0.011    -0.094    -0.289   -0.131   -0.266     +0.083  -0.037
                         :    gm2e925:  -0.203   -0.190  -0.138  -0.282  +1.000  +1.000  -0.011    -0.094    -0.289   -0.131   -0.266     +0.083  -0.037
                         :      ediff:  +0.718   +0.697  +0.892  +0.091  -0.011  -0.011  +1.000    +0.771    +0.067   +0.862   +0.117     -0.429  -0.117
                         :  gm1eerror:  +0.765   +0.767  +0.827  +0.376  -0.094  -0.094  +0.771    +1.000    +0.358   +0.829   +0.400     -0.378  -0.114
                         :  gm2eerror:  +0.644   +0.651  +0.449  +0.862  -0.289  -0.289  +0.067    +0.358    +1.000   +0.467   +0.869     -0.368  -0.135
                         :   gm1p3cms:  +0.938   +0.960  +0.976  +0.535  -0.131  -0.131  +0.862    +0.829    +0.467   +1.000   +0.579     -0.615  -0.170
                         :   gm2p3cms:  +0.760   +0.783  +0.544  +0.979  -0.266  -0.266  +0.117    +0.400    +0.869   +0.579   +1.000     -0.561  -0.181
                         : gmthetacms:  -0.685   -0.671  -0.620  -0.560  +0.083  +0.083  -0.429    -0.378    -0.368   -0.615   -0.561     +1.000  +0.217
                         :     mfchi2:  -0.210   -0.187  -0.189  -0.198  -0.037  -0.037  -0.117    -0.114    -0.135   -0.170   -0.181     +0.217  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : -----------------------------------------------------------------------------------------------------------------------------
                         :               pi0p3 pi0p3cms    gm1e    gm2e gm1e925 gm2e925   ediff gm1eerror gm2eerror gm1p3cms gm2p3cms gmthetacms  mfchi2
                         :      pi0p3:  +1.000   +0.976  +0.967  +0.642  -0.066  -0.066  +0.851    +0.789    +0.505   +0.950   +0.641     -0.708  -0.138
                         :   pi0p3cms:  +0.976   +1.000  +0.943  +0.634  -0.061  -0.061  +0.828    +0.785    +0.513   +0.969   +0.673     -0.716  -0.128
                         :       gm1e:  +0.967   +0.943  +1.000  +0.442  -0.061  -0.061  +0.954    +0.844    +0.347   +0.979   +0.451     -0.613  -0.135
                         :       gm2e:  +0.642   +0.634  +0.442  +1.000  -0.056  -0.056  +0.153    +0.314    +0.822   +0.447   +0.964     -0.539  -0.120
                         :    gm1e925:  -0.066   -0.061  -0.061  -0.056  +1.000  +1.000  -0.048    -0.035    -0.043   -0.057   -0.051     +0.039  +0.003
                         :    gm2e925:  -0.066   -0.061  -0.061  -0.056  +1.000  +1.000  -0.048    -0.035    -0.043   -0.057   -0.051     +0.039  +0.003
                         :      ediff:  +0.851   +0.828  +0.954  +0.153  -0.048  -0.048  +1.000    +0.825    +0.108   +0.929   +0.175     -0.496  -0.108
                         :  gm1eerror:  +0.789   +0.785  +0.844  +0.314  -0.035  -0.035  +0.825    +1.000    +0.258   +0.837   +0.331     -0.378  -0.119
                         :  gm2eerror:  +0.505   +0.513  +0.347  +0.822  -0.043  -0.043  +0.108    +0.258    +1.000   +0.360   +0.812     -0.332  -0.100
                         :   gm1p3cms:  +0.950   +0.969  +0.979  +0.447  -0.057  -0.057  +0.929    +0.837    +0.360   +1.000   +0.481     -0.628  -0.126
                         :   gm2p3cms:  +0.641   +0.673  +0.451  +0.964  -0.051  -0.051  +0.175    +0.331    +0.812   +0.481   +1.000     -0.578  -0.111
                         : gmthetacms:  -0.708   -0.716  -0.613  -0.539  +0.039  +0.039  -0.496    -0.378    -0.332   -0.628   -0.578     +1.000  +0.075
                         :     mfchi2:  -0.138   -0.128  -0.135  -0.120  +0.003  +0.003  -0.108    -0.119    -0.100   -0.126   -0.111     +0.075  +1.000
                         : -----------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'pi0p3' <---> Output : variable 'pi0p3'
                         : Input : variable 'pi0p3cms' <---> Output : variable 'pi0p3cms'
                         : Input : variable 'gm1e' <---> Output : variable 'gm1e'
                         : Input : variable 'gm2e' <---> Output : variable 'gm2e'
                         : Input : variable 'gm1e925' <---> Output : variable 'gm1e925'
                         : Input : variable 'gm2e925' <---> Output : variable 'gm2e925'
                         : Input : variable 'ediff' <---> Output : variable 'ediff'
                         : Input : variable 'gm1eerror' <---> Output : variable 'gm1eerror'
                         : Input : variable 'gm2eerror' <---> Output : variable 'gm2eerror'
                         : Input : variable 'gm1p3cms' <---> Output : variable 'gm1p3cms'
                         : Input : variable 'gm2p3cms' <---> Output : variable 'gm2p3cms'
                         : Input : variable 'gmthetacms' <---> Output : variable 'gmthetacms'
                         : Input : variable 'mfchi2' <---> Output : variable 'mfchi2'
                         : Preparing the Gaussian transformation...
TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0053051     0.99926   [     -3.2332      5.7307 ]
                         :   pi0p3cms:   0.0052321     0.99905   [     -3.2348      5.7307 ]
                         :       gm1e:   0.0060635      1.0029   [     -3.2303      5.7307 ]
                         :       gm2e:   0.0052104     0.99916   [     -3.0607      5.7307 ]
                         :    gm1e925:     0.72692      2.1166   [     -3.1983      5.7307 ]
                         :    gm2e925:     0.72692      2.1166   [     -3.1983      5.7307 ]
                         :      ediff:   0.0061179      1.0031   [     -3.1056      5.7307 ]
                         :  gm1eerror:   0.0079321     0.98961   [     -2.9999      5.7307 ]
                         :  gm2eerror:   0.0060253     0.99530   [     -2.9954      5.7307 ]
                         :   gm1p3cms:   0.0055942      1.0006   [     -3.2277      5.7307 ]
                         :   gm2p3cms:   0.0052206     0.99919   [     -3.2160      5.7307 ]
                         : gmthetacms:   0.0055229      1.0002   [     -3.2350      5.7307 ]
                         :     mfchi2:   0.0099511     0.99009   [     -2.1804      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
Id_GaussTransformation   : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : pi0p3      : 2.927e-01
                         :    2 : gm1e       : 2.599e-01
                         :    3 : gmthetacms : 2.585e-01
                         :    4 : pi0p3cms   : 2.484e-01
                         :    5 : gm1eerror  : 2.435e-01
                         :    6 : mfchi2     : 2.406e-01
                         :    7 : gm2e       : 2.402e-01
                         :    8 : gm1p3cms   : 2.237e-01
                         :    9 : gm2eerror  : 2.197e-01
                         :   10 : gm2p3cms   : 2.021e-01
                         :   11 : ediff      : 1.337e-01
                         :   12 : gm1e925    : 7.512e-02
                         :   13 : gm2e925    : 7.512e-02
                         : -----------------------------------
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:   0.0053051     0.99926   [     -3.2332      5.7307 ]
                         :   pi0p3cms:   0.0052321     0.99905   [     -3.2348      5.7307 ]
                         :       gm1e:   0.0060635      1.0029   [     -3.2303      5.7307 ]
                         :       gm2e:   0.0052104     0.99916   [     -3.0607      5.7307 ]
                         :    gm1e925:     0.72692      2.1166   [     -3.1983      5.7307 ]
                         :    gm2e925:     0.72692      2.1166   [     -3.1983      5.7307 ]
                         :      ediff:   0.0061179      1.0031   [     -3.1056      5.7307 ]
                         :  gm1eerror:   0.0079321     0.98961   [     -2.9999      5.7307 ]
                         :  gm2eerror:   0.0060253     0.99530   [     -2.9954      5.7307 ]
                         :   gm1p3cms:   0.0055942      1.0006   [     -3.2277      5.7307 ]
                         :   gm2p3cms:   0.0052206     0.99919   [     -3.2160      5.7307 ]
                         : gmthetacms:   0.0055229      1.0002   [     -3.2350      5.7307 ]
                         :     mfchi2:   0.0099511     0.99009   [     -2.1804      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
                         : Option TriesEarlyStopping: Training will stop after 3 number of epochs with no improvement of validation loss
Train on 12000 samples, validate on 12000 samples
Epoch 1/10

   32/12000 [..............................] - ETA: 57s - loss: 0.7454 - categorical_accuracy: 0.6250
 1664/12000 [===>..........................] - ETA: 1s - loss: 0.7307 - categorical_accuracy: 0.6010 
 3392/12000 [=======>......................] - ETA: 0s - loss: 0.6767 - categorical_accuracy: 0.6439
 5056/12000 [===========>..................] - ETA: 0s - loss: 0.6393 - categorical_accuracy: 0.6729
 6720/12000 [===============>..............] - ETA: 0s - loss: 0.6247 - categorical_accuracy: 0.6850
 8416/12000 [====================>.........] - ETA: 0s - loss: 0.6119 - categorical_accuracy: 0.6938
10112/12000 [========================>.....] - ETA: 0s - loss: 0.6026 - categorical_accuracy: 0.7021
11744/12000 [============================>.] - ETA: 0s - loss: 0.5934 - categorical_accuracy: 0.7062
12000/12000 [==============================] - 1s 64us/step - loss: 0.5920 - categorical_accuracy: 0.7069 - val_loss: 0.4862 - val_categorical_accuracy: 0.7717

Epoch 00001: val_loss improved from inf to 0.48619, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 2/10

   32/12000 [..............................] - ETA: 0s - loss: 0.4876 - categorical_accuracy: 0.7812
 1600/12000 [===>..........................] - ETA: 0s - loss: 0.5001 - categorical_accuracy: 0.7713
 3264/12000 [=======>......................] - ETA: 0s - loss: 0.5043 - categorical_accuracy: 0.7708
 4896/12000 [===========>..................] - ETA: 0s - loss: 0.5126 - categorical_accuracy: 0.7608
 6528/12000 [===============>..............] - ETA: 0s - loss: 0.5115 - categorical_accuracy: 0.7607
 8224/12000 [===================>..........] - ETA: 0s - loss: 0.5110 - categorical_accuracy: 0.7612
 9888/12000 [=======================>......] - ETA: 0s - loss: 0.5137 - categorical_accuracy: 0.7600
11552/12000 [===========================>..] - ETA: 0s - loss: 0.5137 - categorical_accuracy: 0.7606
12000/12000 [==============================] - 1s 48us/step - loss: 0.5130 - categorical_accuracy: 0.7613 - val_loss: 0.4754 - val_categorical_accuracy: 0.7829

Epoch 00002: val_loss improved from 0.48619 to 0.47540, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 3/10

   32/12000 [..............................] - ETA: 0s - loss: 0.5657 - categorical_accuracy: 0.7500
 1664/12000 [===>..........................] - ETA: 0s - loss: 0.5003 - categorical_accuracy: 0.7722
 3296/12000 [=======>......................] - ETA: 0s - loss: 0.5087 - categorical_accuracy: 0.7637
 5024/12000 [===========>..................] - ETA: 0s - loss: 0.5012 - categorical_accuracy: 0.7667
 6688/12000 [===============>..............] - ETA: 0s - loss: 0.5009 - categorical_accuracy: 0.7703
 8352/12000 [===================>..........] - ETA: 0s - loss: 0.5008 - categorical_accuracy: 0.7671
10016/12000 [========================>.....] - ETA: 0s - loss: 0.5014 - categorical_accuracy: 0.7690
11584/12000 [===========================>..] - ETA: 0s - loss: 0.5004 - categorical_accuracy: 0.7694
12000/12000 [==============================] - 1s 49us/step - loss: 0.5005 - categorical_accuracy: 0.7699 - val_loss: 0.4737 - val_categorical_accuracy: 0.7822

Epoch 00003: val_loss improved from 0.47540 to 0.47371, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 4/10

   32/12000 [..............................] - ETA: 0s - loss: 0.4252 - categorical_accuracy: 0.7500
 1664/12000 [===>..........................] - ETA: 0s - loss: 0.4995 - categorical_accuracy: 0.7704
 3360/12000 [=======>......................] - ETA: 0s - loss: 0.5029 - categorical_accuracy: 0.7673
 5056/12000 [===========>..................] - ETA: 0s - loss: 0.4927 - categorical_accuracy: 0.7727
 6688/12000 [===============>..............] - ETA: 0s - loss: 0.4911 - categorical_accuracy: 0.7762
 8320/12000 [===================>..........] - ETA: 0s - loss: 0.4901 - categorical_accuracy: 0.7776
 9984/12000 [=======================>......] - ETA: 0s - loss: 0.4910 - categorical_accuracy: 0.7783
11648/12000 [============================>.] - ETA: 0s - loss: 0.4929 - categorical_accuracy: 0.7771
12000/12000 [==============================] - 1s 48us/step - loss: 0.4921 - categorical_accuracy: 0.7781 - val_loss: 0.4671 - val_categorical_accuracy: 0.7845

Epoch 00004: val_loss improved from 0.47371 to 0.46711, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 5/10

   32/12000 [..............................] - ETA: 0s - loss: 0.6686 - categorical_accuracy: 0.7188
 1664/12000 [===>..........................] - ETA: 0s - loss: 0.4995 - categorical_accuracy: 0.7788
 3328/12000 [=======>......................] - ETA: 0s - loss: 0.4866 - categorical_accuracy: 0.7885
 4960/12000 [===========>..................] - ETA: 0s - loss: 0.4771 - categorical_accuracy: 0.7923
 6560/12000 [===============>..............] - ETA: 0s - loss: 0.4884 - categorical_accuracy: 0.7838
 8128/12000 [===================>..........] - ETA: 0s - loss: 0.4902 - categorical_accuracy: 0.7830
 9760/12000 [=======================>......] - ETA: 0s - loss: 0.4931 - categorical_accuracy: 0.7802
11488/12000 [===========================>..] - ETA: 0s - loss: 0.4923 - categorical_accuracy: 0.7812
12000/12000 [==============================] - 1s 49us/step - loss: 0.4930 - categorical_accuracy: 0.7812 - val_loss: 0.4695 - val_categorical_accuracy: 0.7862

Epoch 00005: val_loss did not improve from 0.46711
Epoch 6/10

   32/12000 [..............................] - ETA: 0s - loss: 0.4388 - categorical_accuracy: 0.8125
 1632/12000 [===>..........................] - ETA: 0s - loss: 0.4852 - categorical_accuracy: 0.7917
 3392/12000 [=======>......................] - ETA: 0s - loss: 0.4874 - categorical_accuracy: 0.7845
 5024/12000 [===========>..................] - ETA: 0s - loss: 0.4831 - categorical_accuracy: 0.7858
 6688/12000 [===============>..............] - ETA: 0s - loss: 0.4842 - categorical_accuracy: 0.7815
 8320/12000 [===================>..........] - ETA: 0s - loss: 0.4859 - categorical_accuracy: 0.7821
 9952/12000 [=======================>......] - ETA: 0s - loss: 0.4898 - categorical_accuracy: 0.7806
11648/12000 [============================>.] - ETA: 0s - loss: 0.4879 - categorical_accuracy: 0.7811
12000/12000 [==============================] - 1s 48us/step - loss: 0.4892 - categorical_accuracy: 0.7801 - val_loss: 0.4653 - val_categorical_accuracy: 0.7862

Epoch 00006: val_loss improved from 0.46711 to 0.46525, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 7/10

   32/12000 [..............................] - ETA: 0s - loss: 0.4239 - categorical_accuracy: 0.8438
 1632/12000 [===>..........................] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.7825
 3232/12000 [=======>......................] - ETA: 0s - loss: 0.4815 - categorical_accuracy: 0.7806
 4960/12000 [===========>..................] - ETA: 0s - loss: 0.4864 - categorical_accuracy: 0.7776
 6592/12000 [===============>..............] - ETA: 0s - loss: 0.4863 - categorical_accuracy: 0.7806
 8288/12000 [===================>..........] - ETA: 0s - loss: 0.4859 - categorical_accuracy: 0.7831
 9888/12000 [=======================>......] - ETA: 0s - loss: 0.4864 - categorical_accuracy: 0.7829
11584/12000 [===========================>..] - ETA: 0s - loss: 0.4831 - categorical_accuracy: 0.7838
12000/12000 [==============================] - 1s 49us/step - loss: 0.4843 - categorical_accuracy: 0.7832 - val_loss: 0.4614 - val_categorical_accuracy: 0.7872

Epoch 00007: val_loss improved from 0.46525 to 0.46145, saving model to dataset/weights/TrainedModel_PyKeras.h5
Epoch 8/10

   32/12000 [..............................] - ETA: 0s - loss: 0.5082 - categorical_accuracy: 0.7188
 1728/12000 [===>..........................] - ETA: 0s - loss: 0.4823 - categorical_accuracy: 0.7905
 3328/12000 [=======>......................] - ETA: 0s - loss: 0.4838 - categorical_accuracy: 0.7873
 5024/12000 [===========>..................] - ETA: 0s - loss: 0.4860 - categorical_accuracy: 0.7846
 6656/12000 [===============>..............] - ETA: 0s - loss: 0.4846 - categorical_accuracy: 0.7870
 8288/12000 [===================>..........] - ETA: 0s - loss: 0.4826 - categorical_accuracy: 0.7885
 9920/12000 [=======================>......] - ETA: 0s - loss: 0.4840 - categorical_accuracy: 0.7876
11520/12000 [===========================>..] - ETA: 0s - loss: 0.4857 - categorical_accuracy: 0.7854
12000/12000 [==============================] - 1s 50us/step - loss: 0.4854 - categorical_accuracy: 0.7862 - val_loss: 0.4644 - val_categorical_accuracy: 0.7887

Epoch 00008: val_loss did not improve from 0.46145
Epoch 9/10

   32/12000 [..............................] - ETA: 0s - loss: 0.5707 - categorical_accuracy: 0.6875
 1728/12000 [===>..........................] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.7830
 3456/12000 [=======>......................] - ETA: 0s - loss: 0.4797 - categorical_accuracy: 0.7873
 5088/12000 [===========>..................] - ETA: 0s - loss: 0.4840 - categorical_accuracy: 0.7858
 6656/12000 [===============>..............] - ETA: 0s - loss: 0.4759 - categorical_accuracy: 0.7894
 7968/12000 [==================>...........] - ETA: 0s - loss: 0.4730 - categorical_accuracy: 0.7918
 9632/12000 [=======================>......] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.7930
11296/12000 [===========================>..] - ETA: 0s - loss: 0.4793 - categorical_accuracy: 0.7900
12000/12000 [==============================] - 1s 49us/step - loss: 0.4811 - categorical_accuracy: 0.7882 - val_loss: 0.4646 - val_categorical_accuracy: 0.7886

Epoch 00009: val_loss did not improve from 0.46145
Epoch 10/10

   32/12000 [..............................] - ETA: 0s - loss: 0.3557 - categorical_accuracy: 0.8750
 1696/12000 [===>..........................] - ETA: 0s - loss: 0.4686 - categorical_accuracy: 0.7936
 3424/12000 [=======>......................] - ETA: 0s - loss: 0.4760 - categorical_accuracy: 0.7921
 5024/12000 [===========>..................] - ETA: 0s - loss: 0.4718 - categorical_accuracy: 0.7936
 6720/12000 [===============>..............] - ETA: 0s - loss: 0.4781 - categorical_accuracy: 0.7906
 8352/12000 [===================>..........] - ETA: 0s - loss: 0.4801 - categorical_accuracy: 0.7881
 9888/12000 [=======================>......] - ETA: 0s - loss: 0.4804 - categorical_accuracy: 0.7874
11616/12000 [============================>.] - ETA: 0s - loss: 0.4828 - categorical_accuracy: 0.7846
12000/12000 [==============================] - 1s 48us/step - loss: 0.4821 - categorical_accuracy: 0.7857 - val_loss: 0.4633 - val_categorical_accuracy: 0.7875

Epoch 00010: val_loss did not improve from 0.46145
Epoch 00010: early stopping
                         : Elapsed time for training with 12000 events: [1;31m6.79 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: GTB for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ GTB ] :[0m
                         : A gradient tree boosting classifier builds a model from an ensemble
                         : of decision trees, which are adapted each boosting step to fit better
                         : to previously misclassified events.
                         : 
                         : Check out the scikit-learn documentation for more information.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : 
                         : [1mSaving state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
                         : Elapsed time for training with 12000 events: [1;31m1.47 sec[0m         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_GTB.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_GTB.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
                         : No variable ranking supplied by classifier: PyKeras
GTB                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : pi0p3      : 5.489e-01
                         :    2 : mfchi2     : 2.857e-01
                         :    3 : gm2e       : 8.429e-02
                         :    4 : gm2e925    : 1.577e-02
                         :    5 : gm2p3cms   : 1.323e-02
                         :    6 : gmthetacms : 1.038e-02
                         :    7 : gm1e925    : 1.029e-02
                         :    8 : pi0p3cms   : 7.948e-03
                         :    9 : gm1p3cms   : 7.843e-03
                         :   10 : gm2eerror  : 4.448e-03
                         :   11 : gm1e       : 4.066e-03
                         :   12 : ediff      : 3.619e-03
                         :   13 : gm1eerror  : 3.503e-03
                         : --------------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: dataset/weights/TrainedModel_PyKeras.h5
Factory                  : Test method: GTB for Classification performance
                         : 
                         : 
                         : [1mLoading state file: [0mdataset/weights/PyGTBModel_GTB.PyData
                         : 
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.032283     0.98638   [     -3.2187      5.7307 ]
                         :   pi0p3cms:    0.030040     0.98999   [     -3.1008      5.7307 ]
                         :       gm1e:    0.033230     0.99752   [     -3.2208      5.7307 ]
                         :       gm2e:    0.027363     0.98336   [     -3.0910      5.7307 ]
                         :    gm1e925:     0.69260      2.1041   [     -3.7463      5.7307 ]
                         :    gm2e925:     0.69260      2.1041   [     -3.7463      5.7307 ]
                         :      ediff:    0.028545      1.0019   [     -3.1320      5.7307 ]
                         :  gm1eerror:    0.033934     0.97860   [     -2.9854      5.7307 ]
                         :  gm2eerror:    0.023296     0.97998   [     -2.9814      4.1448 ]
                         :   gm1p3cms:    0.032122     0.99468   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.024051     0.99081   [     -3.0380      5.7307 ]
                         : gmthetacms:   -0.019082     0.98551   [     -3.0352      5.7307 ]
                         :     mfchi2:  -0.0067930     0.98367   [     -2.1804      5.7307 ]
                         : ---------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:    0.032283     0.98638   [     -3.2187      5.7307 ]
                         :   pi0p3cms:    0.030040     0.98999   [     -3.1008      5.7307 ]
                         :       gm1e:    0.033230     0.99752   [     -3.2208      5.7307 ]
                         :       gm2e:    0.027363     0.98336   [     -3.0910      5.7307 ]
                         :    gm1e925:     0.69260      2.1041   [     -3.7463      5.7307 ]
                         :    gm2e925:     0.69260      2.1041   [     -3.7463      5.7307 ]
                         :      ediff:    0.028545      1.0019   [     -3.1320      5.7307 ]
                         :  gm1eerror:    0.033934     0.97860   [     -2.9854      5.7307 ]
                         :  gm2eerror:    0.023296     0.97998   [     -2.9814      4.1448 ]
                         :   gm1p3cms:    0.032122     0.99468   [     -5.7307      5.7307 ]
                         :   gm2p3cms:    0.024051     0.99081   [     -3.0380      5.7307 ]
                         : gmthetacms:   -0.019082     0.98551   [     -3.0352      5.7307 ]
                         :     mfchi2:  -0.0067930     0.98367   [     -2.1804      5.7307 ]
                         : ---------------------------------------------------------------------
Factory                  : Evaluate classifier: GTB
                         : 
GTB                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_GTB            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :      pi0p3:     0.59894     0.55840   [   0.0049119      4.9404 ]
                         :   pi0p3cms:     0.75712     0.74795   [    0.011479      7.1892 ]
                         :       gm1e:     0.44397     0.42391   [    0.063063      4.8358 ]
                         :       gm2e:     0.18175     0.17353   [    0.060001      1.9359 ]
                         :    gm1e925:     0.95240    0.062087   [     0.21284      1.0000 ]
                         :    gm2e925:     0.95240    0.062087   [     0.21284      1.0000 ]
                         :      ediff:     0.26222     0.35238   [  1.2249e-05      4.7205 ]
                         :  gm1eerror:  0.00013728  0.00032517   [  2.1524e-06   0.0088087 ]
                         :  gm2eerror:  2.6197e-05  6.6488e-05   [  1.7209e-06   0.0013470 ]
                         :   gm1p3cms:     0.55477     0.57190   [    0.048464      6.9342 ]
                         :   gm2p3cms:     0.22444     0.23195   [    0.043817      2.6974 ]
                         : gmthetacms:     0.72796     0.52335   [    0.044029      3.0902 ]
                         :     mfchi2:      8.7437      11.407   [  1.1481e-09      49.973 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       GTB            : 0.871
                         : dataset       PyKeras        : 0.865
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              GTB            : 0.257 (0.322)       0.659 (0.687)      0.856 (0.870)
                         : dataset              PyKeras        : 0.222 (0.252)       0.646 (0.652)      0.848 (0.858)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 12000 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 12000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
